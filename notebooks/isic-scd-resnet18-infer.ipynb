{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":63056,"databundleVersionId":8940774,"sourceType":"competition"},{"sourceId":187477024,"sourceType":"kernelVersion"},{"sourceId":188039676,"sourceType":"kernelVersion"},{"sourceId":187439867,"sourceType":"kernelVersion"}],"dockerImageVersionId":30733,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import json\nfrom tqdm import tqdm\nfrom pathlib import Path\nfrom timeit import default_timer as timer\n\nimport pandas as pd\nimport numpy as np\nfrom io import BytesIO\nfrom PIL import Image\nimport h5py\n\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.utils.data import DataLoader, Dataset\nimport albumentations as A\nfrom albumentations.pytorch import ToTensorV2\nfrom timm import create_model\n\nfrom accelerate import Accelerator\n\nfrom isic_helper import DotDict\nfrom isic_helper import get_folds\nfrom isic_helper import time_to_str","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-07-13T04:31:34.459372Z","iopub.execute_input":"2024-07-13T04:31:34.460341Z","iopub.status.idle":"2024-07-13T04:31:42.293202Z","shell.execute_reply.started":"2024-07-13T04:31:34.460295Z","shell.execute_reply":"2024-07-13T04:31:42.292346Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"INPUT_PATH = Path(\"../input/isic-2024-challenge/\")\nARTIFACTS_INPUT_PATH = Path(f\"../input/isic-scd-resnet18-train/\")\n\nwith open(ARTIFACTS_INPUT_PATH / \"run_metadata.json\", \"r\") as f:\n    run_metadata = json.load(f)\n\ncfg = DotDict()\nfor k, v in run_metadata[\"params\"].items():\n    setattr(cfg, k, v)\nsetattr(cfg, \"infer\", True)\nprint(cfg)\n\nMODELS_INPUT_PATH = ARTIFACTS_INPUT_PATH / cfg.models_output_dir\n\ntrain_metadata = pd.read_csv(INPUT_PATH / \"train-metadata.csv\", low_memory=False)\n\ntest_metadata = pd.read_csv(INPUT_PATH / \"test-metadata.csv\", low_memory=False)\ntest_images = h5py.File(INPUT_PATH / \"test-image.hdf5\", mode=\"r\")\n\nfolds_df = get_folds()\ntrain_metadata = train_metadata.merge(folds_df, on=[\"isic_id\", \"patient_id\"], how=\"inner\")\nprint(f\"Train data size: {train_metadata.shape}\")\nprint(f\"Test data size: {test_metadata.shape}\")","metadata":{"execution":{"iopub.status.busy":"2024-07-13T04:32:32.443518Z","iopub.execute_input":"2024-07-13T04:32:32.444201Z","iopub.status.idle":"2024-07-13T04:32:42.310880Z","shell.execute_reply.started":"2024-07-13T04:32:32.444168Z","shell.execute_reply":"2024-07-13T04:32:42.309871Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"DotDict(_temp=False, _key=None, _parent=None, infer=True, cpu=False, mixed_precision='fp16', tta=True, pos_ratio=0.1, image_size=64, lr=0.0005, num_epochs=1, seed=2022, train_batch_size=256, train_num_worker=2, val_batch_size=256, val_num_worker=2, log_every=10, models_output_dir='models', model_name='resnet18_v1')\nTrain data size: (401059, 57)\nTest data size: (3, 44)\n","output_type":"stream"}]},{"cell_type":"code","source":"id_column = \"isic_id\"\ntarget_column = \"target\"\nfolds = train_metadata[\"fold\"]","metadata":{"execution":{"iopub.status.busy":"2024-07-13T04:32:43.435513Z","iopub.execute_input":"2024-07-13T04:32:43.436662Z","iopub.status.idle":"2024-07-13T04:32:43.441577Z","shell.execute_reply.started":"2024-07-13T04:32:43.436617Z","shell.execute_reply":"2024-07-13T04:32:43.440493Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"accelerator = Accelerator(cpu=cfg.cpu, mixed_precision=cfg.mixed_precision)","metadata":{"execution":{"iopub.status.busy":"2024-07-13T04:32:44.102266Z","iopub.execute_input":"2024-07-13T04:32:44.102642Z","iopub.status.idle":"2024-07-13T04:32:44.158921Z","shell.execute_reply.started":"2024-07-13T04:32:44.102611Z","shell.execute_reply":"2024-07-13T04:32:44.158161Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"accelerator.device","metadata":{"execution":{"iopub.status.busy":"2024-07-13T04:32:44.903743Z","iopub.execute_input":"2024-07-13T04:32:44.904562Z","iopub.status.idle":"2024-07-13T04:32:44.910945Z","shell.execute_reply.started":"2024-07-13T04:32:44.904532Z","shell.execute_reply":"2024-07-13T04:32:44.910067Z"},"trusted":true},"execution_count":7,"outputs":[{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"device(type='cuda')"},"metadata":{}}]},{"cell_type":"code","source":"def test_augment(image_size):\n    transform = A.Compose([\n        A.Resize(image_size, image_size),\n#         A.Normalize(\n#             mean=[0., 0., 0.],\n#             std=[1, 1, 1],\n#             max_pixel_value=255.0,\n#             p=1.0\n#         ),\n        ToTensorV2()\n    ], p=1.)\n    return transform\n\nclass ISICDataset(Dataset):\n    def __init__(self, metadata, images, augment, infer=False):\n        self.metadata = metadata\n        self.images = images\n        self.augment = augment\n        self.length = len(self.metadata)\n        self.infer = infer\n    \n    def __len__(self):\n        return self.length\n    \n    def __getitem__(self, index):\n        data = self.metadata.iloc[index]\n        \n        image = np.array(Image.open(BytesIO(self.images[data[id_column]][()])))\n        image = self.augment(image=image)[\"image\"]\n        \n        record = {\n            \"image\": image\n        }\n        \n        if not self.infer:\n            target = data[target_column]\n            record[\"target\"] = torch.tensor(target).float()\n        \n        return record\n\nclass ISICNet(nn.Module):\n    def __init__(self, arch=\"resnet18\", pretrained=False, infer=False):\n        super(ISICNet, self).__init__()\n        self.infer = infer\n        self.model = create_model(model_name=arch, pretrained=pretrained, in_chans=3,  num_classes=0, global_pool='')\n        self.classifier = nn.Linear(self.model.num_features, 1)\n        \n        self.dropouts = nn.ModuleList([nn.Dropout(0.5) for i in range(5)])\n        \n    def forward(self, batch):\n        image = batch[\"image\"]\n        image = image.float() / 255\n        \n        x = self.model(image)\n        bs = len(image)\n        pool = F.adaptive_avg_pool2d(x, 1).reshape(bs,-1)\n        \n        if self.training:\n            logit = 0\n            for i in range(len(self.dropouts)):\n                logit += self.classifier(self.dropouts[i](pool))\n            logit = logit/len(self.dropouts)\n        else:\n            logit = self.classifier(pool)\n        return logit","metadata":{"execution":{"iopub.status.busy":"2024-07-13T04:32:45.599636Z","iopub.execute_input":"2024-07-13T04:32:45.600528Z","iopub.status.idle":"2024-07-13T04:32:45.613998Z","shell.execute_reply.started":"2024-07-13T04:32:45.600495Z","shell.execute_reply":"2024-07-13T04:32:45.613081Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"all_folds = np.sort(folds.unique())\ntest_predictions_df = pd.DataFrame({id_column: test_metadata[id_column]})\ntest_dataset = ISICDataset(test_metadata, test_images, augment=test_augment(image_size=cfg.image_size), infer=True)\ntest_dataloader = DataLoader(test_dataset, shuffle=False, batch_size=cfg.val_batch_size, num_workers=cfg.val_num_worker, drop_last=False, pin_memory=True)\nfor fold in all_folds:\n    net = ISICNet(pretrained=False, infer=True)\n    net = net.to(accelerator.device)\n    \n    net, test_dataloader = accelerator.prepare(net, test_dataloader)\n    \n    accelerator.load_state(MODELS_INPUT_PATH / \n                           f\"fold_{fold}/model_{cfg.model_name}_epoch_{run_metadata['best_num_epochs'][f'fold_{fold}']}\")\n    \n    net.eval()\n    test_preds = []\n    for step, batch in tqdm(enumerate(test_dataloader), total=len(test_dataloader)):\n        # We could avoid this line since we set the accelerator with `device_placement=True`.\n        batch = {k: v.to(accelerator.device) for k, v in batch.items()}\n        \n        image0 = batch['image'].clone().detach()\n        test_preds_batch = 0\n        counter = 0\n        with torch.no_grad():\n            outputs = net(batch)\n        preds = torch.sigmoid(outputs)\n        preds = accelerator.gather_for_metrics((preds))\n        test_preds_batch += preds.data.cpu().numpy().reshape(-1)\n        counter += 1\n        if cfg.tta:\n            batch[\"image\"] = torch.flip(image0,dims=[2])\n            with torch.no_grad():\n                outputs = net(batch)\n            preds = torch.sigmoid(outputs)\n            preds = accelerator.gather_for_metrics((preds))\n            test_preds_batch += preds.data.cpu().numpy().reshape(-1)\n            counter += 1\n\n            batch[\"image\"] = torch.flip(image0,dims=[3])\n            with torch.no_grad():\n                outputs = net(batch)\n            preds = torch.sigmoid(outputs)\n            preds = accelerator.gather_for_metrics((preds))\n            test_preds_batch += preds.data.cpu().numpy().reshape(-1)\n            counter += 1\n\n            for k in [1, 2, 3]:\n                batch[\"image\"] = torch.rot90(image0,k, dims=[2, 3])\n                with torch.no_grad():\n                    outputs = net(batch)\n                preds = torch.sigmoid(outputs)\n                preds = accelerator.gather_for_metrics((preds))\n                test_preds_batch += preds.data.cpu().numpy().reshape(-1)\n                counter += 1\n                \n        test_preds_batch = test_preds_batch / counter   \n        test_preds.append(test_preds_batch)\n\n    test_preds = np.concatenate(test_preds)","metadata":{"execution":{"iopub.status.busy":"2024-07-13T04:35:01.769040Z","iopub.execute_input":"2024-07-13T04:35:01.769678Z","iopub.status.idle":"2024-07-13T04:35:03.365892Z","shell.execute_reply.started":"2024-07-13T04:35:01.769639Z","shell.execute_reply":"2024-07-13T04:35:03.364369Z"},"trusted":true},"execution_count":12,"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)","Cell \u001b[0;32mIn[12], line 11\u001b[0m\n\u001b[1;32m      7\u001b[0m net \u001b[38;5;241m=\u001b[39m net\u001b[38;5;241m.\u001b[39mto(accelerator\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[1;32m      9\u001b[0m net, test_dataloader \u001b[38;5;241m=\u001b[39m accelerator\u001b[38;5;241m.\u001b[39mprepare(net, test_dataloader)\n\u001b[0;32m---> 11\u001b[0m \u001b[43maccelerator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_state\u001b[49m\u001b[43m(\u001b[49m\u001b[43mMODELS_INPUT_PATH\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43m \u001b[49m\n\u001b[1;32m     12\u001b[0m \u001b[43m                       \u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfold_\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mfold\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m/model_\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mcfg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel_name\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m_epoch_\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mrun_metadata\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mbest_num_epochs\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mfold_\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mfold\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     14\u001b[0m net\u001b[38;5;241m.\u001b[39meval()\n\u001b[1;32m     15\u001b[0m test_preds \u001b[38;5;241m=\u001b[39m []\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/accelerate/accelerator.py:3102\u001b[0m, in \u001b[0;36mAccelerator.load_state\u001b[0;34m(self, input_dir, **load_model_func_kwargs)\u001b[0m\n\u001b[1;32m   3099\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   3100\u001b[0m         map_location \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 3102\u001b[0m \u001b[43mload_accelerator_state\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   3103\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3104\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3105\u001b[0m \u001b[43m    \u001b[49m\u001b[43moptimizers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3106\u001b[0m \u001b[43m    \u001b[49m\u001b[43mschedulers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3107\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdataloaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3108\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstate\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprocess_index\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3109\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscaler\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3110\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmap_location\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3111\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mload_model_func_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3112\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3113\u001b[0m custom_checkpoints \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m   3114\u001b[0m     f \u001b[38;5;28;01mfor\u001b[39;00m f \u001b[38;5;129;01min\u001b[39;00m os\u001b[38;5;241m.\u001b[39mlistdir(input_dir) \u001b[38;5;28;01mif\u001b[39;00m re\u001b[38;5;241m.\u001b[39msearch(\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m^custom_checkpoint_\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124md+\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124m.pkl$\u001b[39m\u001b[38;5;124m\"\u001b[39m, f) \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   3115\u001b[0m ]\n\u001b[1;32m   3116\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(custom_checkpoints) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_custom_objects):\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/accelerate/checkpointing.py:203\u001b[0m, in \u001b[0;36mload_accelerator_state\u001b[0;34m(input_dir, models, optimizers, schedulers, dataloaders, process_index, scaler, map_location, **load_model_func_kwargs)\u001b[0m\n\u001b[1;32m    200\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    201\u001b[0m         \u001b[38;5;66;03m# Load with torch\u001b[39;00m\n\u001b[1;32m    202\u001b[0m         input_model_file \u001b[38;5;241m=\u001b[39m input_dir\u001b[38;5;241m.\u001b[39mjoinpath(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mMODEL_NAME\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mending\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.bin\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 203\u001b[0m         state_dict \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_model_file\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmap_location\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmap_location\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    204\u001b[0m     models[i]\u001b[38;5;241m.\u001b[39mload_state_dict(state_dict, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mload_model_func_kwargs)\n\u001b[1;32m    205\u001b[0m logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAll model weights loaded successfully\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/serialization.py:986\u001b[0m, in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, weights_only, mmap, **pickle_load_args)\u001b[0m\n\u001b[1;32m    983\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m pickle_load_args\u001b[38;5;241m.\u001b[39mkeys():\n\u001b[1;32m    984\u001b[0m     pickle_load_args[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m--> 986\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43m_open_file_like\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m opened_file:\n\u001b[1;32m    987\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m _is_zipfile(opened_file):\n\u001b[1;32m    988\u001b[0m         \u001b[38;5;66;03m# The zipfile reader is going to advance the current file position.\u001b[39;00m\n\u001b[1;32m    989\u001b[0m         \u001b[38;5;66;03m# If we want to actually tail call to torch.jit.load, we need to\u001b[39;00m\n\u001b[1;32m    990\u001b[0m         \u001b[38;5;66;03m# reset back to the original position.\u001b[39;00m\n\u001b[1;32m    991\u001b[0m         orig_position \u001b[38;5;241m=\u001b[39m opened_file\u001b[38;5;241m.\u001b[39mtell()\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/serialization.py:435\u001b[0m, in \u001b[0;36m_open_file_like\u001b[0;34m(name_or_buffer, mode)\u001b[0m\n\u001b[1;32m    433\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_open_file_like\u001b[39m(name_or_buffer, mode):\n\u001b[1;32m    434\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m _is_path(name_or_buffer):\n\u001b[0;32m--> 435\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_open_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    436\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    437\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m mode:\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/serialization.py:416\u001b[0m, in \u001b[0;36m_open_file.__init__\u001b[0;34m(self, name, mode)\u001b[0m\n\u001b[1;32m    415\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, name, mode):\n\u001b[0;32m--> 416\u001b[0m     \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m)\n","\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../input/isic-scd-resnet18-train/models/fold_1/model_resnet18_v1_epoch_0/pytorch_model_1.bin'"],"ename":"FileNotFoundError","evalue":"[Errno 2] No such file or directory: '../input/isic-scd-resnet18-train/models/fold_1/model_resnet18_v1_epoch_0/pytorch_model_1.bin'","output_type":"error"}]},{"cell_type":"code","source":"test_predictions_df.head()","metadata":{"execution":{"iopub.status.busy":"2024-07-13T02:09:06.026582Z","iopub.execute_input":"2024-07-13T02:09:06.027268Z","iopub.status.idle":"2024-07-13T02:09:06.033745Z","shell.execute_reply.started":"2024-07-13T02:09:06.027230Z","shell.execute_reply":"2024-07-13T02:09:06.032687Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_predictions_df[target_column] = test_predictions_df[[f\"fold_{fold}\" for fold in all_folds]].mean(axis=1)","metadata":{"execution":{"iopub.status.busy":"2024-07-13T02:09:07.548279Z","iopub.execute_input":"2024-07-13T02:09:07.549232Z","iopub.status.idle":"2024-07-13T02:09:07.560031Z","shell.execute_reply.started":"2024-07-13T02:09:07.549188Z","shell.execute_reply":"2024-07-13T02:09:07.559135Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_predictions_df.head()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_predictions_df[target_column].describe()","metadata":{"execution":{"iopub.status.busy":"2024-07-13T02:09:09.907822Z","iopub.execute_input":"2024-07-13T02:09:09.908585Z","iopub.status.idle":"2024-07-13T02:09:09.921930Z","shell.execute_reply.started":"2024-07-13T02:09:09.908552Z","shell.execute_reply":"2024-07-13T02:09:09.920783Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_predictions_df[[id_column, target_column]].head(10)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_predictions_df[[id_column, target_column]].to_csv(\"submission.csv\", index=False)","metadata":{"execution":{"iopub.status.busy":"2024-07-13T02:09:12.236679Z","iopub.execute_input":"2024-07-13T02:09:12.237620Z","iopub.status.idle":"2024-07-13T02:09:12.245766Z","shell.execute_reply.started":"2024-07-13T02:09:12.237583Z","shell.execute_reply":"2024-07-13T02:09:12.244789Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}