{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":63056,"databundleVersionId":8940774,"sourceType":"competition"},{"sourceId":187439867,"sourceType":"kernelVersion"},{"sourceId":187477024,"sourceType":"kernelVersion"}],"dockerImageVersionId":30732,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import json\nimport joblib\nfrom tqdm import tqdm\nfrom pathlib import Path\nfrom timeit import default_timer as timer\n\nimport pandas as pd\nimport numpy as np\nfrom io import BytesIO\nfrom PIL import Image\nimport h5py\n\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.utils.data import DataLoader, Dataset\nimport albumentations as A\nfrom albumentations.pytorch import ToTensorV2\nfrom timm import create_model\nfrom torch.optim.lr_scheduler import OneCycleLR\n\nfrom accelerate import Accelerator\n\nfrom isic_helper import DotDict\nfrom isic_helper import get_folds\nfrom isic_helper import compute_auc, compute_pauc\nfrom isic_helper import set_seed\nfrom isic_helper import time_to_str","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-07-10T19:08:39.529145Z","iopub.execute_input":"2024-07-10T19:08:39.529974Z","iopub.status.idle":"2024-07-10T19:08:39.539200Z","shell.execute_reply.started":"2024-07-10T19:08:39.529918Z","shell.execute_reply":"2024-07-10T19:08:39.538141Z"},"trusted":true},"execution_count":42,"outputs":[]},{"cell_type":"code","source":"cfg = DotDict()\ncfg.infer = False\ncfg.cpu = False\ncfg.mixed_precision = None\n\ncfg.image_size = 384\ncfg.lr = 5e-4\ncfg.num_epochs = 10\ncfg.seed = 2022\ncfg.train_batch_size = 256\ncfg.train_num_worker = 2\ncfg.val_batch_size = 256\ncfg.val_num_worker = 2\ncfg.log_every = 10\n\ncfg.models_output_dir = \"models\"\ncfg.model_name = \"resnet18_v1\"","metadata":{"execution":{"iopub.status.busy":"2024-07-10T19:08:42.471674Z","iopub.execute_input":"2024-07-10T19:08:42.472565Z","iopub.status.idle":"2024-07-10T19:08:42.478848Z","shell.execute_reply.started":"2024-07-10T19:08:42.472531Z","shell.execute_reply":"2024-07-10T19:08:42.477827Z"},"trusted":true},"execution_count":43,"outputs":[]},{"cell_type":"code","source":"INPUT_PATH = Path(\"../input/isic-2024-challenge/\")\nMODELS_OUTPUT_PATH = Path(f\"{cfg.models_output_dir}\")\nMODELS_OUTPUT_PATH.mkdir(exist_ok=True)\n\ntrain_metadata = pd.read_csv(INPUT_PATH / \"train-metadata.csv\", low_memory=False)\ntrain_images = h5py.File(INPUT_PATH / \"train-image.hdf5\", mode=\"r\")\n\nfolds_df = get_folds()\ntrain_metadata = train_metadata.merge(folds_df, on=[\"isic_id\", \"patient_id\"], how=\"inner\")\ntrain_metadata = train_metadata.sample(frac=0.05, random_state=cfg.seed)\nprint(f\"Train data size: {train_metadata.shape}\")","metadata":{"execution":{"iopub.status.busy":"2024-07-10T19:08:42.809655Z","iopub.execute_input":"2024-07-10T19:08:42.810023Z","iopub.status.idle":"2024-07-10T19:08:51.114645Z","shell.execute_reply.started":"2024-07-10T19:08:42.809993Z","shell.execute_reply":"2024-07-10T19:08:51.113616Z"},"trusted":true},"execution_count":44,"outputs":[{"name":"stdout","text":"Train data size: (20053, 57)\n","output_type":"stream"}]},{"cell_type":"code","source":"id_column = \"isic_id\"\ntarget_column = \"final_target\"\ngroup_column = \"patient_id\"\n\ntrain_ids = train_metadata[id_column]\ngroups = train_metadata[group_column]\nfolds = train_metadata[\"fold\"]\ny_train = train_metadata[target_column]","metadata":{"execution":{"iopub.status.busy":"2024-07-10T19:08:51.116545Z","iopub.execute_input":"2024-07-10T19:08:51.116906Z","iopub.status.idle":"2024-07-10T19:08:51.122682Z","shell.execute_reply.started":"2024-07-10T19:08:51.116877Z","shell.execute_reply":"2024-07-10T19:08:51.121586Z"},"trusted":true},"execution_count":45,"outputs":[]},{"cell_type":"code","source":"accelerator = Accelerator(cpu=cfg.cpu, mixed_precision=cfg.mixed_precision)","metadata":{"execution":{"iopub.status.busy":"2024-07-10T19:08:51.123857Z","iopub.execute_input":"2024-07-10T19:08:51.124422Z","iopub.status.idle":"2024-07-10T19:08:51.139221Z","shell.execute_reply.started":"2024-07-10T19:08:51.124393Z","shell.execute_reply":"2024-07-10T19:08:51.138177Z"},"trusted":true},"execution_count":46,"outputs":[]},{"cell_type":"code","source":"accelerator.device","metadata":{"execution":{"iopub.status.busy":"2024-07-10T19:08:51.141011Z","iopub.execute_input":"2024-07-10T19:08:51.141314Z","iopub.status.idle":"2024-07-10T19:08:51.151524Z","shell.execute_reply.started":"2024-07-10T19:08:51.141277Z","shell.execute_reply":"2024-07-10T19:08:51.150536Z"},"trusted":true},"execution_count":47,"outputs":[{"execution_count":47,"output_type":"execute_result","data":{"text/plain":"device(type='cuda')"},"metadata":{}}]},{"cell_type":"code","source":"def dev_augment(image_size):\n    transform = A.Compose([\n        A.Resize(image_size, image_size),\n#         A.Normalize(\n#             mean=[0., 0., 0.],\n#             std=[1, 1, 1],\n#             max_pixel_value=255.0,\n#             p=1.0\n#         ),\n        ToTensorV2()\n    ], p=1.)\n    return transform\n\ndef val_augment(image_size):\n    transform = A.Compose([\n        A.Resize(image_size, image_size),\n#         A.Normalize(\n#             mean=[0., 0., 0.],\n#             std=[1, 1, 1],\n#             max_pixel_value=255.0,\n#             p=1.0\n#         ),\n        ToTensorV2()\n    ], p=1.)\n    return transform\n\nclass ISICDataset(Dataset):\n    def __init__(self, metadata, images, augment, infer=False):\n        self.metadata = metadata\n        self.images = images\n        self.augment = augment\n        self.length = len(self.metadata)\n        self.infer = infer\n    \n    def __len__(self):\n        return self.length\n    \n    def __getitem__(self, index):\n        data = self.metadata.iloc[index]\n        \n        image = np.array(Image.open(BytesIO(self.images[data[id_column]][()])))\n        image = self.augment(image=image)[\"image\"]\n        \n        record = {\n            \"image\": image\n        }\n        \n        if not self.infer:\n            target = data[target_column]\n            record[\"target\"] = torch.tensor(target).long()\n        \n        return record\n\nclass ISICNet(nn.Module):\n    def __init__(self, arch=\"resnet18\", pretrained=False, infer=False):\n        super(ISICNet, self).__init__()\n        self.infer = infer\n        self.model = create_model(model_name=arch, pretrained=pretrained, in_chans=3,  num_classes=0, global_pool='')\n        self.classifier = nn.Linear(self.model.num_features, 1)\n        \n        self.dropouts = nn.ModuleList([nn.Dropout(0.5) for i in range(5)])\n        \n    def forward(self, batch):\n        image = batch[\"image\"]\n        image = image.float() / 255\n        \n        x = self.model(image)\n        bs = len(image)\n        pool = F.adaptive_avg_pool2d(x, 1).reshape(bs,-1)\n        print(pool.size)\n        \n        if self.training:\n            logit = 0\n            for i in range(len(self.dropouts)):\n                logit += self.classifier(self.dropouts[i](pool))\n            logit = logit/len(self.dropouts)\n        else:\n            logit = self.classifier(pool)\n        return logit","metadata":{"execution":{"iopub.status.busy":"2024-07-10T19:08:58.572003Z","iopub.execute_input":"2024-07-10T19:08:58.572725Z","iopub.status.idle":"2024-07-10T19:08:58.590191Z","shell.execute_reply.started":"2024-07-10T19:08:58.572692Z","shell.execute_reply":"2024-07-10T19:08:58.589050Z"},"trusted":true},"execution_count":48,"outputs":[]},{"cell_type":"code","source":"best_num_epochs = {}\nval_auc_scores = {}\nval_pauc_scores = {}\nall_folds = np.sort(folds.unique())\noof_predictions = np.zeros(train_metadata.shape[0])\nfor fold in all_folds:\n    set_seed(cfg.seed)\n    \n    print(f\"Running fold: {fold}\")\n    dev_index = folds != fold\n    val_index = folds == fold\n    \n    dev_metadata = train_metadata[train_metadata[\"fold\"] != fold].reset_index(drop=True);print(f\"Dev data size: {dev_metadata.shape}\")\n    val_metadata = train_metadata[train_metadata[\"fold\"] == fold].reset_index(drop=True);print(f\"Val data size: {val_metadata.shape}\")\n    \n    dev_dataset = ISICDataset(dev_metadata, train_images, augment=dev_augment(image_size=cfg.image_size))\n    val_dataset = ISICDataset(val_metadata, train_images, augment=val_augment(image_size=cfg.image_size))\n\n    dev_dataloader = DataLoader(dev_dataset, shuffle=True, batch_size=cfg.train_batch_size, num_workers=cfg.train_num_worker)\n    val_dataloader = DataLoader(val_dataset, shuffle=False, batch_size=cfg.val_batch_size, num_workers=cfg.val_num_worker, drop_last=False)\n    \n    net = ISICNet(pretrained=True)\n    net = net.to(accelerator.device)\n        \n    optimizer = torch.optim.Adam(net.parameters(), lr=cfg.lr / 5)\n    lr_scheduler = OneCycleLR(optimizer=optimizer, max_lr=cfg.lr, epochs=cfg.num_epochs, steps_per_epoch=len(dev_dataloader))\n\n    net, optimizer, dev_dataloader, val_dataloader, lr_scheduler = accelerator.prepare(\n        net, optimizer, dev_dataloader, val_dataloader, lr_scheduler\n    )\n    \n    print(\"Ready to train\")\n    \n    overall_step = 0\n    starting_epoch = 0\n    best_pauc_score = -np.Inf\n    best_auc_score = -np.Inf\n    best_epoch = None\n    best_val_preds = None\n\n    for epoch in range(starting_epoch, cfg.num_epochs):\n        net.train()\n        for step, batch in tqdm(enumerate(dev_dataloader)):\n            # We could avoid this line since we set the accelerator with `device_placement=True`.\n            batch = {k: v.to(accelerator.device) for k, v in batch.items()}\n            \n            optimizer.zero_grad()\n            \n            outputs = net(batch)\n            loss = F.binary_cross_entropy_with_logits(outputs, batch[\"target\"].unsqueeze(1))\n            accelerator.backward(loss)\n            optimizer.step()\n            lr_scheduler.step()\n\n        net.eval()\n        val_preds = []\n        val_y = []\n        for step, batch in tqdm(enumerate(val_dataloader)):\n            # We could avoid this line since we set the accelerator with `device_placement=True`.\n            batch = {k: v.to(accelerator.device) for k, v in batch.items()}\n            with torch.no_grad():\n                outputs = net(batch)\n            val_preds_batch = torch.sigmoid(outputs)\n            val_y_batch = batch[\"target\"]\n            val_preds_batch, val_y_batch = accelerator.gather_for_metrics((val_preds_batch, val_y_batch))\n            val_preds.append(val_preds_batch.data.cpu().numpy().reshape(-1))\n            val_y.append(val_y_batch.data.cpu().numpy().reshape(-1))\n            \n        val_preds = np.concatenate(val_preds)\n        val_y = np.concatenate(val_y)\n        auc = compute_auc(val_y, val_preds) \n        pauc = compute_pauc(val_y, val_preds, min_tpr=0.80)\n        \n        if pauc >= best_pauc_score:\n            best_auc_score = auc\n            best_pauc_score = pauc\n            best_epoch = epoch\n            best_val_preds = val_preds\n        print(f\"Epoch pauc: {pauc} | Best auc: {best_auc_score} | Best pauc: {best_pauc_score} | Best epoch: {best_epoch}\")\n        \n        output_dir = f\"fold_{fold}/model_{cfg.model_name}_epoch_{epoch}\"\n        if cfg.models_output_dir is not None:\n            output_dir = Path(f\"{cfg.models_output_dir}/{output_dir}\")\n        accelerator.save_state(output_dir)\n    \n    best_num_epochs[f\"fold_{fold}\"] = best_epoch\n    val_auc_scores[f\"fold_{fold}\"] = best_auc_score\n    val_pauc_scores[f\"fold_{fold}\"] = best_pauc_score\n    \n    oof_predictions[val_index] = best_val_preds\n    print(\"\\n\")\n    break","metadata":{"execution":{"iopub.status.busy":"2024-07-10T19:12:25.137090Z","iopub.execute_input":"2024-07-10T19:12:25.137485Z","iopub.status.idle":"2024-07-10T19:12:32.119382Z","shell.execute_reply.started":"2024-07-10T19:12:25.137453Z","shell.execute_reply":"2024-07-10T19:12:32.117552Z"},"trusted":true},"execution_count":50,"outputs":[{"name":"stdout","text":"Running fold: 1\nDev data size: (16040, 57)\nVal data size: (4013, 57)\nReady to train\n","output_type":"stream"},{"name":"stderr","text":"0it [00:03, ?it/s]\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)","Cell \u001b[0;32mIn[50], line 49\u001b[0m\n\u001b[1;32m     45\u001b[0m batch \u001b[38;5;241m=\u001b[39m {k: v\u001b[38;5;241m.\u001b[39mto(accelerator\u001b[38;5;241m.\u001b[39mdevice) \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m batch\u001b[38;5;241m.\u001b[39mitems()}\n\u001b[1;32m     47\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m---> 49\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[43mnet\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     50\u001b[0m loss \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mbinary_cross_entropy_with_logits(outputs, batch[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtarget\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m1\u001b[39m))\n\u001b[1;32m     51\u001b[0m accelerator\u001b[38;5;241m.\u001b[39mbackward(loss)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n","Cell \u001b[0;32mIn[48], line 67\u001b[0m, in \u001b[0;36mISICNet.forward\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m     64\u001b[0m image \u001b[38;5;241m=\u001b[39m batch[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mimage\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m     65\u001b[0m image \u001b[38;5;241m=\u001b[39m image\u001b[38;5;241m.\u001b[39mfloat() \u001b[38;5;241m/\u001b[39m \u001b[38;5;241m255\u001b[39m\n\u001b[0;32m---> 67\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     68\u001b[0m bs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(image)\n\u001b[1;32m     69\u001b[0m pool \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39madaptive_avg_pool2d(x, \u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mreshape(bs,\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/timm/models/resnet.py:644\u001b[0m, in \u001b[0;36mResNet.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    643\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x: torch\u001b[38;5;241m.\u001b[39mTensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m torch\u001b[38;5;241m.\u001b[39mTensor:\n\u001b[0;32m--> 644\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward_features\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    645\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mforward_head(x)\n\u001b[1;32m    646\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m x\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/timm/models/resnet.py:634\u001b[0m, in \u001b[0;36mResNet.forward_features\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    632\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayer2(x)\n\u001b[1;32m    633\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayer3(x)\n\u001b[0;32m--> 634\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlayer4\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    635\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m x\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/container.py:215\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    213\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[1;32m    214\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[0;32m--> 215\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    216\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/timm/models/resnet.py:119\u001b[0m, in \u001b[0;36mBasicBlock.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    116\u001b[0m shortcut \u001b[38;5;241m=\u001b[39m x\n\u001b[1;32m    118\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconv1(x)\n\u001b[0;32m--> 119\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbn1\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    120\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdrop_block(x)\n\u001b[1;32m    121\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mact1(x)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/batchnorm.py:171\u001b[0m, in \u001b[0;36m_BatchNorm.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    164\u001b[0m     bn_training \u001b[38;5;241m=\u001b[39m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrunning_mean \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;129;01mand\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrunning_var \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m    166\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    167\u001b[0m \u001b[38;5;124;03mBuffers are only updated if they are to be tracked and we are in training mode. Thus they only need to be\u001b[39;00m\n\u001b[1;32m    168\u001b[0m \u001b[38;5;124;03mpassed when the update should occur (i.e. in training mode when they are tracked), or when buffer stats are\u001b[39;00m\n\u001b[1;32m    169\u001b[0m \u001b[38;5;124;03mused for normalization (i.e. in eval mode when buffers are not None).\u001b[39;00m\n\u001b[1;32m    170\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m--> 171\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbatch_norm\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    172\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    173\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# If buffers are not to be tracked, ensure that they won't be updated\u001b[39;49;00m\n\u001b[1;32m    174\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrunning_mean\u001b[49m\n\u001b[1;32m    175\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrack_running_stats\u001b[49m\n\u001b[1;32m    176\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    177\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrunning_var\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrack_running_stats\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    178\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    179\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    180\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbn_training\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    181\u001b[0m \u001b[43m    \u001b[49m\u001b[43mexponential_average_factor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    182\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    183\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/functional.py:2478\u001b[0m, in \u001b[0;36mbatch_norm\u001b[0;34m(input, running_mean, running_var, weight, bias, training, momentum, eps)\u001b[0m\n\u001b[1;32m   2475\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m training:\n\u001b[1;32m   2476\u001b[0m     _verify_batch_size(\u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39msize())\n\u001b[0;32m-> 2478\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbatch_norm\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2479\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrunning_mean\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrunning_var\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtraining\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmomentum\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meps\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackends\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcudnn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menabled\u001b[49m\n\u001b[1;32m   2480\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n","\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 72.00 MiB. GPU 0 has a total capacty of 15.89 GiB of which 41.12 MiB is free. Process 2724 has 15.85 GiB memory in use. Of the allocated memory 15.48 GiB is allocated by PyTorch, and 81.53 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"],"ename":"OutOfMemoryError","evalue":"CUDA out of memory. Tried to allocate 72.00 MiB. GPU 0 has a total capacty of 15.89 GiB of which 41.12 MiB is free. Process 2724 has 15.85 GiB memory in use. Of the allocated memory 15.48 GiB is allocated by PyTorch, and 81.53 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","output_type":"error"}]},{"cell_type":"code","source":"a = next(iter(dev_dataloader))","metadata":{"execution":{"iopub.status.busy":"2024-07-10T18:48:19.444896Z","iopub.execute_input":"2024-07-10T18:48:19.445525Z","iopub.status.idle":"2024-07-10T18:48:23.627011Z","shell.execute_reply.started":"2024-07-10T18:48:19.445490Z","shell.execute_reply":"2024-07-10T18:48:23.625656Z"},"trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"code","source":"a","metadata":{"execution":{"iopub.status.busy":"2024-07-10T18:48:28.261796Z","iopub.execute_input":"2024-07-10T18:48:28.262645Z","iopub.status.idle":"2024-07-10T18:48:28.285632Z","shell.execute_reply.started":"2024-07-10T18:48:28.262604Z","shell.execute_reply":"2024-07-10T18:48:28.284778Z"},"trusted":true},"execution_count":29,"outputs":[{"execution_count":29,"output_type":"execute_result","data":{"text/plain":"{'index': tensor([ 2350, 15414, 13373, 10416,  4991,  2901, 12102, 15483, 11463, 10048,\n          9345, 14708,  9903,  7172,  9658, 13044,  2521,  1352,  4372,  1940,\n         15880,  7643, 13040,  7385, 10210, 14400,  9433, 12534,  3589,  5844,\n          2507,  3714, 12036,  3258, 11688,  6212,  7210,  3391, 12508,  1136,\n         14370,   107,  9628,  4073,  6349, 10216, 13689, 11017,  3251, 12248,\n          1832,  6901, 12937,  9251,  4381,  1875,  6479,  3925,  1049,  8917,\n          7275,  7153,  3854, 15845, 15950,  9324,  6762,  2575,  8761,  6833,\n         15619, 13328,  7501,   883,  9683, 11186,  5151,   432,  2699,  4012,\n         15583,  2856,  4686, 14620,  5874, 12601, 12726, 10159,  3747, 11088,\n          6408,   670, 10228,  7010, 13306,  6325,  1021,  2605,  7330, 10949,\n         15685,  4031,  6529,  5371, 12842,  6658, 15819,  8607, 10946, 15179,\n         10567, 14991,  8351, 15246,  7604,   720,  6539, 15244, 11089, 12561,\n           540,  2947,  5796,  5620, 11055,  7239, 11343,  2998,  8188,  1127,\n          7654,   504, 14723,  2785, 14696,  4041,  7287, 12081, 15962,  1116,\n          3222, 15849,   499,  3835,  4198,  1553,    25,   261,  9709,  7420,\n         14760,  4468, 15943,   163,  6919, 13175, 10223, 13609,  1814, 14096,\n           535, 12350,  7740,  8666, 15434,     2,  7228,  6976, 10813,  1578,\n          7853,  8142, 13797, 14916,  1636,  9019,  8691,  1756, 14294, 10403,\n          8936,  2238,  6574,   127,  2618,  3200,  2858, 11595, 12086,  2045,\n         12321, 13033,  4905, 12955, 12452,  3875,  3410,  8513,  1892,  5200,\n         13219,  2789, 12177,  9210,  8853,  8338,  6861, 15259,  8717,  7812,\n          2811,  9418, 12554,  6308,  8181,  3921,  3070, 11808, 11279,  9106,\n           651, 15563,  9749,  5136, 11434,  8541,  5626,  1011,    78,  8485,\n           805,  5276, 14241,  7896,  6910, 13111, 10955, 13677,   866,  2021,\n         11641,   992,  3971,  2245,  4879,  2438,  7089, 14870,  9174,  4981,\n         14402,  8363, 13024, 11556,  4947, 15545]),\n 'image': tensor([[[[185, 185, 185,  ..., 163, 163, 163],\n           [185, 185, 185,  ..., 163, 163, 163],\n           [186, 186, 186,  ..., 162, 162, 162],\n           ...,\n           [158, 158, 160,  ..., 130, 128, 128],\n           [158, 158, 159,  ..., 130, 128, 128],\n           [158, 158, 159,  ..., 130, 128, 128]],\n \n          [[155, 155, 154,  ..., 128, 128, 128],\n           [155, 155, 155,  ..., 128, 128, 128],\n           [156, 156, 156,  ..., 127, 127, 127],\n           ...,\n           [116, 116, 118,  ..., 101,  98,  98],\n           [116, 116, 118,  ..., 100,  98,  98],\n           [116, 116, 118,  ..., 100,  98,  98]],\n \n          [[127, 127, 127,  ...,  98,  98,  98],\n           [127, 127, 127,  ...,  98,  98,  98],\n           [128, 128, 128,  ...,  98,  97,  97],\n           ...,\n           [ 91,  91,  93,  ...,  75,  72,  72],\n           [ 91,  91,  93,  ...,  74,  72,  72],\n           [ 91,  91,  93,  ...,  74,  72,  72]]],\n \n \n         [[[118, 118, 118,  ..., 118, 117, 117],\n           [118, 118, 118,  ..., 118, 117, 117],\n           [117, 117, 118,  ..., 119, 118, 118],\n           ...,\n           [107, 107, 106,  ..., 107, 108, 108],\n           [106, 106, 105,  ..., 106, 107, 107],\n           [106, 106, 106,  ..., 106, 107, 107]],\n \n          [[ 76,  76,  76,  ...,  82,  81,  81],\n           [ 76,  76,  76,  ...,  82,  81,  81],\n           [ 75,  75,  76,  ...,  83,  82,  82],\n           ...,\n           [ 65,  65,  65,  ...,  75,  75,  75],\n           [ 64,  64,  63,  ...,  74,  74,  74],\n           [ 64,  64,  63,  ...,  74,  74,  74]],\n \n          [[ 52,  52,  52,  ...,  60,  59,  59],\n           [ 52,  52,  52,  ...,  60,  59,  59],\n           [ 51,  51,  52,  ...,  60,  60,  60],\n           ...,\n           [ 43,  43,  42,  ...,  56,  57,  57],\n           [ 42,  42,  41,  ...,  56,  57,  57],\n           [ 42,  42,  41,  ...,  56,  57,  57]]],\n \n \n         [[[169, 169, 169,  ..., 158, 159, 159],\n           [169, 169, 169,  ..., 159, 159, 159],\n           [169, 169, 169,  ..., 161, 162, 162],\n           ...,\n           [169, 169, 167,  ..., 105, 103, 103],\n           [169, 169, 167,  ..., 105, 103, 103],\n           [169, 169, 167,  ..., 105, 103, 103]],\n \n          [[114, 114, 114,  ..., 108, 109, 110],\n           [114, 114, 114,  ..., 109, 110, 110],\n           [114, 114, 114,  ..., 111, 113, 113],\n           ...,\n           [108, 107, 105,  ...,  73,  71,  70],\n           [106, 106, 104,  ...,  74,  71,  70],\n           [106, 105, 104,  ...,  74,  71,  70]],\n \n          [[ 84,  84,  84,  ...,  80,  80,  80],\n           [ 84,  84,  84,  ...,  81,  81,  81],\n           [ 84,  84,  84,  ...,  83,  83,  83],\n           ...,\n           [ 89,  88,  86,  ...,  64,  62,  61],\n           [ 88,  88,  86,  ...,  64,  61,  61],\n           [ 88,  87,  86,  ...,  65,  62,  61]]],\n \n \n         ...,\n \n \n         [[[200, 200, 200,  ..., 192, 192, 192],\n           [200, 200, 200,  ..., 191, 192, 192],\n           [200, 200, 200,  ..., 192, 192, 192],\n           ...,\n           [185, 185, 185,  ..., 190, 189, 189],\n           [185, 185, 184,  ..., 190, 190, 190],\n           [185, 185, 185,  ..., 190, 190, 190]],\n \n          [[157, 157, 157,  ..., 151, 152, 152],\n           [157, 157, 157,  ..., 152, 152, 152],\n           [156, 156, 156,  ..., 152, 152, 152],\n           ...,\n           [142, 142, 142,  ..., 144, 143, 143],\n           [142, 142, 142,  ..., 144, 144, 144],\n           [142, 142, 142,  ..., 144, 144, 144]],\n \n          [[141, 141, 141,  ..., 142, 142, 142],\n           [141, 141, 141,  ..., 142, 142, 142],\n           [140, 140, 140,  ..., 142, 142, 142],\n           ...,\n           [126, 126, 126,  ..., 129, 129, 129],\n           [126, 126, 125,  ..., 129, 129, 129],\n           [126, 126, 126,  ..., 129, 129, 129]]],\n \n \n         [[[243, 243, 243,  ..., 243, 244, 244],\n           [243, 243, 243,  ..., 243, 244, 244],\n           [243, 243, 243,  ..., 244, 244, 244],\n           ...,\n           [229, 229, 229,  ..., 233, 233, 233],\n           [229, 229, 229,  ..., 233, 233, 233],\n           [229, 229, 229,  ..., 233, 233, 233]],\n \n          [[213, 213, 213,  ..., 212, 213, 213],\n           [213, 213, 213,  ..., 212, 213, 213],\n           [213, 213, 213,  ..., 213, 213, 213],\n           ...,\n           [197, 197, 197,  ..., 203, 203, 203],\n           [197, 197, 197,  ..., 203, 203, 203],\n           [197, 197, 197,  ..., 203, 203, 203]],\n \n          [[185, 185, 185,  ..., 184, 185, 185],\n           [185, 185, 185,  ..., 184, 185, 185],\n           [185, 185, 185,  ..., 185, 185, 185],\n           ...,\n           [172, 172, 172,  ..., 177, 177, 177],\n           [172, 172, 172,  ..., 177, 177, 177],\n           [172, 172, 172,  ..., 177, 177, 177]]],\n \n \n         [[[189, 189, 190,  ..., 194, 193, 193],\n           [189, 189, 190,  ..., 194, 193, 193],\n           [189, 189, 190,  ..., 194, 193, 193],\n           ...,\n           [201, 201, 201,  ..., 198, 198, 198],\n           [202, 202, 201,  ..., 198, 198, 198],\n           [202, 202, 201,  ..., 198, 198, 198]],\n \n          [[154, 154, 155,  ..., 156, 156, 156],\n           [154, 154, 155,  ..., 157, 156, 156],\n           [154, 154, 155,  ..., 157, 156, 156],\n           ...,\n           [166, 166, 166,  ..., 160, 160, 160],\n           [167, 167, 166,  ..., 160, 160, 160],\n           [167, 167, 166,  ..., 160, 160, 160]],\n \n          [[134, 134, 135,  ..., 137, 137, 137],\n           [134, 134, 135,  ..., 138, 137, 137],\n           [134, 134, 135,  ..., 138, 137, 137],\n           ...,\n           [147, 147, 147,  ..., 147, 147, 147],\n           [148, 148, 147,  ..., 147, 147, 147],\n           [148, 148, 147,  ..., 147, 147, 147]]]], dtype=torch.uint8),\n 'target': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])}"},"metadata":{}}]},{"cell_type":"code","source":"oof_preds_df = pd.DataFrame({\n    id_column: train_ids,\n    group_column: groups,\n    \"fold\": folds,\n    target_column: y_train,\n    f\"oof_{cfg.model_name}\": oof_predictions\n})\noof_preds_df.to_csv(f\"oof_preds_{cfg.model_name}.csv\")\noof_preds_df.head()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"best_num_epochs","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"val_auc_scores","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"val_pauc_scores","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cv_auc_oof = compute_auc(oof_preds_df[target_column], oof_preds_df[f\"oof_{cfg.model_name}\"])\ncv_pauc_oof = compute_pauc(oof_preds_df[target_column], oof_preds_df[f\"oof_{cfg.model_name}\"], min_tpr=0.8)\n\ncv_auc_avg = np.mean(list(val_auc_scores.values()))\ncv_pauc_avg = np.mean(list(val_pauc_scores.values()))","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(f\"CV AUC OOF: {cv_auc_oof}\")\nprint(f\"CV PAUC OOF: {cv_pauc_oof}\")\nprint(f\"CV AUC AVG: {cv_auc_avg}\")\nprint(f\"CV PAUC AVG: {cv_pauc_avg}\")","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"params = vars(cfg)\nparams = {k: v for k, v in params.items() if not k.startswith(\"_\")}\n\nmetadata = {\n    \"params\": params,\n    \"best_num_epochs\": best_num_epochs,\n    \"val_auc_scores\": val_auc_scores,\n    \"val_pauc_scores\": val_pauc_scores,\n    \"cv_auc_oof\": cv_auc_oof,\n    \"cv_pauc_oof\": cv_pauc_oof,\n    \"cv_auc_avg\": cv_auc_avg,\n    \"cv_pauc_avg\": cv_pauc_avg\n}\n\nwith open(\"run_metadata.json\", \"w\") as f:\n    json.dump(metadata, f)","metadata":{},"execution_count":null,"outputs":[]}]}