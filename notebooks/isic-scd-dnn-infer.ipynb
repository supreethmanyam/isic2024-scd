{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "485be96d",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2024-08-28T04:31:02.416696Z",
     "iopub.status.busy": "2024-08-28T04:31:02.416414Z",
     "iopub.status.idle": "2024-08-28T04:31:12.097223Z",
     "shell.execute_reply": "2024-08-28T04:31:12.096430Z"
    },
    "papermill": {
     "duration": 9.688788,
     "end_time": "2024-08-28T04:31:12.099487",
     "exception": false,
     "start_time": "2024-08-28T04:31:02.410699",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import gc\n",
    "import time\n",
    "import json\n",
    "import joblib\n",
    "from pprint import pprint\n",
    "from typing import List, Dict\n",
    "from collections import defaultdict\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import h5py\n",
    "from io import BytesIO\n",
    "from PIL import Image\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from timm import create_model\n",
    "\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "\n",
    "from accelerate import Accelerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0abeec4c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-28T04:31:12.110005Z",
     "iopub.status.busy": "2024-08-28T04:31:12.109495Z",
     "iopub.status.idle": "2024-08-28T04:31:12.114204Z",
     "shell.execute_reply": "2024-08-28T04:31:12.113383Z"
    },
    "papermill": {
     "duration": 0.011562,
     "end_time": "2024-08-28T04:31:12.116005",
     "exception": false,
     "start_time": "2024-08-28T04:31:12.104443",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_name = \"efficientnet_b2\"\n",
    "version = \"v3\"\n",
    "mode = \"pretrain\"\n",
    "path = f\"/kaggle/input/isic-scd-{model_name.replace('_', '-')}-{version}-{mode}\"\n",
    "\n",
    "SAMPLE_SIZE = 5000\n",
    "EXPECTED_TEST_SIZE = 500000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7f930302",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-28T04:31:12.125216Z",
     "iopub.status.busy": "2024-08-28T04:31:12.124925Z",
     "iopub.status.idle": "2024-08-28T04:31:12.128799Z",
     "shell.execute_reply": "2024-08-28T04:31:12.128076Z"
    },
    "papermill": {
     "duration": 0.010724,
     "end_time": "2024-08-28T04:31:12.130750",
     "exception": false,
     "start_time": "2024-08-28T04:31:12.120026",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "id_column = \"isic_id\"\n",
    "target_column = \"target\"\n",
    "group_column = \"patient_id\"\n",
    "fold_column = \"fold\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cb0e02a5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-28T04:31:12.140309Z",
     "iopub.status.busy": "2024-08-28T04:31:12.139995Z",
     "iopub.status.idle": "2024-08-28T04:31:12.193510Z",
     "shell.execute_reply": "2024-08-28T04:31:12.192840Z"
    },
    "papermill": {
     "duration": 0.060627,
     "end_time": "2024-08-28T04:31:12.195299",
     "exception": false,
     "start_time": "2024-08-28T04:31:12.134672",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "feature_mapping_dict = {\n",
    "    \"sex\": defaultdict(lambda: 0, {\n",
    "        \"missing_sex\": 0,\n",
    "        \"female\": 1,\n",
    "        \"male\": 2,\n",
    "    }),\n",
    "    \"anatom_site_general\": defaultdict(lambda: 0, {\n",
    "        \"missing_anatom_site_general\": 0,\n",
    "        \"lower extremity\": 1,\n",
    "        \"head/neck\": 2,\n",
    "        \"posterior torso\": 3,\n",
    "        \"anterior torso\": 4,\n",
    "        \"upper extremity\": 5,\n",
    "    }),\n",
    "    \"tbp_tile_type\": defaultdict(lambda: 0, {\n",
    "        \"3D: white\": 0,\n",
    "        \"3D: XP\": 1,\n",
    "    }),\n",
    "    \"tbp_lv_location\": defaultdict(lambda: 0, {\n",
    "        \"Unknown\": 0,\n",
    "        \"Right Leg - Upper\": 1,\n",
    "        \"Head & Neck\": 2,\n",
    "        \"Torso Back Top Third\": 3,\n",
    "        \"Torso Front Top Half\": 4,\n",
    "        \"Right Arm - Upper\": 5,\n",
    "        \"Left Leg - Upper\": 6,\n",
    "        \"Torso Front Bottom Half\": 7,\n",
    "        \"Left Arm - Upper\": 8,\n",
    "        \"Right Leg\": 9,\n",
    "        \"Torso Back Middle Third\": 10,\n",
    "        \"Right Arm - Lower\": 11,\n",
    "        \"Right Leg - Lower\": 12,\n",
    "        \"Left Leg - Lower\": 13,\n",
    "        \"Left Arm - Lower\": 14,\n",
    "        \"Left Leg\": 15,\n",
    "        \"Torso Back Bottom Third\": 16,\n",
    "        \"Left Arm\": 17,\n",
    "        \"Right Arm\": 18,\n",
    "        \"Torso Front\": 19,\n",
    "        \"Torso Back\": 20\n",
    "    }),\n",
    "    \"tbp_lv_location_simple\": defaultdict(lambda: 0, {\n",
    "        \"Unknown\": 0,\n",
    "        \"Right Leg\": 1,\n",
    "        \"Head & Neck\": 2,\n",
    "        \"Torso Back\": 3,\n",
    "        \"Torso Front\": 4,\n",
    "        \"Right Arm\": 5,\n",
    "        \"Left Leg\": 6,\n",
    "        \"Left Arm\": 7,\n",
    "    }),\n",
    "}\n",
    "\n",
    "\n",
    "def get_emb_szs(cat_cols):\n",
    "    emb_szs = {}\n",
    "    for col in cat_cols:\n",
    "        emb_szs[col] = (len(feature_mapping_dict[col]), min(600, round(1.6 * len(feature_mapping_dict[col]) ** 0.56)))\n",
    "    return emb_szs\n",
    "\n",
    "\n",
    "def cnn_norm_feature(df, value_col, group_cols, err=1e-5):\n",
    "    stats = [\"mean\", \"std\"]\n",
    "    tmp = df.groupby(group_cols)[value_col].agg(stats)\n",
    "    tmp.columns = [f\"{value_col}_{stat}\" for stat in stats]\n",
    "    tmp.reset_index(inplace=True)\n",
    "    df = df.merge(tmp, on=group_cols, how=\"left\")\n",
    "    feature_name = f\"{value_col}_patient_norm\"\n",
    "    df[feature_name] = ((df[value_col] - df[f\"{value_col}_mean\"]) / (df[f\"{value_col}_std\"] + err)).fillna(0)\n",
    "    return df, feature_name\n",
    "\n",
    "\n",
    "def cnn_feature_engineering(df):\n",
    "    df[\"age_approx\"] = df[\"age_approx\"].fillna(0)\n",
    "    df[\"age_approx\"] = df[\"age_approx\"] / 90\n",
    "    df[\"sex\"] = df[\"sex\"].fillna(\"missing_sex\")\n",
    "    df[\"sex\"] = df[\"sex\"].map(feature_mapping_dict[\"sex\"])\n",
    "    df[\"anatom_site_general\"] = df[\"anatom_site_general\"].fillna(\"missing_anatom_site_general\")\n",
    "    df[\"anatom_site_general\"] = df[\"anatom_site_general\"].map(feature_mapping_dict[\"anatom_site_general\"])\n",
    "    df[\"tbp_tile_type\"] = df[\"tbp_tile_type\"].map(feature_mapping_dict[\"tbp_tile_type\"])\n",
    "    df[\"tbp_lv_location\"] = df[\"tbp_lv_location\"].map(feature_mapping_dict[\"tbp_lv_location\"])\n",
    "    df[\"tbp_lv_location_simple\"] = df[\"tbp_lv_location_simple\"].map(feature_mapping_dict[\"tbp_lv_location_simple\"])\n",
    "\n",
    "    cat_cols = [\"sex\", \"anatom_site_general\",\n",
    "                \"tbp_tile_type\", \"tbp_lv_location\", \"tbp_lv_location_simple\"]\n",
    "\n",
    "    df[\"num_images\"] = df[\"patient_id\"].map(df.groupby(\"patient_id\")[\"isic_id\"].count())\n",
    "    df[\"num_images\"] = np.log1p(df[\"num_images\"])\n",
    "\n",
    "    cols_to_norm = [\n",
    "        \"age_approx\",\n",
    "        \"clin_size_long_diam_mm\",\n",
    "        \"tbp_lv_A\", \"tbp_lv_Aext\",\n",
    "        \"tbp_lv_B\", \"tbp_lv_Bext\",\n",
    "        \"tbp_lv_C\", \"tbp_lv_Cext\",\n",
    "        \"tbp_lv_H\", \"tbp_lv_Hext\",\n",
    "        \"tbp_lv_L\", \"tbp_lv_Lext\",\n",
    "        \"tbp_lv_areaMM2\", \"tbp_lv_area_perim_ratio\",\n",
    "        \"tbp_lv_color_std_mean\",\n",
    "        \"tbp_lv_deltaA\", \"tbp_lv_deltaB\", \"tbp_lv_deltaL\", \"tbp_lv_deltaLB\", \"tbp_lv_deltaLBnorm\",\n",
    "        \"tbp_lv_eccentricity\",\n",
    "        \"tbp_lv_minorAxisMM\", \"tbp_lv_nevi_confidence\", \"tbp_lv_norm_border\",\n",
    "        \"tbp_lv_norm_color\", \"tbp_lv_perimeterMM\",\n",
    "        \"tbp_lv_radial_color_std_max\", \"tbp_lv_stdL\", \"tbp_lv_stdLExt\",\n",
    "        \"tbp_lv_symm_2axis\", \"tbp_lv_symm_2axis_angle\",\n",
    "        \"tbp_lv_x\", \"tbp_lv_y\", \"tbp_lv_z\"\n",
    "    ]\n",
    "    cont_cols = cols_to_norm[:]\n",
    "    for col in cols_to_norm:\n",
    "        df, feature_name = cnn_norm_feature(df, col, [\"patient_id\"])\n",
    "        cont_cols += [feature_name]\n",
    "\n",
    "    df[\"num_images\"] = np.log1p(df[\"patient_id\"].map(df.groupby(\"patient_id\")[\"isic_id\"].count()))\n",
    "    cont_cols += [\"num_images\"]\n",
    "    assert df[cont_cols].isnull().sum().sum() == 0\n",
    "    return df, cat_cols, cont_cols\n",
    "\n",
    "def test_augment(image_size, mean=None, std=None):\n",
    "    if mean is not None and std is not None:\n",
    "        normalize = A.Normalize(mean=mean, std=std, max_pixel_value=255.0, p=1.0)\n",
    "    else:\n",
    "        normalize = A.Normalize(max_pixel_value=255.0, p=1.0)\n",
    "    transform = A.Compose(\n",
    "        [A.Resize(image_size, image_size), normalize, ToTensorV2()], p=1.0\n",
    "    )\n",
    "    return transform\n",
    "\n",
    "\n",
    "class ISICDataset(Dataset):\n",
    "    def __init__(self, metadata, images, augment,\n",
    "                 use_meta=False, cat_cols: List = None, cont_cols: List = None,\n",
    "                 infer=False):\n",
    "        self.metadata = metadata\n",
    "        self.images = images\n",
    "        self.augment = augment\n",
    "        self.use_meta = use_meta\n",
    "        self.cat_cols = cat_cols\n",
    "        self.cont_cols = cont_cols\n",
    "        self.length = len(self.metadata)\n",
    "        self.infer = infer\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.length\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        row = self.metadata.iloc[index]\n",
    "        image = np.array(Image.open(BytesIO(self.images[row[\"isic_id\"]][()])))\n",
    "        if self.augment is not None:\n",
    "            image = self.augment(image=image)[\"image\"].float()\n",
    "\n",
    "        if self.use_meta:\n",
    "            x_cat = torch.tensor([row[col] for col in self.cat_cols], dtype=torch.long)\n",
    "            x_cont = torch.tensor([row[col] for col in self.cont_cols], dtype=torch.float)\n",
    "        else:\n",
    "            x_cat = torch.tensor(0)\n",
    "            x_cont = torch.tensor(0)\n",
    "\n",
    "        if self.infer:\n",
    "            return image, x_cat, x_cont\n",
    "        else:\n",
    "            target = torch.tensor(row[\"target\"])\n",
    "            return image, x_cat, x_cont, target\n",
    "\n",
    "    \n",
    "class ISICNet(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        model_name,\n",
    "        pretrained=True,\n",
    "        use_meta=False,\n",
    "        cat_cols: List = None, cont_cols: List = None, emb_szs: Dict = None,\n",
    "    ):\n",
    "        super(ISICNet, self).__init__()\n",
    "        self.model = create_model(\n",
    "            model_name=model_name,\n",
    "            pretrained=pretrained,\n",
    "            in_chans=3,\n",
    "            num_classes=0,\n",
    "            global_pool=\"\",\n",
    "        )\n",
    "        in_dim = self.model.num_features\n",
    "        self.dropouts = nn.ModuleList([nn.Dropout(0.5) for _ in range(5)])\n",
    "        self.use_meta = use_meta\n",
    "        if use_meta:\n",
    "            self.linear = nn.Linear(in_dim, 256)\n",
    "\n",
    "            self.embeddings = nn.ModuleList([nn.Embedding(emb_szs[col][0], emb_szs[col][1]) for col in cat_cols])\n",
    "            self.embedding_dropout = nn.Dropout(0.1)\n",
    "            n_emb = sum([emb_szs[col][1] for col in cat_cols])\n",
    "            n_cont = len(cont_cols)\n",
    "            self.bn_cont = nn.BatchNorm1d(n_cont)\n",
    "            self.meta = nn.Sequential(\n",
    "                nn.Linear(n_emb + n_cont, 256),\n",
    "                nn.BatchNorm1d(256),\n",
    "                nn.SiLU(),\n",
    "                nn.Dropout(0.3),\n",
    "                nn.Linear(256, 64),\n",
    "                nn.BatchNorm1d(64),\n",
    "                nn.SiLU(),\n",
    "                nn.Dropout(0.1),\n",
    "            )\n",
    "            self.classifier = nn.Linear(256 + 64, 1)\n",
    "        else:\n",
    "            self.linear = nn.Linear(in_dim, 1)\n",
    "\n",
    "    def forward(self, images, x_cat=None, x_cont=None):\n",
    "        x = self.model(images)\n",
    "        bs = len(images)\n",
    "        pool = F.adaptive_avg_pool2d(x, 1).reshape(bs, -1)\n",
    "        if self.training:\n",
    "            x_image = 0\n",
    "            for i in range(len(self.dropouts)):\n",
    "                x_image += self.linear(self.dropouts[i](pool))\n",
    "            x_image = x_image / len(self.dropouts)\n",
    "        else:\n",
    "            x_image = self.linear(pool)\n",
    "\n",
    "        if self.use_meta:\n",
    "            x_cat = [emb(x_cat[:, i]) for i, emb in enumerate(self.embeddings)]\n",
    "            x_cat = torch.cat(x_cat, 1)\n",
    "            x_cat = self.embedding_dropout(x_cat)\n",
    "            x_cont = self.bn_cont(x_cont)\n",
    "            x_meta = self.meta(torch.cat([x_cat, x_cont], 1))\n",
    "            x = torch.cat([x_image, x_meta], 1)\n",
    "            logits = self.classifier(x)\n",
    "        else:\n",
    "            logits = x_image\n",
    "        return logits\n",
    "\n",
    "\n",
    "def get_trans(img, iteration):\n",
    "    if iteration >= 6:\n",
    "        img = img.transpose(2, 3)\n",
    "    if iteration % 6 == 0:\n",
    "        return img\n",
    "    elif iteration % 6 == 1:\n",
    "        return torch.flip(img, dims=[2])\n",
    "    elif iteration % 6 == 2:\n",
    "        return torch.flip(img, dims=[3])\n",
    "    elif iteration % 6 == 3:\n",
    "        return torch.rot90(img, 1, dims=[2, 3])\n",
    "    elif iteration % 6 == 4:\n",
    "        return torch.rot90(img, 2, dims=[2, 3])\n",
    "    elif iteration % 6 == 5:\n",
    "        return torch.rot90(img, 3, dims=[2, 3])\n",
    "\n",
    "    \n",
    "def predict(model, test_dataloader, accelerator, n_tta, use_meta, log_interval=10):\n",
    "    model.eval()\n",
    "    test_probs = []\n",
    "    total_steps = len(test_dataloader)\n",
    "    with torch.no_grad():\n",
    "        for step, (images, x_cat, x_cont) in enumerate(test_dataloader):\n",
    "            logits = 0\n",
    "            probs = 0\n",
    "            for i in range(n_tta):\n",
    "                if use_meta:\n",
    "                    logits_iter = model(get_trans(images, i), x_cat, x_cont)\n",
    "                else:\n",
    "                    logits_iter = model(get_trans(images, i))\n",
    "                logits += logits_iter\n",
    "                probs += torch.sigmoid(logits_iter)\n",
    "            logits /= n_tta\n",
    "            probs /= n_tta\n",
    "\n",
    "            probs = accelerator.gather(probs)\n",
    "            test_probs.append(probs)\n",
    "\n",
    "            if (step == 0) or ((step + 1) % log_interval == 0):\n",
    "                print(f\"Step: {step + 1}/{total_steps}\")\n",
    "\n",
    "    test_probs = torch.cat(test_probs).cpu().numpy()\n",
    "    return test_probs\n",
    "\n",
    "\n",
    "def get_dnn_predictions(train, test, images, model_name, version, path, oof_column):\n",
    "    start_time = time.time()\n",
    "    with open(path / f\"{model_name}_{version}_run_metadata.json\", \"r\") as f:\n",
    "        run_metadata = json.load(f)\n",
    "    pprint(run_metadata[\"params\"])\n",
    "    \n",
    "    image_size = run_metadata[\"params\"][\"image_size\"]\n",
    "    batch_size = run_metadata[\"params\"][\"val_batch_size\"]\n",
    "    use_meta = run_metadata[\"params\"][\"use_meta\"]\n",
    "    \n",
    "    test_dataset = ISICDataset(\n",
    "        test, images, augment=test_augment(image_size), \n",
    "        use_meta=use_meta,\n",
    "        cat_cols=cat_cols,\n",
    "        cont_cols=cont_cols,\n",
    "        infer=True\n",
    "    )\n",
    "    test_dataloader = DataLoader(\n",
    "        test_dataset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=False,\n",
    "        num_workers=4,\n",
    "        drop_last=False,\n",
    "        pin_memory=True,\n",
    "    )\n",
    "\n",
    "#     all_folds = np.unique(train[fold_column])\n",
    "    all_folds = [1, 5]\n",
    "    test_predictions_df = pd.DataFrame({id_column: test[id_column]})\n",
    "    for fold in all_folds:\n",
    "        print(f\"\\nFold {fold}\")\n",
    "        accelerator = Accelerator(\n",
    "            mixed_precision=run_metadata[\"params\"][\"mixed_precision\"],\n",
    "        )\n",
    "        \n",
    "        model = ISICNet(model_name=model_name, pretrained=False,\n",
    "                        use_meta=use_meta,\n",
    "                        cat_cols=cat_cols,\n",
    "                        cont_cols=cont_cols,\n",
    "                        emb_szs=emb_szs,)\n",
    "        model = model.to(accelerator.device)\n",
    "        \n",
    "        model, test_dataloader = accelerator.prepare(model, test_dataloader)\n",
    "        model_filepath = path / f\"models/fold_{fold}\"\n",
    "        accelerator.load_state(model_filepath)\n",
    "\n",
    "        test_predictions_df[f\"fold_{fold}\"] = predict(model, test_dataloader, accelerator, n_tta=run_metadata[\"params\"][\"n_tta\"], use_meta=use_meta)\n",
    "    test_predictions_df[oof_column] = test_predictions_df[[f\"fold_{fold}\" for fold in all_folds]].mean(axis=1)\n",
    "    end_time = time.time()\n",
    "    return test_predictions_df[[id_column, oof_column]], (end_time - start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7a0f1498",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-28T04:31:12.204386Z",
     "iopub.status.busy": "2024-08-28T04:31:12.204112Z",
     "iopub.status.idle": "2024-08-28T04:31:39.941719Z",
     "shell.execute_reply": "2024-08-28T04:31:39.940649Z"
    },
    "papermill": {
     "duration": 27.745051,
     "end_time": "2024-08-28T04:31:39.944323",
     "exception": false,
     "start_time": "2024-08-28T04:31:12.199272",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data size: (401059, 56)\n",
      "Test data size: (3, 44)\n",
      "Feature engineering...\n"
     ]
    }
   ],
   "source": [
    "INPUT_PATH = Path(\"../input/isic-2024-challenge/\")\n",
    "\n",
    "train_metadata = pd.read_csv(INPUT_PATH / \"train-metadata.csv\", low_memory=False)\n",
    "test_metadata = pd.read_csv(INPUT_PATH / \"test-metadata.csv\")\n",
    "\n",
    "folds_df = pd.read_csv(\"/kaggle/input/isic-scd-folds/folds.csv\")\n",
    "train_metadata = train_metadata.merge(folds_df, on=[id_column, group_column], how=\"inner\")\n",
    "print(f\"Train data size: {train_metadata.shape}\")\n",
    "print(f\"Test data size: {test_metadata.shape}\")\n",
    "\n",
    "train_images = h5py.File(INPUT_PATH / \"train-image.hdf5\", mode=\"r\")\n",
    "test_images = h5py.File(INPUT_PATH / \"test-image.hdf5\", mode=\"r\")\n",
    "\n",
    "print(f\"Feature engineering...\")\n",
    "train_metadata, cat_cols, cont_cols = cnn_feature_engineering(train_metadata)\n",
    "test_metadata, _, _ = cnn_feature_engineering(test_metadata)\n",
    "emb_szs = get_emb_szs(cat_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "53fca268",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-28T04:31:39.954262Z",
     "iopub.status.busy": "2024-08-28T04:31:39.953944Z",
     "iopub.status.idle": "2024-08-28T04:32:18.993924Z",
     "shell.execute_reply": "2024-08-28T04:32:18.992875Z"
    },
    "papermill": {
     "duration": 39.047155,
     "end_time": "2024-08-28T04:32:18.995944",
     "exception": false,
     "start_time": "2024-08-28T04:31:39.948789",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'debug': False,\n",
      " 'down_sampling': True,\n",
      " 'image_size': 128,\n",
      " 'init_lr': 3e-05,\n",
      " 'mixed_precision': 'fp16',\n",
      " 'mode': 'pretrain',\n",
      " 'n_tta': 8,\n",
      " 'num_epochs': 20,\n",
      " 'num_workers': 8,\n",
      " 'seed': 2022,\n",
      " 'train_batch_size': 64,\n",
      " 'use_meta': True,\n",
      " 'val_batch_size': 512}\n",
      "\n",
      "Fold 1\n",
      "Step: 1/10\n",
      "Step: 10/10\n",
      "\n",
      "Fold 5\n",
      "Step: 1/10\n",
      "Step: 10/10\n",
      "Expected total runtime during submission: 64 mins and 59.75414276123047 secs\n"
     ]
    }
   ],
   "source": [
    "if test_metadata.shape[0] == 3:\n",
    "    test_preds_df, total_runtime = get_dnn_predictions(\n",
    "        train_metadata, \n",
    "        train_metadata.sample(n=SAMPLE_SIZE, random_state=42), \n",
    "        train_images, \n",
    "        model_name, \n",
    "        version, \n",
    "        Path(path),\n",
    "        target_column\n",
    "    )\n",
    "else:\n",
    "    test_preds_df, total_runtime = get_dnn_predictions(\n",
    "        train_metadata, \n",
    "        test_metadata, \n",
    "        test_images, \n",
    "        model_name, \n",
    "        version, \n",
    "        Path(path),\n",
    "        target_column\n",
    "    )\n",
    "factor = EXPECTED_TEST_SIZE / SAMPLE_SIZE\n",
    "expected_total_runtime = total_runtime * factor\n",
    "total_runtime_minutes = int(expected_total_runtime // 60)\n",
    "total_runtime_seconds = expected_total_runtime % 60\n",
    "print(f\"Expected total runtime during submission: {total_runtime_minutes} mins and {total_runtime_seconds} secs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "361c0200",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-28T04:32:19.006917Z",
     "iopub.status.busy": "2024-08-28T04:32:19.006610Z",
     "iopub.status.idle": "2024-08-28T04:32:19.020991Z",
     "shell.execute_reply": "2024-08-28T04:32:19.020163Z"
    },
    "papermill": {
     "duration": 0.022159,
     "end_time": "2024-08-28T04:32:19.022800",
     "exception": false,
     "start_time": "2024-08-28T04:32:19.000641",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>isic_id</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>278442</th>\n",
       "      <td>ISIC_6973879</td>\n",
       "      <td>0.000061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>215021</th>\n",
       "      <td>ISIC_5407194</td>\n",
       "      <td>0.000015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>209685</th>\n",
       "      <td>ISIC_5273739</td>\n",
       "      <td>0.001036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29648</th>\n",
       "      <td>ISIC_0802250</td>\n",
       "      <td>0.000024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>323386</th>\n",
       "      <td>ISIC_8084953</td>\n",
       "      <td>0.000618</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             isic_id    target\n",
       "278442  ISIC_6973879  0.000061\n",
       "215021  ISIC_5407194  0.000015\n",
       "209685  ISIC_5273739  0.001036\n",
       "29648   ISIC_0802250  0.000024\n",
       "323386  ISIC_8084953  0.000618"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_preds_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b1b25326",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-28T04:32:19.033623Z",
     "iopub.status.busy": "2024-08-28T04:32:19.033364Z",
     "iopub.status.idle": "2024-08-28T04:32:19.043908Z",
     "shell.execute_reply": "2024-08-28T04:32:19.043085Z"
    },
    "papermill": {
     "duration": 0.018153,
     "end_time": "2024-08-28T04:32:19.045972",
     "exception": false,
     "start_time": "2024-08-28T04:32:19.027819",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    5000.000000\n",
       "mean        0.001794\n",
       "std         0.026877\n",
       "min         0.000002\n",
       "25%         0.000029\n",
       "50%         0.000068\n",
       "75%         0.000188\n",
       "max         0.999999\n",
       "Name: target, dtype: float64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_preds_df[target_column].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e7cd7f58",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-28T04:32:19.057508Z",
     "iopub.status.busy": "2024-08-28T04:32:19.056996Z",
     "iopub.status.idle": "2024-08-28T04:32:19.066210Z",
     "shell.execute_reply": "2024-08-28T04:32:19.065335Z"
    },
    "papermill": {
     "duration": 0.017136,
     "end_time": "2024-08-28T04:32:19.068314",
     "exception": false,
     "start_time": "2024-08-28T04:32:19.051178",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>isic_id</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>278442</th>\n",
       "      <td>ISIC_6973879</td>\n",
       "      <td>0.000061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>215021</th>\n",
       "      <td>ISIC_5407194</td>\n",
       "      <td>0.000015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>209685</th>\n",
       "      <td>ISIC_5273739</td>\n",
       "      <td>0.001036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29648</th>\n",
       "      <td>ISIC_0802250</td>\n",
       "      <td>0.000024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>323386</th>\n",
       "      <td>ISIC_8084953</td>\n",
       "      <td>0.000618</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             isic_id    target\n",
       "278442  ISIC_6973879  0.000061\n",
       "215021  ISIC_5407194  0.000015\n",
       "209685  ISIC_5273739  0.001036\n",
       "29648   ISIC_0802250  0.000024\n",
       "323386  ISIC_8084953  0.000618"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_preds_df[[id_column, target_column]].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f60b595c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-28T04:32:19.079736Z",
     "iopub.status.busy": "2024-08-28T04:32:19.079497Z",
     "iopub.status.idle": "2024-08-28T04:32:19.100356Z",
     "shell.execute_reply": "2024-08-28T04:32:19.099576Z"
    },
    "papermill": {
     "duration": 0.028854,
     "end_time": "2024-08-28T04:32:19.102382",
     "exception": false,
     "start_time": "2024-08-28T04:32:19.073528",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_preds_df[[id_column, target_column]].to_csv(\"submission.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bfb594c",
   "metadata": {
    "papermill": {
     "duration": 0.004908,
     "end_time": "2024-08-28T04:32:19.112854",
     "exception": false,
     "start_time": "2024-08-28T04:32:19.107946",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "databundleVersionId": 9094797,
     "sourceId": 63056,
     "sourceType": "competition"
    },
    {
     "datasetId": 5604316,
     "sourceId": 9262133,
     "sourceType": "datasetVersion"
    },
    {
     "sourceId": 187477024,
     "sourceType": "kernelVersion"
    },
    {
     "sourceId": 193130710,
     "sourceType": "kernelVersion"
    }
   ],
   "dockerImageVersionId": 30733,
   "isGpuEnabled": true,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 82.247699,
   "end_time": "2024-08-28T04:32:21.826779",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-08-28T04:30:59.579080",
   "version": "2.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
