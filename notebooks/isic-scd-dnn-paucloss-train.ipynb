{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":63056,"databundleVersionId":9094797,"sourceType":"competition"},{"sourceId":9114826,"sourceType":"datasetVersion","datasetId":5454133},{"sourceId":187477024,"sourceType":"kernelVersion"},{"sourceId":189656082,"sourceType":"kernelVersion"}],"dockerImageVersionId":30733,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"from timm import create_model\nimport torch","metadata":{"execution":{"iopub.status.busy":"2024-08-07T00:53:59.653544Z","iopub.execute_input":"2024-08-07T00:53:59.653889Z","iopub.status.idle":"2024-08-07T00:53:59.658197Z","shell.execute_reply.started":"2024-08-07T00:53:59.653863Z","shell.execute_reply":"2024-08-07T00:53:59.657226Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"from urllib.request import urlopen\nfrom PIL import Image\n\nimg = Image.open(urlopen(\n    'https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/beignets-task-guide.png'\n))","metadata":{"execution":{"iopub.status.busy":"2024-08-07T00:53:59.927542Z","iopub.execute_input":"2024-08-07T00:53:59.927884Z","iopub.status.idle":"2024-08-07T00:54:00.145518Z","shell.execute_reply.started":"2024-08-07T00:53:59.927859Z","shell.execute_reply":"2024-08-07T00:54:00.144578Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"model = create_model(\n    model_name=\"eva02_small_patch14_336\",\n#     model_name=\"resnet18\",\n    pretrained=True,\n    in_chans=3,\n    num_classes=0,\n#     global_pool=\"\",\n)","metadata":{"execution":{"iopub.status.busy":"2024-08-07T01:06:07.346889Z","iopub.execute_input":"2024-08-07T01:06:07.347274Z","iopub.status.idle":"2024-08-07T01:06:07.910660Z","shell.execute_reply.started":"2024-08-07T01:06:07.347245Z","shell.execute_reply":"2024-08-07T01:06:07.909699Z"},"trusted":true},"execution_count":93,"outputs":[]},{"cell_type":"code","source":"model","metadata":{"execution":{"iopub.status.busy":"2024-08-07T01:06:08.679463Z","iopub.execute_input":"2024-08-07T01:06:08.680152Z","iopub.status.idle":"2024-08-07T01:06:08.687023Z","shell.execute_reply.started":"2024-08-07T01:06:08.680117Z","shell.execute_reply":"2024-08-07T01:06:08.686116Z"},"trusted":true},"execution_count":94,"outputs":[{"execution_count":94,"output_type":"execute_result","data":{"text/plain":"Eva(\n  (patch_embed): PatchEmbed(\n    (proj): Conv2d(3, 384, kernel_size=(14, 14), stride=(14, 14))\n    (norm): Identity()\n  )\n  (pos_drop): Dropout(p=0.0, inplace=False)\n  (rope): RotaryEmbeddingCat()\n  (blocks): ModuleList(\n    (0-11): 12 x EvaBlock(\n      (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n      (attn): EvaAttention(\n        (qkv): Linear(in_features=384, out_features=1152, bias=False)\n        (attn_drop): Dropout(p=0.0, inplace=False)\n        (norm): Identity()\n        (proj): Linear(in_features=384, out_features=384, bias=True)\n        (proj_drop): Dropout(p=0.0, inplace=False)\n      )\n      (drop_path1): Identity()\n      (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n      (mlp): GluMlp(\n        (fc1): Linear(in_features=384, out_features=2048, bias=True)\n        (act): SiLU()\n        (drop1): Dropout(p=0.0, inplace=False)\n        (norm): Identity()\n        (fc2): Linear(in_features=1024, out_features=384, bias=True)\n        (drop2): Dropout(p=0.0, inplace=False)\n      )\n      (drop_path2): Identity()\n    )\n  )\n  (norm): Identity()\n  (fc_norm): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n  (head_drop): Dropout(p=0.0, inplace=False)\n  (head): Identity()\n)"},"metadata":{}}]},{"cell_type":"code","source":"img = torch.randn((3, 336, 336)).unsqueeze(0)","metadata":{"execution":{"iopub.status.busy":"2024-08-07T01:06:22.470760Z","iopub.execute_input":"2024-08-07T01:06:22.471470Z","iopub.status.idle":"2024-08-07T01:06:22.478054Z","shell.execute_reply.started":"2024-08-07T01:06:22.471441Z","shell.execute_reply":"2024-08-07T01:06:22.477294Z"},"trusted":true},"execution_count":95,"outputs":[]},{"cell_type":"code","source":"output = model(img)","metadata":{"execution":{"iopub.status.busy":"2024-08-07T01:06:25.384782Z","iopub.execute_input":"2024-08-07T01:06:25.385154Z","iopub.status.idle":"2024-08-07T01:06:25.627341Z","shell.execute_reply.started":"2024-08-07T01:06:25.385125Z","shell.execute_reply":"2024-08-07T01:06:25.626498Z"},"trusted":true},"execution_count":96,"outputs":[]},{"cell_type":"code","source":"output.shape","metadata":{"execution":{"iopub.status.busy":"2024-08-07T01:06:26.410557Z","iopub.execute_input":"2024-08-07T01:06:26.411400Z","iopub.status.idle":"2024-08-07T01:06:26.416944Z","shell.execute_reply.started":"2024-08-07T01:06:26.411366Z","shell.execute_reply":"2024-08-07T01:06:26.415993Z"},"trusted":true},"execution_count":97,"outputs":[{"execution_count":97,"output_type":"execute_result","data":{"text/plain":"torch.Size([1, 384])"},"metadata":{}}]},{"cell_type":"code","source":"bs = len(img)","metadata":{"execution":{"iopub.status.busy":"2024-08-07T01:04:35.980996Z","iopub.execute_input":"2024-08-07T01:04:35.981389Z","iopub.status.idle":"2024-08-07T01:04:35.985514Z","shell.execute_reply.started":"2024-08-07T01:04:35.981362Z","shell.execute_reply":"2024-08-07T01:04:35.984577Z"},"trusted":true},"execution_count":84,"outputs":[]},{"cell_type":"code","source":"bs","metadata":{"execution":{"iopub.status.busy":"2024-08-07T01:04:46.176760Z","iopub.execute_input":"2024-08-07T01:04:46.177570Z","iopub.status.idle":"2024-08-07T01:04:46.183127Z","shell.execute_reply.started":"2024-08-07T01:04:46.177538Z","shell.execute_reply":"2024-08-07T01:04:46.182107Z"},"trusted":true},"execution_count":85,"outputs":[{"execution_count":85,"output_type":"execute_result","data":{"text/plain":"1"},"metadata":{}}]},{"cell_type":"code","source":"import torch.nn.functional as F","metadata":{"execution":{"iopub.status.busy":"2024-08-07T01:04:47.725735Z","iopub.execute_input":"2024-08-07T01:04:47.726275Z","iopub.status.idle":"2024-08-07T01:04:47.730338Z","shell.execute_reply.started":"2024-08-07T01:04:47.726248Z","shell.execute_reply":"2024-08-07T01:04:47.729340Z"},"trusted":true},"execution_count":86,"outputs":[]},{"cell_type":"code","source":"# pool = F.adaptive_avg_pool2d(output, 1).reshape(bs, -1)","metadata":{"execution":{"iopub.status.busy":"2024-08-07T01:04:48.311640Z","iopub.execute_input":"2024-08-07T01:04:48.312308Z","iopub.status.idle":"2024-08-07T01:04:48.316099Z","shell.execute_reply.started":"2024-08-07T01:04:48.312278Z","shell.execute_reply":"2024-08-07T01:04:48.315110Z"},"trusted":true},"execution_count":87,"outputs":[]},{"cell_type":"code","source":"pool = F.adaptive_avg_pool1d(output, 1).reshape(bs, -1)","metadata":{"execution":{"iopub.status.busy":"2024-08-07T01:04:50.251221Z","iopub.execute_input":"2024-08-07T01:04:50.251893Z","iopub.status.idle":"2024-08-07T01:04:50.257959Z","shell.execute_reply.started":"2024-08-07T01:04:50.251866Z","shell.execute_reply":"2024-08-07T01:04:50.256973Z"},"trusted":true},"execution_count":88,"outputs":[]},{"cell_type":"code","source":"pool.shape","metadata":{"execution":{"iopub.status.busy":"2024-08-07T01:04:51.555665Z","iopub.execute_input":"2024-08-07T01:04:51.556027Z","iopub.status.idle":"2024-08-07T01:04:51.564766Z","shell.execute_reply.started":"2024-08-07T01:04:51.555998Z","shell.execute_reply":"2024-08-07T01:04:51.563818Z"},"trusted":true},"execution_count":89,"outputs":[{"execution_count":89,"output_type":"execute_result","data":{"text/plain":"torch.Size([1, 577])"},"metadata":{}}]},{"cell_type":"code","source":"img = torch.randn((3, ))","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install -q libauc","metadata":{"execution":{"iopub.status.busy":"2024-08-06T21:51:39.651501Z","iopub.execute_input":"2024-08-06T21:51:39.651861Z","iopub.status.idle":"2024-08-06T21:51:56.104924Z","shell.execute_reply.started":"2024-08-06T21:51:39.651826Z","shell.execute_reply":"2024-08-06T21:51:56.103696Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"from libauc.losses import pAUC_DRO_Loss","metadata":{"execution":{"iopub.status.busy":"2024-08-06T21:54:33.535305Z","iopub.execute_input":"2024-08-06T21:54:33.536045Z","iopub.status.idle":"2024-08-06T21:54:33.541314Z","shell.execute_reply.started":"2024-08-06T21:54:33.536007Z","shell.execute_reply":"2024-08-06T21:54:33.540162Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"criterion = pAUC_DRO_Loss(data_len=32, gamma=0.9, Lambda=1.0)","metadata":{"execution":{"iopub.status.busy":"2024-08-06T22:02:04.020704Z","iopub.execute_input":"2024-08-06T22:02:04.021134Z","iopub.status.idle":"2024-08-06T22:02:04.027099Z","shell.execute_reply.started":"2024-08-06T22:02:04.021101Z","shell.execute_reply":"2024-08-06T22:02:04.025962Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"import torch","metadata":{"execution":{"iopub.status.busy":"2024-08-06T22:02:05.075098Z","iopub.execute_input":"2024-08-06T22:02:05.075504Z","iopub.status.idle":"2024-08-06T22:02:05.080703Z","shell.execute_reply.started":"2024-08-06T22:02:05.075474Z","shell.execute_reply":"2024-08-06T22:02:05.079410Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"preds = torch.randn(32, 1, requires_grad=True).to(\"cuda\")","metadata":{"execution":{"iopub.status.busy":"2024-08-06T22:06:14.737647Z","iopub.execute_input":"2024-08-06T22:06:14.738094Z","iopub.status.idle":"2024-08-06T22:06:14.743900Z","shell.execute_reply.started":"2024-08-06T22:06:14.738061Z","shell.execute_reply":"2024-08-06T22:06:14.742788Z"},"trusted":true},"execution_count":36,"outputs":[]},{"cell_type":"code","source":"target = torch.tensor([0]*30 + [1]*2).long().to(\"cuda\")","metadata":{"execution":{"iopub.status.busy":"2024-08-06T22:06:14.893680Z","iopub.execute_input":"2024-08-06T22:06:14.894121Z","iopub.status.idle":"2024-08-06T22:06:14.900542Z","shell.execute_reply.started":"2024-08-06T22:06:14.894084Z","shell.execute_reply":"2024-08-06T22:06:14.899518Z"},"trusted":true},"execution_count":37,"outputs":[]},{"cell_type":"code","source":"index = torch.randint(32, (32,), requires_grad=False).to(\"cuda\")","metadata":{"execution":{"iopub.status.busy":"2024-08-06T22:06:15.452584Z","iopub.execute_input":"2024-08-06T22:06:15.453552Z","iopub.status.idle":"2024-08-06T22:06:15.459086Z","shell.execute_reply.started":"2024-08-06T22:06:15.453513Z","shell.execute_reply":"2024-08-06T22:06:15.457792Z"},"trusted":true},"execution_count":38,"outputs":[]},{"cell_type":"code","source":"loss = loss_fn(preds, target, index)","metadata":{"execution":{"iopub.status.busy":"2024-08-06T22:06:15.998978Z","iopub.execute_input":"2024-08-06T22:06:15.999386Z","iopub.status.idle":"2024-08-06T22:06:16.244867Z","shell.execute_reply.started":"2024-08-06T22:06:15.999349Z","shell.execute_reply":"2024-08-06T22:06:16.243712Z"},"trusted":true},"execution_count":39,"outputs":[]},{"cell_type":"code","source":"loss","metadata":{"execution":{"iopub.status.busy":"2024-08-06T22:06:19.091988Z","iopub.execute_input":"2024-08-06T22:06:19.092389Z","iopub.status.idle":"2024-08-06T22:06:19.202732Z","shell.execute_reply.started":"2024-08-06T22:06:19.092357Z","shell.execute_reply":"2024-08-06T22:06:19.201609Z"},"trusted":true},"execution_count":40,"outputs":[{"execution_count":40,"output_type":"execute_result","data":{"text/plain":"tensor(17.7397, device='cuda:0', grad_fn=<MeanBackward0>)"},"metadata":{}}]},{"cell_type":"code","source":"import json\nimport time\nfrom pathlib import Path\nfrom io import BytesIO\n\nimport albumentations as A\nimport h5py\nimport numpy as np\nimport pandas as pd\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom accelerate import Accelerator\nfrom accelerate.utils import (\n    DistributedDataParallelKwargs,\n    ProjectConfiguration,\n    set_seed,\n)\nfrom safetensors import safe_open\nfrom albumentations.pytorch import ToTensorV2\nfrom PIL import Image\nfrom sklearn.metrics import auc, roc_curve, roc_auc_score\nfrom timm import create_model\nfrom torch.utils.data import DataLoader, Dataset\nfrom libauc.sampler import DualSampler\nfrom libauc.losses import pAUCLoss\nfrom libauc.optimizers import SOPAs\n\nfrom isic_helper import DotDict, get_folds","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-08-06T06:59:15.231097Z","iopub.execute_input":"2024-08-06T06:59:15.231738Z","iopub.status.idle":"2024-08-06T06:59:15.239058Z","shell.execute_reply.started":"2024-08-06T06:59:15.231705Z","shell.execute_reply":"2024-08-06T06:59:15.238166Z"},"trusted":true},"execution_count":38,"outputs":[]},{"cell_type":"code","source":"def dev_augment(image_size):\n    transform = A.Compose(\n        [\n            A.Transpose(p=0.5),\n            A.VerticalFlip(p=0.5),\n            A.HorizontalFlip(p=0.5),\n            A.RandomBrightnessContrast(\n                brightness_limit=0.2, contrast_limit=0.2, p=0.75\n            ),\n            A.OneOf(\n                [\n                    A.MotionBlur(blur_limit=(5, 7)),\n                    A.MedianBlur(blur_limit=(5, 7)),\n                    A.GaussianBlur(blur_limit=(5, 7)),\n                    A.GaussNoise(var_limit=(5.0, 30.0)),\n                ],\n                p=0.7,\n            ),\n            A.OneOf(\n                [\n                    A.OpticalDistortion(distort_limit=1.0),\n                    A.GridDistortion(num_steps=5, distort_limit=1.0),\n                    A.ElasticTransform(alpha=3),\n                ],\n                p=0.7,\n            ),\n            A.CLAHE(clip_limit=4.0, p=0.7),\n            A.HueSaturationValue(\n                hue_shift_limit=10, sat_shift_limit=20, val_shift_limit=10, p=0.5\n            ),\n            A.ShiftScaleRotate(\n                shift_limit=0.1, scale_limit=0.1, rotate_limit=15, border_mode=0, p=0.85\n            ),\n            A.Resize(image_size, image_size),\n            A.CoarseDropout(\n                max_height=int(image_size * 0.375),\n                max_width=int(image_size * 0.375),\n                max_holes=1,\n                min_holes=1,\n                p=0.7,\n            ),\n            A.Normalize(),\n            ToTensorV2(),\n        ],\n        p=1.0,\n    )\n    return transform\n\n\ndef val_augment(image_size):\n    transform = A.Compose(\n        [A.Resize(image_size, image_size), A.Normalize(), ToTensorV2()], p=1.0\n    )\n    return transform\n\n\nclass ISICDataset(Dataset):\n    def __init__(self, metadata, images, augment, infer=False):\n        self.metadata = metadata\n        self.images = images\n        self.augment = augment\n        self.length = len(self.metadata)\n        self.infer = infer\n        \n        if not infer:\n            self.targets = metadata[\"target\"].values\n            # for loss function\n            self.pos_indices = np.flatnonzero(self.targets == 1)\n            self.pos_index_map = {}\n            for i, idx in enumerate(self.pos_indices):\n                self.pos_index_map[idx] = i\n\n    def __len__(self):\n        return self.length\n\n    def __getitem__(self, index):\n        row = self.metadata.iloc[index]\n        image = np.array(Image.open(BytesIO(self.images[row[\"isic_id\"]][()])))\n        if self.augment is not None:\n            image = self.augment(image=image)[\"image\"].float()\n        if self.infer:\n            return image, index\n        else:\n            label = torch.tensor(row[\"target\"]).float()\n            return image, label, index\n\n\nclass ISICNet(nn.Module):\n    def __init__(\n        self,\n        model_name,\n        pretrained=True\n    ):\n        super(ISICNet, self).__init__()\n        self.model = create_model(\n            model_name=model_name,\n            pretrained=pretrained,\n            in_chans=3,\n            num_classes=0,\n            global_pool=\"\",\n        )\n        in_dim = self.model.num_features\n        self.classifier = nn.Linear(in_dim, 1)\n        self.dropouts = nn.ModuleList([nn.Dropout(0.5) for _ in range(5)])\n\n    def forward(self, images):\n        x = self.model(images)\n        bs = len(images)\n        pool = F.adaptive_avg_pool2d(x, 1).reshape(bs, -1)\n        if self.training:\n            logits = 0\n            for i in range(len(self.dropouts)):\n                logits += self.classifier(self.dropouts[i](pool))\n            logits = logits / len(self.dropouts)\n        else:\n            logits = self.classifier(pool)\n        return logits\n\n    \ndef train_epoch(\n    epoch,\n    model,\n    optimizer,\n    criterion,\n    dev_dataloader,\n    lr_scheduler,\n    accelerator,\n    log_interval=100,\n):\n    model.train()\n    train_loss = []\n    total_steps = len(dev_dataloader)\n    for step, (images, labels, index) in enumerate(dev_dataloader):\n        optimizer.zero_grad()\n        logits = model(images)\n        probs = torch.sigmoid(logits)\n        loss = criterion(probs, labels.unsqueeze(1), index)\n        accelerator.backward(loss)\n        optimizer.step()\n#         lr_scheduler.step()\n\n        loss_value = accelerator.gather(loss).item()\n        train_loss.append(loss_value)\n        smooth_loss = sum(train_loss[-100:]) / min(len(train_loss), 100)\n        if (step == 0) or ((step + 1) % log_interval == 0):\n            print(\n                f\"Epoch: {epoch} | Step: {step + 1}/{total_steps} |\"\n                f\" Loss: {loss_value:.5f} | Smooth loss: {smooth_loss:.5f}\"\n            )\n    train_loss = np.mean(train_loss)\n    return train_loss\n\n\ndef get_trans(img, iteration):\n    if iteration >= 6:\n        img = img.transpose(2, 3)\n    if iteration % 6 == 0:\n        return img\n    elif iteration % 6 == 1:\n        return torch.flip(img, dims=[2])\n    elif iteration % 6 == 2:\n        return torch.flip(img, dims=[3])\n    elif iteration % 6 == 3:\n        return torch.rot90(img, 1, dims=[2, 3])\n    elif iteration % 6 == 4:\n        return torch.rot90(img, 2, dims=[2, 3])\n    elif iteration % 6 == 5:\n        return torch.rot90(img, 3, dims=[2, 3])\n\n\ndef val_epoch(\n    epoch,\n    model,\n    criterion,\n    val_dataloader,\n    accelerator,\n    n_tta,\n    log_interval=100,\n):\n    model.eval()\n    val_probs = []\n    val_labels = []\n    val_loss = []\n    total_steps = len(val_dataloader)\n    with torch.no_grad():\n        for step, (images, labels, index) in enumerate(val_dataloader):\n            logits = 0\n            probs = 0\n            for i in range(n_tta):\n                logits_iter = model(get_trans(images, i))\n                logits += logits_iter\n                probs += torch.sigmoid(logits_iter)\n            logits /= n_tta\n            probs /= n_tta\n\n            labels = labels.unsqueeze(1)\n            loss = criterion(probs, labels, index)\n            val_loss.append(loss.detach().cpu().numpy())\n\n            probs, labels = accelerator.gather((probs, labels))\n            val_probs.append(probs)\n            val_labels.append(labels)\n\n            if (step == 0) or ((step + 1) % log_interval == 0):\n                print(f\"Epoch: {epoch} | Step: {step + 1}/{total_steps}\")\n\n    val_loss = np.mean(val_loss)\n    val_probs = torch.cat(val_probs).cpu().numpy()\n    val_labels = torch.cat(val_labels).cpu().numpy()\n    val_auc = compute_auc(val_labels, val_probs)\n    val_pauc = compute_pauc(val_labels, val_probs, min_tpr=0.8)\n    return (\n        val_loss,\n        val_auc,\n        val_pauc,\n        val_probs,\n        val_labels\n    )\n\ndef compute_auc(y_true, y_pred) -> float:\n    \"\"\"\n    Compute the Area Under the Receiver Operating Characteristic Curve (ROC AUC).\n\n    Args:\n        y_true: ground truth of 1s and 0s\n        y_pred: predictions of scores ranging [0, 1]\n\n    Returns:\n        Float value range [0, 1]\n    \"\"\"\n    return roc_auc_score(y_true, y_pred)\n\n\ndef compute_pauc(y_true, y_pred, min_tpr: float = 0.80) -> float:\n    \"\"\"\n    2024 ISIC Challenge metric: pAUC\n\n    Given a solution file and submission file, this function returns the\n    partial area under the receiver operating characteristic (pAUC)\n    above a given true positive rate (TPR) = 0.80.\n    https://en.wikipedia.org/wiki/Partial_Area_Under_the_ROC_Curve.\n\n    (c) 2024 Nicholas R Kurtansky, MSKCC\n\n    Args:\n        min_tpr:\n        y_true: ground truth of 1s and 0s\n        y_pred: predictions of scores ranging [0, 1]\n\n    Returns:\n        Float value range [0, max_fpr]\n    \"\"\"\n\n    # rescale the target. set 0s to 1s and 1s to 0s (since sklearn only has max_fpr)\n    v_gt = abs(y_true - 1)\n\n    # flip the submissions to their compliments\n    v_pred = -1.0 * y_pred\n\n    max_fpr = abs(1 - min_tpr)\n\n    # using sklearn.metric functions: (1) roc_curve and (2) auc\n    fpr, tpr, _ = roc_curve(v_gt, v_pred, sample_weight=None)\n    if max_fpr is None or max_fpr == 1:\n        return auc(fpr, tpr)\n    if max_fpr <= 0 or max_fpr > 1:\n        raise ValueError(\"Expected min_tpr in range [0, 1), got: %r\" % min_tpr)\n\n    # Add a single point at max_fpr by linear interpolation\n    stop = np.searchsorted(fpr, max_fpr, \"right\")\n    x_interp = [fpr[stop - 1], fpr[stop]]\n    y_interp = [tpr[stop - 1], tpr[stop]]\n    tpr = np.append(tpr[:stop], np.interp(max_fpr, x_interp, y_interp))\n    fpr = np.append(fpr[:stop], max_fpr)\n    partial_auc = auc(fpr, tpr)\n\n    #     # Equivalent code that uses sklearn's roc_auc_score\n    #     v_gt = abs(np.asarray(solution.values)-1)\n    #     v_pred = np.array([1.0 - x for x in submission.values])\n    #     max_fpr = abs(1-min_tpr)\n    #     partial_auc_scaled = roc_auc_score(v_gt, v_pred, max_fpr=max_fpr)\n    #     # change scale from [0.5, 1.0] to [0.5 * max_fpr**2, max_fpr]\n    #     # https://math.stackexchange.com/questions/914823/shift-numbers-into-a-different-range\n    #     partial_auc = 0.5 * max_fpr**2 + (max_fpr - 0.5 * max_fpr**2) / (1.0 - 0.5) * (partial_auc_scaled - 0.5)\n\n    return partial_auc\n","metadata":{"execution":{"iopub.status.busy":"2024-08-06T07:02:18.609851Z","iopub.execute_input":"2024-08-06T07:02:18.610238Z","iopub.status.idle":"2024-08-06T07:02:18.649702Z","shell.execute_reply.started":"2024-08-06T07:02:18.610206Z","shell.execute_reply":"2024-08-06T07:02:18.648630Z"},"trusted":true},"execution_count":43,"outputs":[]},{"cell_type":"code","source":"INPUT_DIR = Path(\"/kaggle/input\")\nWEIGHTS_DIR = Path(\".\")\n\nargs = DotDict()\n\nargs.data_dir = INPUT_DIR / \"isic-2024-challenge\"\nargs.model_name = \"efficientnet_b0\"\nargs.version = \"v1\"\nargs.model_identifier = f\"deep_auc_{args.model_name}_{args.version}\"\nargs.model_dir = WEIGHTS_DIR / args.model_identifier\nargs.model_dir.mkdir(parents=True, exist_ok=True)\nargs.pretrained_model_dir = INPUT_DIR / f\"isic-scd-{args.model_name.replace('_', '-')}-{args.version}-train\"\nargs.logging_dir = \"logs\"\nargs.fold = 1\n\nargs.mixed_precision = \"fp16\"\nargs.image_size = 64\nargs.batch_size = 64\nargs.num_workers = 4\nargs.init_lr = 1e-3\nargs.gamma = 500\nargs.margin = 1.0\nargs.weight_decay = 1e-5\nargs.num_epochs = 10\nargs.n_tta: int = 6\nargs.seed = 2022\nargs.debug = True","metadata":{"execution":{"iopub.status.busy":"2024-08-06T06:47:47.823027Z","iopub.execute_input":"2024-08-06T06:47:47.823952Z","iopub.status.idle":"2024-08-06T06:47:47.831964Z","shell.execute_reply.started":"2024-08-06T06:47:47.823917Z","shell.execute_reply":"2024-08-06T06:47:47.830992Z"},"trusted":true},"execution_count":30,"outputs":[]},{"cell_type":"code","source":"train_metadata = pd.read_csv(args.data_dir / \"train-metadata.csv\", low_memory=False)\ntest_metadata = pd.read_csv(args.data_dir / \"test-metadata.csv\")\n\nfolds_df = get_folds()\ntrain_metadata = train_metadata.merge(folds_df, on=[\"isic_id\", \"patient_id\"], how=\"inner\")\nprint(f\"Train data size: {train_metadata.shape}\")\nprint(f\"Test data size: {test_metadata.shape}\")\n\ntrain_images = h5py.File(args.data_dir / \"train-image.hdf5\", mode=\"r\")\ntest_images = h5py.File(args.data_dir / \"test-image.hdf5\", mode=\"r\")","metadata":{"execution":{"iopub.status.busy":"2024-08-06T07:06:06.441696Z","iopub.execute_input":"2024-08-06T07:06:06.442085Z","iopub.status.idle":"2024-08-06T07:06:14.249403Z","shell.execute_reply.started":"2024-08-06T07:06:06.442050Z","shell.execute_reply":"2024-08-06T07:06:14.248340Z"},"trusted":true},"execution_count":49,"outputs":[{"name":"stdout","text":"Train data size: (401059, 57)\nTest data size: (3, 44)\n","output_type":"stream"}]},{"cell_type":"code","source":"if args.debug:\n    train_metadata = train_metadata.sample(frac=0.05, random_state=args.seed)","metadata":{"execution":{"iopub.status.busy":"2024-08-06T07:06:14.251163Z","iopub.execute_input":"2024-08-06T07:06:14.251492Z","iopub.status.idle":"2024-08-06T07:06:14.356017Z","shell.execute_reply.started":"2024-08-06T07:06:14.251465Z","shell.execute_reply":"2024-08-06T07:06:14.355247Z"},"trusted":true},"execution_count":50,"outputs":[]},{"cell_type":"code","source":"train_metadata[\"target\"].value_counts()","metadata":{"execution":{"iopub.status.busy":"2024-08-06T07:06:29.052763Z","iopub.execute_input":"2024-08-06T07:06:29.053501Z","iopub.status.idle":"2024-08-06T07:06:29.064873Z","shell.execute_reply.started":"2024-08-06T07:06:29.053467Z","shell.execute_reply":"2024-08-06T07:06:29.063921Z"},"trusted":true},"execution_count":51,"outputs":[{"execution_count":51,"output_type":"execute_result","data":{"text/plain":"target\n0    20040\n1       13\nName: count, dtype: int64"},"metadata":{}}]},{"cell_type":"code","source":"logging_dir = Path(args.model_dir, args.logging_dir)\naccelerator_project_config = ProjectConfiguration(\n    project_dir=args.model_dir, logging_dir=str(logging_dir)\n)\nkwargs = DistributedDataParallelKwargs()\naccelerator = Accelerator(\n    mixed_precision=args.mixed_precision,\n    project_config=accelerator_project_config,\n    kwargs_handlers=[kwargs],\n)\nprint(accelerator.state)\n\nif args.seed is not None:\n    set_seed(args.seed)\n\ndev_index = train_metadata[train_metadata[\"fold\"] != args.fold].index\nval_index = train_metadata[train_metadata[\"fold\"] == args.fold].index\n\ndev_metadata = train_metadata.loc[dev_index, :].reset_index(drop=True)\nval_metadata = train_metadata.loc[val_index, :].reset_index(drop=True)\n\ndev_dataset = ISICDataset(\n    dev_metadata, train_images, augment=dev_augment(args.image_size)\n)\nval_dataset = ISICDataset(\n    val_metadata, train_images, augment=val_augment(args.image_size)\n)\n\nsampling_rate = 0.5\nsampler = DualSampler(dev_dataset, args.batch_size, sampling_rate=sampling_rate)\n\ndev_dataloader = DataLoader(\n    dev_dataset,\n    batch_size=args.batch_size,\n    sampler=sampler,\n    num_workers=args.num_workers,\n)\nval_dataloader = DataLoader(\n    val_dataset,\n    batch_size=args.batch_size,\n    shuffle=False,\n    num_workers=args.num_workers,\n    drop_last=False,\n    pin_memory=True,\n)\n\nmodel = ISICNet(\n    model_name=args.model_name, pretrained=False,\n)\nmodel = model.to(accelerator.device)\n\ncriterion = pAUCLoss(\"1w\", data_len=len(dev_dataset), margin=args.margin, gamma=args.gamma)\noptimizer = SOPAs(model.parameters(), \n                 mode='adam',\n                 lr=args.init_lr, \n                 weight_decay=args.weight_decay)\nlr_scheduler = torch.optim.lr_scheduler.OneCycleLR(\n    optimizer,\n    pct_start=1 / args.num_epochs,\n    max_lr=args.init_lr * 10,\n    div_factor=10,\n    epochs=args.num_epochs,\n    steps_per_epoch=len(dev_dataloader),\n)\n\nmodel_filepath = args.pretrained_model_dir / f\"models/fold_{args.fold}/model.safetensors\"\ntensors = {}\nwith safe_open(model_filepath, framework=\"pt\", device=\"cpu\") as f:\n    for key in f.keys():\n        if \"classifier\" not in key:\n            tensors[key] = f.get_tensor(key)\nmsg = model.load_state_dict(tensors, strict=False)\nprint(msg)\nmodel.classifier.reset_parameters()\n\n(\n    model,\n    optimizer,\n    dev_dataloader,\n    val_dataloader,\n    lr_scheduler\n) = accelerator.prepare(\n    model, optimizer, dev_dataloader, val_dataloader, lr_scheduler\n)\n\nbest_val_auc = 0\nbest_val_pauc = 0\nbest_val_loss = 0\nbest_epoch = 0\nbest_val_probs = None\n\nfor epoch in range(1, args.num_epochs + 1):\n    print(f\"Fold {args.fold} | Epoch {epoch}\")\n    start_time = time.time()\n\n    train_loss = train_epoch(\n        epoch,\n        model,\n        optimizer,\n        criterion,\n        dev_dataloader,\n        lr_scheduler,\n        accelerator,\n    )\n    (\n        val_loss,\n        val_auc,\n        val_pauc,\n        val_probs,\n        val_targets,\n    ) = val_epoch(\n        epoch,\n        model,\n        criterion,\n        val_dataloader,\n        accelerator,\n        args.n_tta,\n    )\n\n    if val_pauc > best_val_pauc:\n        print(\n            f\"pAUC: {best_val_pauc:.5f} --> {val_pauc:.5f}, saving model...\"\n        )\n        best_val_pauc = val_pauc\n        best_val_auc = val_auc\n        best_val_loss = val_loss\n        best_epoch = epoch\n        best_val_probs = binary_probs\n        output_dir = f\"{args.model_dir}/models/fold_{args.fold}\"\n        accelerator.save_state(output_dir)\n    else:\n        print(\n            f\"pAUC: {best_val_pauc:.5f} --> {val_pauc:.5f}, skipping model save...\"\n        )\n    print(\n        f\"Fold: {args.fold} | Epoch: {epoch} |\"\n        f\" Train loss: {train_loss:.5f} | Val loss: {val_loss:.5f}\"\n        f\" Val AUC: {val_auc:.5f} | Val pAUC: {val_pauc:.5f}\"\n    )\n    elapsed_time = time.time() - start_time\n    elapsed_mins = int(elapsed_time // 60)\n    elapsed_secs = int(elapsed_time % 60)\n    print(f\"Epoch {epoch} took {elapsed_mins}m {elapsed_secs}s\")\n\nprint(\n    f\"Fold: {args.fold} | \"\n    f\"Best Val pAUC: {best_val_pauc} | Best AUC: {best_val_auc} |\"\n    f\" Best loss: {best_val_loss} |\"\n    f\" Best epoch: {best_epoch}\"\n)\noof_df = pd.DataFrame(\n    {\n        \"isic_id\": val_metadata[\"isic_id\"],\n        \"patient_id\": val_metadata[\"patient_id\"],\n        \"fold\": args.fold,\n        \"target\": val_metadata[\"target\"],\n        f\"oof_{args.model_identifier}\": best_val_probs,\n    }\n)\noof_df.to_csv(\n    f\"{args.model_dir}/oof_preds_{args.model_identifier}_fold_{args.fold}.csv\",\n    index=False,\n)\n\nfold_metadata = {\n    \"fold\": args.fold,\n    \"best_epoch\": best_epoch,\n    \"best_val_auc\": best_val_auc,\n    \"best_val_pauc\": best_val_pauc,\n    \"best_val_loss\": float(best_val_loss),\n}\nwith open(f\"{args.model_dir}/models/fold_{args.fold}/metadata.json\", \"w\") as f:\n    json.dump(fold_metadata, f)\nprint(f\"Finished training fold {args.fold}\")\n","metadata":{"execution":{"iopub.status.busy":"2024-08-06T07:06:38.090974Z","iopub.execute_input":"2024-08-06T07:06:38.091380Z","iopub.status.idle":"2024-08-06T07:06:38.679689Z","shell.execute_reply.started":"2024-08-06T07:06:38.091340Z","shell.execute_reply":"2024-08-06T07:06:38.677817Z"},"trusted":true},"execution_count":52,"outputs":[{"name":"stdout","text":"Distributed environment: NO\nNum processes: 1\nProcess index: 0\nLocal process index: 0\nDevice: cuda\n\nMixed precision type: fp16\n\n_IncompatibleKeys(missing_keys=['classifier.weight', 'classifier.bias'], unexpected_keys=[])\nFold 1 | Epoch 1\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","Cell \u001b[0;32mIn[52], line 96\u001b[0m\n\u001b[1;32m     93\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFold \u001b[39m\u001b[38;5;132;01m{\u001b[39;00margs\u001b[38;5;241m.\u001b[39mfold\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m | Epoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     94\u001b[0m start_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[0;32m---> 96\u001b[0m train_loss \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_epoch\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     97\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepoch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     98\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     99\u001b[0m \u001b[43m    \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    100\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    101\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdev_dataloader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    102\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlr_scheduler\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    103\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccelerator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    104\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    105\u001b[0m (\n\u001b[1;32m    106\u001b[0m     val_loss,\n\u001b[1;32m    107\u001b[0m     val_auc,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    117\u001b[0m     args\u001b[38;5;241m.\u001b[39mn_tta,\n\u001b[1;32m    118\u001b[0m )\n\u001b[1;32m    120\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m val_pauc \u001b[38;5;241m>\u001b[39m best_val_pauc:\n","Cell \u001b[0;32mIn[43], line 126\u001b[0m, in \u001b[0;36mtrain_epoch\u001b[0;34m(epoch, model, optimizer, criterion, dev_dataloader, lr_scheduler, accelerator, log_interval)\u001b[0m\n\u001b[1;32m    124\u001b[0m train_loss \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m    125\u001b[0m total_steps \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(dev_dataloader)\n\u001b[0;32m--> 126\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m step, (images, labels, index) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(dev_dataloader):\n\u001b[1;32m    127\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m    128\u001b[0m     logits \u001b[38;5;241m=\u001b[39m model(images)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/accelerate/data_loader.py:451\u001b[0m, in \u001b[0;36mDataLoaderShard.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    448\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbegin()\n\u001b[1;32m    450\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mset_epoch(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39miteration)\n\u001b[0;32m--> 451\u001b[0m dataloader_iter \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__iter__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    452\u001b[0m \u001b[38;5;66;03m# We iterate one batch ahead to check when we are at the end\u001b[39;00m\n\u001b[1;32m    453\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/utils/data/dataloader.py:438\u001b[0m, in \u001b[0;36mDataLoader.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    436\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iterator\n\u001b[1;32m    437\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 438\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_iterator\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/utils/data/dataloader.py:386\u001b[0m, in \u001b[0;36mDataLoader._get_iterator\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    384\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    385\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcheck_worker_number_rationality()\n\u001b[0;32m--> 386\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_MultiProcessingDataLoaderIter\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/utils/data/dataloader.py:1084\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter.__init__\u001b[0;34m(self, loader)\u001b[0m\n\u001b[1;32m   1082\u001b[0m _utils\u001b[38;5;241m.\u001b[39msignal_handling\u001b[38;5;241m.\u001b[39m_set_SIGCHLD_handler()\n\u001b[1;32m   1083\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_worker_pids_set \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m-> 1084\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_reset\u001b[49m\u001b[43m(\u001b[49m\u001b[43mloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfirst_iter\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/utils/data/dataloader.py:1117\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._reset\u001b[0;34m(self, loader, first_iter)\u001b[0m\n\u001b[1;32m   1115\u001b[0m \u001b[38;5;66;03m# prime the prefetch loop\u001b[39;00m\n\u001b[1;32m   1116\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_prefetch_factor \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_workers):\n\u001b[0;32m-> 1117\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_try_put_index\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/utils/data/dataloader.py:1351\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._try_put_index\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1348\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tasks_outstanding \u001b[38;5;241m<\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_prefetch_factor \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_workers\n\u001b[1;32m   1350\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1351\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_index\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1352\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m:\n\u001b[1;32m   1353\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/utils/data/dataloader.py:620\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter._next_index\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    619\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_index\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m--> 620\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sampler_iter\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/utils/data/sampler.py:282\u001b[0m, in \u001b[0;36mBatchSampler.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    280\u001b[0m batch \u001b[38;5;241m=\u001b[39m [\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatch_size\n\u001b[1;32m    281\u001b[0m idx_in_batch \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m--> 282\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msampler:\n\u001b[1;32m    283\u001b[0m     batch[idx_in_batch] \u001b[38;5;241m=\u001b[39m idx\n\u001b[1;32m    284\u001b[0m     idx_in_batch \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/libauc/sampler/sampler.py:227\u001b[0m, in \u001b[0;36mDualSampler.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    225\u001b[0m     np\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mshuffle(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpos_indices)\n\u001b[1;32m    226\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpos_ptr \u001b[38;5;241m=\u001b[39m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpos_ptr\u001b[38;5;241m+\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_pos)\u001b[38;5;241m%\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpos_len\n\u001b[0;32m--> 227\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msampled\u001b[49m\u001b[43m[\u001b[49m\u001b[43mstart_index\u001b[49m\u001b[43m:\u001b[49m\u001b[43mstart_index\u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnum_pos\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mconcatenate((temp, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpos_indices[:\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpos_ptr]))\n\u001b[1;32m    228\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    229\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msampled[start_index:start_index\u001b[38;5;241m+\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_pos]\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpos_indices[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpos_ptr:\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpos_ptr\u001b[38;5;241m+\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_pos]\n","\u001b[0;31mValueError\u001b[0m: could not broadcast input array from shape (20,) into shape (32,)"],"ename":"ValueError","evalue":"could not broadcast input array from shape (20,) into shape (32,)","output_type":"error"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}