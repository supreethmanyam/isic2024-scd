{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "04330b8d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-29T00:42:18.586071Z",
     "iopub.status.busy": "2024-08-29T00:42:18.585358Z",
     "iopub.status.idle": "2024-08-29T00:42:28.299931Z",
     "shell.execute_reply": "2024-08-29T00:42:28.299140Z"
    },
    "papermill": {
     "duration": 9.725199,
     "end_time": "2024-08-29T00:42:28.302218",
     "exception": false,
     "start_time": "2024-08-29T00:42:18.577019",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import gc\n",
    "import time\n",
    "import json\n",
    "import joblib\n",
    "from pprint import pprint\n",
    "from typing import List, Dict\n",
    "from collections import defaultdict\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import h5py\n",
    "from io import BytesIO\n",
    "from PIL import Image\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from timm import create_model\n",
    "\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "\n",
    "from accelerate import Accelerator\n",
    "\n",
    "from isic_helper import DotDict\n",
    "from isic_multi_predict import main as get_dnn_multi_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "23b43123",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-29T00:42:28.317059Z",
     "iopub.status.busy": "2024-08-29T00:42:28.316265Z",
     "iopub.status.idle": "2024-08-29T00:42:28.320999Z",
     "shell.execute_reply": "2024-08-29T00:42:28.320135Z"
    },
    "papermill": {
     "duration": 0.014088,
     "end_time": "2024-08-29T00:42:28.323023",
     "exception": false,
     "start_time": "2024-08-29T00:42:28.308935",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "id_column = \"isic_id\"\n",
    "target_column = \"target\"\n",
    "group_column = \"patient_id\"\n",
    "\n",
    "INPUT_PATH = Path(\"/kaggle/input/isic-2024-challenge/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "55807402",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-29T00:42:28.337125Z",
     "iopub.status.busy": "2024-08-29T00:42:28.336822Z",
     "iopub.status.idle": "2024-08-29T00:42:28.347435Z",
     "shell.execute_reply": "2024-08-29T00:42:28.346580Z"
    },
    "papermill": {
     "duration": 0.019943,
     "end_time": "2024-08-29T00:42:28.349352",
     "exception": false,
     "start_time": "2024-08-29T00:42:28.329409",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "cnn_model_names = []\n",
    "cnn_versions = []\n",
    "cnn_modes = []\n",
    "cnn_paths = [f\"/kaggle/input/isic-scd-{model_name.replace('_', '-')}-{version}-{mode}\" for model_name, version, mode in zip(cnn_model_names, cnn_versions, cnn_modes)]\n",
    "\n",
    "all_cnn_oof_columns = []\n",
    "for idx, path in enumerate(cnn_paths):\n",
    "    model_name = cnn_model_names[idx]\n",
    "    version = cnn_versions[idx]\n",
    "    mode = cnn_modes[idx]\n",
    "    cnn_oof_train_preds_model_df = pd.read_csv(f\"{path}/oof_preds_{model_name}_{version}.csv\")\n",
    "    cnn_oof_columns = [col for col in cnn_oof_train_preds_model_df if col.startswith(\"oof_\")]\n",
    "    all_cnn_oof_columns += cnn_oof_columns\n",
    "    if idx == 0:\n",
    "        cnn_oof_train_preds_df = cnn_oof_train_preds_model_df[[id_column] + cnn_oof_columns].copy()\n",
    "    else:\n",
    "        cnn_oof_train_preds_df = cnn_oof_train_preds_df.merge(cnn_oof_train_preds_model_df[[id_column] + cnn_oof_columns], on=id_column, how=\"left\")\n",
    "        assert cnn_oof_train_preds_df.shape[0] == cnn_oof_train_preds_model_df.shape[0]\n",
    "    \n",
    "    with open(f\"{path}/{model_name}_{version}_run_metadata.json\", \"r\") as f:\n",
    "        run_metadata = json.load(f)\n",
    "    mixed_precision = run_metadata[\"params\"][\"mixed_precision\"]\n",
    "    image_size = run_metadata[\"params\"][\"image_size\"]\n",
    "    batch_size = run_metadata[\"params\"][\"val_batch_size\"]\n",
    "    n_tta = run_metadata[\"params\"][\"n_tta\"]\n",
    "\n",
    "    cnn_oof_test_preds_model_df, _ = get_dnn_multi_predictions(model_name, version, path, \n",
    "                                                               mixed_precision, image_size, batch_size, n_tta)\n",
    "    if idx == 0:\n",
    "        cnn_oof_test_preds_df = cnn_oof_test_preds_model_df[[id_column] + cnn_oof_columns].copy()\n",
    "    else:\n",
    "        cnn_oof_test_preds_df = cnn_oof_test_preds_df.merge(cnn_oof_test_preds_model_df[[id_column] + cnn_oof_columns], on=id_column, how=\"left\")\n",
    "    assert cnn_oof_test_preds_df.shape[0] == cnn_oof_test_preds_model_df.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4bc322aa",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-29T00:42:28.363160Z",
     "iopub.status.busy": "2024-08-29T00:42:28.362848Z",
     "iopub.status.idle": "2024-08-29T00:42:28.369770Z",
     "shell.execute_reply": "2024-08-29T00:42:28.368916Z"
    },
    "papermill": {
     "duration": 0.016092,
     "end_time": "2024-08-29T00:42:28.371681",
     "exception": false,
     "start_time": "2024-08-29T00:42:28.355589",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "boosting_model_names = [\"xgb\"]\n",
    "boosting_versions = [\"v5\"]\n",
    "boosting_modes = [\"train\"]\n",
    "boosting_oof_columns = [f\"oof_{model_name}_{version}\" for model_name, version in zip(boosting_model_names, boosting_versions)]\n",
    "boosting_paths = [f\"/kaggle/input/isic-scd-{model_name.replace('_', '-')}-{version}-{mode}\" for model_name, version, mode in zip(\n",
    "    boosting_model_names, boosting_versions, boosting_modes)]\n",
    "\n",
    "cnn_model_names = []\n",
    "cnn_versions = []\n",
    "cnn_modes = []\n",
    "cnn_oof_columns = [f\"oof_{model_name}_{version}\" for model_name, version in zip(cnn_model_names, cnn_versions)]\n",
    "cnn_paths = [f\"/kaggle/input/isic-scd-{model_name.replace('_', '-')}-{version}-{mode}\" for model_name, version, mode in zip(\n",
    "    cnn_model_names, cnn_versions, cnn_modes)]\n",
    "\n",
    "blend_oof_columns = boosting_oof_columns + cnn_oof_columns\n",
    "\n",
    "weights = [1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "aa573682",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-29T00:42:28.386248Z",
     "iopub.status.busy": "2024-08-29T00:42:28.385907Z",
     "iopub.status.idle": "2024-08-29T00:42:28.404829Z",
     "shell.execute_reply": "2024-08-29T00:42:28.404070Z"
    },
    "papermill": {
     "duration": 0.028926,
     "end_time": "2024-08-29T00:42:28.406938",
     "exception": false,
     "start_time": "2024-08-29T00:42:28.378012",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "ord_categorical_features = [\n",
    "    \"sex\",\n",
    "    \"tbp_lv_location\",\n",
    "    \"tbp_tile_type\",\n",
    "    \"tbp_lv_location_simple\",\n",
    "]\n",
    "\n",
    "ohe_categorical_features = [\n",
    "    \"anatom_site_general\", \n",
    "    \"attribution\",\n",
    "]\n",
    "\n",
    "attribution_mapper = {\n",
    "    \"Memorial Sloan Kettering Cancer Center\": \"MSKCC\",\n",
    "    \"ACEMID MIA\": \"ACEMIDMIA\",\n",
    "    \"Department of Dermatology, Hospital ClÃ­nic de Barcelona\": \"DoD_HCB\",\n",
    "    \"University Hospital of Basel\": \"UHB\",\n",
    "    \"Frazer Institute, The University of Queensland, Dermatology Research Centre\": \"FI_TUQ-DRC\",\n",
    "    \"Department of Dermatology, University of Athens, Andreas Syggros Hospital of Skin and Venereal Diseases, Alexander Stratigos, Konstantinos Liopyris\": \"DoD_UA\",\n",
    "    \"ViDIR Group, Department of Dermatology, Medical University of Vienna\": \"ViDIR\"\n",
    "}\n",
    "\n",
    "def boosting_norm_feature(df, value_col, group_cols, err=1e-5):\n",
    "    stats = [\"mean\", \"std\"]\n",
    "    tmp = df.groupby(group_cols)[value_col].agg(stats)\n",
    "    tmp.columns = [f\"{value_col}_{stat}\" for stat in stats]\n",
    "    tmp.reset_index(inplace=True)\n",
    "    df = df.merge(tmp, on=group_cols, how=\"left\")\n",
    "    feature_name = f\"{value_col}_patient_norm\"\n",
    "    df[feature_name] = ((df[value_col] - df[f\"{value_col}_mean\"]) / \n",
    "                                       (df[f\"{value_col}_std\"] + err))\n",
    "    return df, feature_name\n",
    "\n",
    "def boosting_feature_engineering(df):\n",
    "    df[\"sex\"] = df[\"sex\"].fillna(\"missing_sex\")\n",
    "    df[\"anatom_site_general\"] = df[\"anatom_site_general\"].fillna(\"missing_anatom_site_general\")\n",
    "    df[\"tbp_tile_type\"] = df[\"tbp_tile_type\"].map({\"3D: white\": \"white\", \"3D: XP\": \"XP\"})\n",
    "    df[\"attribution\"] = df[\"attribution\"].map(attribution_mapper)\n",
    "\n",
    "    cols_to_norm = [\n",
    "        \"age_approx\",\n",
    "        \"clin_size_long_diam_mm\",\n",
    "        \"tbp_lv_A\", \"tbp_lv_Aext\",\n",
    "        \"tbp_lv_B\", \"tbp_lv_Bext\",\n",
    "        \"tbp_lv_C\", \"tbp_lv_Cext\",\n",
    "        \"tbp_lv_H\", \"tbp_lv_Hext\",\n",
    "        \"tbp_lv_L\", \"tbp_lv_Lext\",\n",
    "        \"tbp_lv_areaMM2\", \"tbp_lv_area_perim_ratio\",\n",
    "        \"tbp_lv_color_std_mean\",\n",
    "        \"tbp_lv_deltaA\", \"tbp_lv_deltaB\", \"tbp_lv_deltaL\", \"tbp_lv_deltaLB\", \"tbp_lv_deltaLBnorm\",\n",
    "        \"tbp_lv_eccentricity\",\n",
    "        \"tbp_lv_minorAxisMM\", \"tbp_lv_nevi_confidence\", \"tbp_lv_norm_border\",\n",
    "        \"tbp_lv_norm_color\", \"tbp_lv_perimeterMM\",\n",
    "        \"tbp_lv_radial_color_std_max\", \"tbp_lv_stdL\", \"tbp_lv_stdLExt\",\n",
    "        \"tbp_lv_symm_2axis\", \"tbp_lv_symm_2axis_angle\",\n",
    "        \"tbp_lv_x\", \"tbp_lv_y\", \"tbp_lv_z\"\n",
    "    ]\n",
    "    numerical_features = cols_to_norm[:]\n",
    "    for col in cols_to_norm:\n",
    "        df, feature_name = boosting_norm_feature(df, col, [\"patient_id\"])\n",
    "        numerical_features += [feature_name]\n",
    "    \n",
    "    df[\"num_images\"] = df[\"patient_id\"].map(df.groupby(\"patient_id\")[\"isic_id\"].count())\n",
    "    numerical_features += [\"num_images\"]\n",
    "    return df, numerical_features\n",
    "\n",
    "\n",
    "# class PAUC:\n",
    "#     def get_final_error(self, error, weight):\n",
    "#         return error\n",
    "\n",
    "#     def is_max_optimal(self):\n",
    "#         return True\n",
    "\n",
    "#     def evaluate(self, approxes, target, weight):\n",
    "#         y_true = target.astype(int)\n",
    "#         y_pred = approxes[0].astype(float)\n",
    "        \n",
    "#         score = compute_pauc(y_true, y_pred, min_tpr=0.8)\n",
    "        \n",
    "#         return score, 1.0\n",
    "\n",
    "\n",
    "def pauc_80(y_train, y_pred):\n",
    "    score_value = compute_pauc(y_train, y_pred, min_tpr=0.8)   \n",
    "    return score_value\n",
    "\n",
    "\n",
    "def get_boosting_predictions(train, test, model_name, version, path, oof_column):\n",
    "    start_time = time.time()\n",
    "    with open(path / f\"{model_name}_{version}_run_metadata.json\", \"r\") as f:\n",
    "        run_metadata = json.load(f)\n",
    "    pprint(run_metadata)\n",
    "    fold_column = run_metadata[\"config\"][\"fold_column\"]\n",
    "    \n",
    "    with open(path / f\"{model_name}_{version}_encoder.joblib\", \"rb\") as f:\n",
    "        mixed_encoded_preprocessor = joblib.load(f)\n",
    "\n",
    "    enc = mixed_encoded_preprocessor.fit(train)\n",
    "    X_test = enc.transform(test)\n",
    "\n",
    "    columns_for_model = len(X_test.columns)\n",
    "    print(f\"Total number of columns: {columns_for_model}\")\n",
    "        \n",
    "    all_folds = np.unique(train[fold_column])\n",
    "#     all_folds = [1]\n",
    "    test_predictions_df = pd.DataFrame({id_column: test[id_column]})\n",
    "    for fold in all_folds:\n",
    "        model_filepath = path / f\"models/{model_name}_{version}_fold_{fold}.txt\"\n",
    "        with open(model_filepath, \"rb\") as f:\n",
    "            estimator = joblib.load(f)\n",
    "        test_predictions_df[f\"fold_{fold}\"] = estimator.predict_proba(X_test)[:, -1]\n",
    "    test_predictions_df[oof_column] = test_predictions_df[[f\"fold_{fold}\" for fold in all_folds]].mean(axis=1)\n",
    "    end_time = time.time()\n",
    "    return test_predictions_df[[id_column, oof_column]], (end_time - start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "90971420",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-29T00:42:28.422231Z",
     "iopub.status.busy": "2024-08-29T00:42:28.421881Z",
     "iopub.status.idle": "2024-08-29T00:42:55.482582Z",
     "shell.execute_reply": "2024-08-29T00:42:55.481609Z"
    },
    "papermill": {
     "duration": 27.070422,
     "end_time": "2024-08-29T00:42:55.484916",
     "exception": false,
     "start_time": "2024-08-29T00:42:28.414494",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data size: (401059, 58)\n",
      "Test data size: (3, 44)\n"
     ]
    }
   ],
   "source": [
    "train_metadata = pd.read_csv(INPUT_PATH / \"train-metadata.csv\", low_memory=False, na_values=[\"NA\"])\n",
    "test_metadata = pd.read_csv(INPUT_PATH / \"test-metadata.csv\", low_memory=False, na_values=[\"NA\"])\n",
    "\n",
    "folds_df = pd.read_csv(\"/kaggle/input/isic-scd-folds/folds.csv\")\n",
    "train_metadata = train_metadata.merge(folds_df, on=[id_column, group_column], how=\"inner\")\n",
    "print(f\"Train data size: {train_metadata.shape}\")\n",
    "print(f\"Test data size: {test_metadata.shape}\")\n",
    "\n",
    "train_metadata, numerical_features = boosting_feature_engineering(train_metadata)\n",
    "test_metadata, _ = boosting_feature_engineering(test_metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9359bea7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-29T00:42:55.499039Z",
     "iopub.status.busy": "2024-08-29T00:42:55.498725Z",
     "iopub.status.idle": "2024-08-29T00:42:55.503348Z",
     "shell.execute_reply": "2024-08-29T00:42:55.502489Z"
    },
    "papermill": {
     "duration": 0.013801,
     "end_time": "2024-08-29T00:42:55.505341",
     "exception": false,
     "start_time": "2024-08-29T00:42:55.491540",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if all_cnn_oof_columns:\n",
    "    train_metadata = train_metadata.merge(cnn_oof_train_preds_df, on=id_column, how=\"left\")\n",
    "    test_metadata = test_metadata.merge(cnn_oof_test_preds_df, on=id_column, how=\"left\")\n",
    "    numerical_features += all_oof_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b0214e36",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-29T00:42:55.519208Z",
     "iopub.status.busy": "2024-08-29T00:42:55.518824Z",
     "iopub.status.idle": "2024-08-29T00:42:56.880739Z",
     "shell.execute_reply": "2024-08-29T00:42:56.879426Z"
    },
    "papermill": {
     "duration": 1.371512,
     "end_time": "2024-08-29T00:42:56.883048",
     "exception": false,
     "start_time": "2024-08-29T00:42:55.511536",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating predictions for xgb_v5\n",
      "{'best_num_rounds': {'fold_1': 193,\n",
      "                     'fold_2': 156,\n",
      "                     'fold_3': 154,\n",
      "                     'fold_4': 64,\n",
      "                     'fold_5': 65},\n",
      " 'config': {'_key': None,\n",
      "            '_parent': None,\n",
      "            '_temp': False,\n",
      "            'fold_column': 'tsgkf_fold',\n",
      "            'model_name': 'xgb_v5',\n",
      "            'models_output_dir': 'models',\n",
      "            'sampling_ratio': 0.005,\n",
      "            'seed': 2022},\n",
      " 'cv_auc_avg': 0.9664094500182616,\n",
      " 'cv_auc_oof': 0.9586841915843708,\n",
      " 'cv_auc_std': 0.007714971601090204,\n",
      " 'cv_pauc_avg': 0.17330312295178082,\n",
      " 'cv_pauc_oof': 0.16508305592308392,\n",
      " 'cv_pauc_std': 0.005713928888263255,\n",
      " 'es_rounds': 150,\n",
      " 'num_rounds': 2000,\n",
      " 'params': {'alpha': 0.6779926606782505,\n",
      "            'colsample_bylevel': 0.5476090898823716,\n",
      "            'colsample_bynode': 0.9928601203635129,\n",
      "            'colsample_bytree': 0.8437772277074493,\n",
      "            'disable_default_eval_metric': True,\n",
      "            'enable_categorical': True,\n",
      "            'lambda': 8.879624125465703,\n",
      "            'learning_rate': 0.08501257473292347,\n",
      "            'max_depth': 6,\n",
      "            'random_state': 2022,\n",
      "            'scale_pos_weight': 3.29440313334688,\n",
      "            'subsample': 0.6012681388711075,\n",
      "            'tree_method': 'hist',\n",
      "            'verbosity': 0},\n",
      " 'val_auc_scores': {'fold_1': 0.9722051502097672,\n",
      "                    'fold_2': 0.9549559539756749,\n",
      "                    'fold_3': 0.9749985690039175,\n",
      "                    'fold_4': 0.9597111061029152,\n",
      "                    'fold_5': 0.9701764707990329},\n",
      " 'val_pauc_scores': {'fold_1': 0.17774051082375997,\n",
      "                     'fold_2': 0.16399476133070867,\n",
      "                     'fold_3': 0.17858805385175905,\n",
      "                     'fold_4': 0.1692953066642884,\n",
      "                     'fold_5': 0.17689698208838817}}\n",
      "Total number of columns: 86\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for idx, (model_name, version, path, oof_column) in enumerate(zip(boosting_model_names, boosting_versions, boosting_paths, boosting_oof_columns)):\n",
    "    print(f\"Generating predictions for {model_name}_{version}\")\n",
    "    model_preds_df, _ = get_boosting_predictions(\n",
    "        train_metadata, \n",
    "        test_metadata,\n",
    "        model_name, \n",
    "        version, \n",
    "        Path(path),\n",
    "        oof_column\n",
    "    )\n",
    "    print(\"\\n\")\n",
    "    if idx == 0:\n",
    "        ensemble_preds_df = model_preds_df.copy()\n",
    "    else:\n",
    "        ensemble_preds_df = ensemble_preds_df.merge(model_preds_df, on=id_column, how=\"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "136d58ed",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-29T00:42:56.899214Z",
     "iopub.status.busy": "2024-08-29T00:42:56.898840Z",
     "iopub.status.idle": "2024-08-29T00:42:57.139592Z",
     "shell.execute_reply": "2024-08-29T00:42:57.138676Z"
    },
    "papermill": {
     "duration": 0.250731,
     "end_time": "2024-08-29T00:42:57.141568",
     "exception": false,
     "start_time": "2024-08-29T00:42:56.890837",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "150"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del train_metadata, test_metadata\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7a078895",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-29T00:42:57.156929Z",
     "iopub.status.busy": "2024-08-29T00:42:57.156651Z",
     "iopub.status.idle": "2024-08-29T00:42:57.209920Z",
     "shell.execute_reply": "2024-08-29T00:42:57.208993Z"
    },
    "papermill": {
     "duration": 0.063448,
     "end_time": "2024-08-29T00:42:57.211887",
     "exception": false,
     "start_time": "2024-08-29T00:42:57.148439",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "feature_mapping_dict = {\n",
    "    \"sex\": defaultdict(lambda: 0, {\n",
    "        \"missing_sex\": 0,\n",
    "        \"female\": 1,\n",
    "        \"male\": 2,\n",
    "    }),\n",
    "    \"anatom_site_general\": defaultdict(lambda: 0, {\n",
    "        \"missing_anatom_site_general\": 0,\n",
    "        \"lower extremity\": 1,\n",
    "        \"head/neck\": 2,\n",
    "        \"posterior torso\": 3,\n",
    "        \"anterior torso\": 4,\n",
    "        \"upper extremity\": 5,\n",
    "    }),\n",
    "    \"tbp_tile_type\": defaultdict(lambda: 0, {\n",
    "        \"3D: white\": 0,\n",
    "        \"3D: XP\": 1,\n",
    "    }),\n",
    "    \"tbp_lv_location\": defaultdict(lambda: 0, {\n",
    "        \"Unknown\": 0,\n",
    "        \"Right Leg - Upper\": 1,\n",
    "        \"Head & Neck\": 2,\n",
    "        \"Torso Back Top Third\": 3,\n",
    "        \"Torso Front Top Half\": 4,\n",
    "        \"Right Arm - Upper\": 5,\n",
    "        \"Left Leg - Upper\": 6,\n",
    "        \"Torso Front Bottom Half\": 7,\n",
    "        \"Left Arm - Upper\": 8,\n",
    "        \"Right Leg\": 9,\n",
    "        \"Torso Back Middle Third\": 10,\n",
    "        \"Right Arm - Lower\": 11,\n",
    "        \"Right Leg - Lower\": 12,\n",
    "        \"Left Leg - Lower\": 13,\n",
    "        \"Left Arm - Lower\": 14,\n",
    "        \"Left Leg\": 15,\n",
    "        \"Torso Back Bottom Third\": 16,\n",
    "        \"Left Arm\": 17,\n",
    "        \"Right Arm\": 18,\n",
    "        \"Torso Front\": 19,\n",
    "        \"Torso Back\": 20\n",
    "    }),\n",
    "    \"tbp_lv_location_simple\": defaultdict(lambda: 0, {\n",
    "        \"Unknown\": 0,\n",
    "        \"Right Leg\": 1,\n",
    "        \"Head & Neck\": 2,\n",
    "        \"Torso Back\": 3,\n",
    "        \"Torso Front\": 4,\n",
    "        \"Right Arm\": 5,\n",
    "        \"Left Leg\": 6,\n",
    "        \"Left Arm\": 7,\n",
    "    }),\n",
    "}\n",
    "\n",
    "\n",
    "def get_emb_szs(cat_cols):\n",
    "    emb_szs = {}\n",
    "    for col in cat_cols:\n",
    "        emb_szs[col] = (len(feature_mapping_dict[col]), min(600, round(1.6 * len(feature_mapping_dict[col]) ** 0.56)))\n",
    "    return emb_szs\n",
    "\n",
    "\n",
    "def cnn_norm_feature(df, value_col, group_cols, err=1e-5):\n",
    "    stats = [\"mean\", \"std\"]\n",
    "    tmp = df.groupby(group_cols)[value_col].agg(stats)\n",
    "    tmp.columns = [f\"{value_col}_{stat}\" for stat in stats]\n",
    "    tmp.reset_index(inplace=True)\n",
    "    df = df.merge(tmp, on=group_cols, how=\"left\")\n",
    "    feature_name = f\"{value_col}_patient_norm\"\n",
    "    df[feature_name] = ((df[value_col] - df[f\"{value_col}_mean\"]) / (df[f\"{value_col}_std\"] + err)).fillna(0)\n",
    "    return df, feature_name\n",
    "\n",
    "\n",
    "def cnn_feature_engineering(df):\n",
    "    df[\"age_approx\"] = df[\"age_approx\"].fillna(0)\n",
    "    df[\"age_approx\"] = df[\"age_approx\"] / 90\n",
    "    df[\"sex\"] = df[\"sex\"].fillna(\"missing_sex\")\n",
    "    df[\"sex\"] = df[\"sex\"].map(feature_mapping_dict[\"sex\"])\n",
    "    df[\"anatom_site_general\"] = df[\"anatom_site_general\"].fillna(\"missing_anatom_site_general\")\n",
    "    df[\"anatom_site_general\"] = df[\"anatom_site_general\"].map(feature_mapping_dict[\"anatom_site_general\"])\n",
    "    df[\"tbp_tile_type\"] = df[\"tbp_tile_type\"].map(feature_mapping_dict[\"tbp_tile_type\"])\n",
    "    df[\"tbp_lv_location\"] = df[\"tbp_lv_location\"].map(feature_mapping_dict[\"tbp_lv_location\"])\n",
    "    df[\"tbp_lv_location_simple\"] = df[\"tbp_lv_location_simple\"].map(feature_mapping_dict[\"tbp_lv_location_simple\"])\n",
    "\n",
    "    cat_cols = [\"sex\", \"anatom_site_general\",\n",
    "                \"tbp_tile_type\", \"tbp_lv_location\", \"tbp_lv_location_simple\"]\n",
    "\n",
    "    df[\"num_images\"] = df[\"patient_id\"].map(df.groupby(\"patient_id\")[\"isic_id\"].count())\n",
    "    df[\"num_images\"] = np.log1p(df[\"num_images\"])\n",
    "\n",
    "    cols_to_norm = [\n",
    "        \"age_approx\",\n",
    "        \"clin_size_long_diam_mm\",\n",
    "        \"tbp_lv_A\", \"tbp_lv_Aext\",\n",
    "        \"tbp_lv_B\", \"tbp_lv_Bext\",\n",
    "        \"tbp_lv_C\", \"tbp_lv_Cext\",\n",
    "        \"tbp_lv_H\", \"tbp_lv_Hext\",\n",
    "        \"tbp_lv_L\", \"tbp_lv_Lext\",\n",
    "        \"tbp_lv_areaMM2\", \"tbp_lv_area_perim_ratio\",\n",
    "        \"tbp_lv_color_std_mean\",\n",
    "        \"tbp_lv_deltaA\", \"tbp_lv_deltaB\", \"tbp_lv_deltaL\", \"tbp_lv_deltaLB\", \"tbp_lv_deltaLBnorm\",\n",
    "        \"tbp_lv_eccentricity\",\n",
    "        \"tbp_lv_minorAxisMM\", \"tbp_lv_nevi_confidence\", \"tbp_lv_norm_border\",\n",
    "        \"tbp_lv_norm_color\", \"tbp_lv_perimeterMM\",\n",
    "        \"tbp_lv_radial_color_std_max\", \"tbp_lv_stdL\", \"tbp_lv_stdLExt\",\n",
    "        \"tbp_lv_symm_2axis\", \"tbp_lv_symm_2axis_angle\",\n",
    "        \"tbp_lv_x\", \"tbp_lv_y\", \"tbp_lv_z\"\n",
    "    ]\n",
    "    cont_cols = cols_to_norm[:]\n",
    "    for col in cols_to_norm:\n",
    "        df, feature_name = cnn_norm_feature(df, col, [\"patient_id\"])\n",
    "        cont_cols += [feature_name]\n",
    "\n",
    "    df[\"num_images\"] = np.log1p(df[\"patient_id\"].map(df.groupby(\"patient_id\")[\"isic_id\"].count()))\n",
    "    cont_cols += [\"num_images\"]\n",
    "    assert df[cont_cols].isnull().sum().sum() == 0\n",
    "    return df, cat_cols, cont_cols\n",
    "\n",
    "def test_augment(image_size, mean=None, std=None):\n",
    "    if mean is not None and std is not None:\n",
    "        normalize = A.Normalize(mean=mean, std=std, max_pixel_value=255.0, p=1.0)\n",
    "    else:\n",
    "        normalize = A.Normalize(max_pixel_value=255.0, p=1.0)\n",
    "    transform = A.Compose(\n",
    "        [A.Resize(image_size, image_size), normalize, ToTensorV2()], p=1.0\n",
    "    )\n",
    "    return transform\n",
    "\n",
    "\n",
    "class ISICDataset(Dataset):\n",
    "    def __init__(self, metadata, images, augment,\n",
    "                 use_meta=False, cat_cols: List = None, cont_cols: List = None,\n",
    "                 infer=False):\n",
    "        self.metadata = metadata\n",
    "        self.images = images\n",
    "        self.augment = augment\n",
    "        self.use_meta = use_meta\n",
    "        self.cat_cols = cat_cols\n",
    "        self.cont_cols = cont_cols\n",
    "        self.length = len(self.metadata)\n",
    "        self.infer = infer\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.length\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        row = self.metadata.iloc[index]\n",
    "        image = np.array(Image.open(BytesIO(self.images[row[\"isic_id\"]][()])))\n",
    "        if self.augment is not None:\n",
    "            image = self.augment(image=image)[\"image\"].float()\n",
    "\n",
    "        if self.use_meta:\n",
    "            x_cat = torch.tensor([row[col] for col in self.cat_cols], dtype=torch.long)\n",
    "            x_cont = torch.tensor([row[col] for col in self.cont_cols], dtype=torch.float)\n",
    "        else:\n",
    "            x_cat = torch.tensor(0)\n",
    "            x_cont = torch.tensor(0)\n",
    "\n",
    "        if self.infer:\n",
    "            return image, x_cat, x_cont\n",
    "        else:\n",
    "            target = torch.tensor(row[\"target\"])\n",
    "            return image, x_cat, x_cont, target\n",
    "\n",
    "    \n",
    "class ISICNet(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        model_name,\n",
    "        pretrained=True,\n",
    "        use_meta=False,\n",
    "        cat_cols: List = None, cont_cols: List = None, emb_szs: Dict = None,\n",
    "    ):\n",
    "        super(ISICNet, self).__init__()\n",
    "        self.model = create_model(\n",
    "            model_name=model_name,\n",
    "            pretrained=pretrained,\n",
    "            in_chans=3,\n",
    "            num_classes=0,\n",
    "            global_pool=\"\",\n",
    "        )\n",
    "        in_dim = self.model.num_features\n",
    "        self.dropouts = nn.ModuleList([nn.Dropout(0.5) for _ in range(5)])\n",
    "        self.use_meta = use_meta\n",
    "        if use_meta:\n",
    "            self.linear = nn.Linear(in_dim, 256)\n",
    "\n",
    "            self.embeddings = nn.ModuleList([nn.Embedding(emb_szs[col][0], emb_szs[col][1]) for col in cat_cols])\n",
    "            self.embedding_dropout = nn.Dropout(0.1)\n",
    "            n_emb = sum([emb_szs[col][1] for col in cat_cols])\n",
    "            n_cont = len(cont_cols)\n",
    "            self.bn_cont = nn.BatchNorm1d(n_cont)\n",
    "            self.meta = nn.Sequential(\n",
    "                nn.Linear(n_emb + n_cont, 256),\n",
    "                nn.BatchNorm1d(256),\n",
    "                nn.SiLU(),\n",
    "                nn.Dropout(0.3),\n",
    "                nn.Linear(256, 64),\n",
    "                nn.BatchNorm1d(64),\n",
    "                nn.SiLU(),\n",
    "                nn.Dropout(0.1),\n",
    "            )\n",
    "            self.classifier = nn.Linear(256 + 64, 1)\n",
    "        else:\n",
    "            self.linear = nn.Linear(in_dim, 1)\n",
    "\n",
    "    def forward(self, images, x_cat=None, x_cont=None):\n",
    "        x = self.model(images)\n",
    "        bs = len(images)\n",
    "        pool = F.adaptive_avg_pool2d(x, 1).reshape(bs, -1)\n",
    "        if self.training:\n",
    "            x_image = 0\n",
    "            for i in range(len(self.dropouts)):\n",
    "                x_image += self.linear(self.dropouts[i](pool))\n",
    "            x_image = x_image / len(self.dropouts)\n",
    "        else:\n",
    "            x_image = self.linear(pool)\n",
    "\n",
    "        if self.use_meta:\n",
    "            x_cat = [emb(x_cat[:, i]) for i, emb in enumerate(self.embeddings)]\n",
    "            x_cat = torch.cat(x_cat, 1)\n",
    "            x_cat = self.embedding_dropout(x_cat)\n",
    "            x_cont = self.bn_cont(x_cont)\n",
    "            x_meta = self.meta(torch.cat([x_cat, x_cont], 1))\n",
    "            x = torch.cat([x_image, x_meta], 1)\n",
    "            logits = self.classifier(x)\n",
    "        else:\n",
    "            logits = x_image\n",
    "        return logits\n",
    "\n",
    "\n",
    "def get_trans(img, iteration):\n",
    "    if iteration >= 6:\n",
    "        img = img.transpose(2, 3)\n",
    "    if iteration % 6 == 0:\n",
    "        return img\n",
    "    elif iteration % 6 == 1:\n",
    "        return torch.flip(img, dims=[2])\n",
    "    elif iteration % 6 == 2:\n",
    "        return torch.flip(img, dims=[3])\n",
    "    elif iteration % 6 == 3:\n",
    "        return torch.rot90(img, 1, dims=[2, 3])\n",
    "    elif iteration % 6 == 4:\n",
    "        return torch.rot90(img, 2, dims=[2, 3])\n",
    "    elif iteration % 6 == 5:\n",
    "        return torch.rot90(img, 3, dims=[2, 3])\n",
    "\n",
    "    \n",
    "def predict(model, test_dataloader, accelerator, n_tta, use_meta, log_interval=10):\n",
    "    model.eval()\n",
    "    test_probs = []\n",
    "    total_steps = len(test_dataloader)\n",
    "    with torch.no_grad():\n",
    "        for step, (images, x_cat, x_cont) in enumerate(test_dataloader):\n",
    "            logits = 0\n",
    "            probs = 0\n",
    "            for i in range(n_tta):\n",
    "                if use_meta:\n",
    "                    logits_iter = model(get_trans(images, i), x_cat, x_cont)\n",
    "                else:\n",
    "                    logits_iter = model(get_trans(images, i))\n",
    "                logits += logits_iter\n",
    "                probs += torch.sigmoid(logits_iter)\n",
    "            logits /= n_tta\n",
    "            probs /= n_tta\n",
    "\n",
    "            probs = accelerator.gather(probs)\n",
    "            test_probs.append(probs)\n",
    "\n",
    "            if (step == 0) or ((step + 1) % log_interval == 0):\n",
    "                print(f\"Step: {step + 1}/{total_steps}\")\n",
    "\n",
    "    test_probs = torch.cat(test_probs).cpu().numpy()\n",
    "    return test_probs\n",
    "\n",
    "\n",
    "def get_dnn_predictions(train, test, images, model_name, version, path, oof_column):\n",
    "    start_time = time.time()\n",
    "    with open(path / f\"{model_name}_{version}_run_metadata.json\", \"r\") as f:\n",
    "        run_metadata = json.load(f)\n",
    "    pprint(run_metadata[\"params\"])\n",
    "    \n",
    "    image_size = run_metadata[\"params\"][\"image_size\"]\n",
    "    batch_size = run_metadata[\"params\"][\"val_batch_size\"]\n",
    "    use_meta = run_metadata[\"params\"][\"use_meta\"]\n",
    "    \n",
    "    test_dataset = ISICDataset(\n",
    "        test, images, augment=test_augment(image_size), \n",
    "        use_meta=use_meta,\n",
    "        cat_cols=cat_cols,\n",
    "        cont_cols=cont_cols,\n",
    "        infer=True\n",
    "    )\n",
    "    test_dataloader = DataLoader(\n",
    "        test_dataset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=False,\n",
    "        num_workers=4,\n",
    "        drop_last=False,\n",
    "        pin_memory=True,\n",
    "    )\n",
    "\n",
    "    all_folds = np.unique(train[fold_column])\n",
    "#     all_folds = [1]\n",
    "    test_predictions_df = pd.DataFrame({id_column: test[id_column]})\n",
    "    for fold in all_folds:\n",
    "        print(f\"\\nFold {fold}\")\n",
    "        accelerator = Accelerator(\n",
    "            mixed_precision=run_metadata[\"params\"][\"mixed_precision\"],\n",
    "        )\n",
    "        \n",
    "        model = ISICNet(model_name=model_name, pretrained=False,\n",
    "                        use_meta=use_meta,\n",
    "                        cat_cols=cat_cols,\n",
    "                        cont_cols=cont_cols,\n",
    "                        emb_szs=emb_szs,)\n",
    "        model = model.to(accelerator.device)\n",
    "        \n",
    "        model, test_dataloader = accelerator.prepare(model, test_dataloader)\n",
    "        model_filepath = path / f\"models/fold_{fold}\"\n",
    "        accelerator.load_state(model_filepath)\n",
    "\n",
    "        test_predictions_df[f\"fold_{fold}\"] = predict(model, test_dataloader, accelerator, n_tta=run_metadata[\"params\"][\"n_tta\"], use_meta=use_meta)\n",
    "    test_predictions_df[oof_column] = test_predictions_df[[f\"fold_{fold}\" for fold in all_folds]].mean(axis=1)\n",
    "    end_time = time.time()\n",
    "    return test_predictions_df[[id_column, oof_column]], (end_time - start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "69d43f6e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-29T00:42:57.227422Z",
     "iopub.status.busy": "2024-08-29T00:42:57.226575Z",
     "iopub.status.idle": "2024-08-29T00:43:23.198942Z",
     "shell.execute_reply": "2024-08-29T00:43:23.197979Z"
    },
    "papermill": {
     "duration": 25.982553,
     "end_time": "2024-08-29T00:43:23.201422",
     "exception": false,
     "start_time": "2024-08-29T00:42:57.218869",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data size: (401059, 58)\n",
      "Test data size: (3, 44)\n"
     ]
    }
   ],
   "source": [
    "train_metadata = pd.read_csv(INPUT_PATH / \"train-metadata.csv\", low_memory=False, na_values=[\"NA\"])\n",
    "test_metadata = pd.read_csv(INPUT_PATH / \"test-metadata.csv\", low_memory=False, na_values=[\"NA\"])\n",
    "\n",
    "folds_df = pd.read_csv(\"/kaggle/input/isic-scd-folds/folds.csv\")\n",
    "train_metadata = train_metadata.merge(folds_df, on=[id_column, group_column], how=\"inner\")\n",
    "print(f\"Train data size: {train_metadata.shape}\")\n",
    "print(f\"Test data size: {test_metadata.shape}\")\n",
    "\n",
    "train_images = h5py.File(INPUT_PATH / \"train-image.hdf5\", mode=\"r\")\n",
    "test_images = h5py.File(INPUT_PATH / \"test-image.hdf5\", mode=\"r\")\n",
    "\n",
    "train_metadata, cat_cols, cont_cols = cnn_feature_engineering(train_metadata)\n",
    "test_metadata, _, _ = cnn_feature_engineering(test_metadata)\n",
    "emb_szs = get_emb_szs(cat_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8feb3972",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-29T00:43:23.218085Z",
     "iopub.status.busy": "2024-08-29T00:43:23.217136Z",
     "iopub.status.idle": "2024-08-29T00:43:23.223285Z",
     "shell.execute_reply": "2024-08-29T00:43:23.222556Z"
    },
    "papermill": {
     "duration": 0.015847,
     "end_time": "2024-08-29T00:43:23.225267",
     "exception": false,
     "start_time": "2024-08-29T00:43:23.209420",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "for idx, (model_name, version, path, oof_column) in enumerate(zip(cnn_model_names, cnn_versions, cnn_paths, cnn_oof_columns)):\n",
    "    print(f\"Generating predictions for {model_name}_{version}\")\n",
    "    model_preds_df, _ = get_dnn_predictions(\n",
    "        train_metadata, \n",
    "        test_metadata,\n",
    "        test_images,\n",
    "        model_name, \n",
    "        version, \n",
    "        Path(path),\n",
    "        oof_column\n",
    "    )\n",
    "    print(\"\\n\")\n",
    "    ensemble_preds_df = ensemble_preds_df.merge(model_preds_df, on=id_column, how=\"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9eb374cd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-29T00:43:23.240432Z",
     "iopub.status.busy": "2024-08-29T00:43:23.239777Z",
     "iopub.status.idle": "2024-08-29T00:43:23.252040Z",
     "shell.execute_reply": "2024-08-29T00:43:23.251078Z"
    },
    "papermill": {
     "duration": 0.021923,
     "end_time": "2024-08-29T00:43:23.253985",
     "exception": false,
     "start_time": "2024-08-29T00:43:23.232062",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>isic_id</th>\n",
       "      <th>oof_xgb_v5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ISIC_0015657</td>\n",
       "      <td>0.376651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ISIC_0015729</td>\n",
       "      <td>0.206420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ISIC_0015740</td>\n",
       "      <td>0.502445</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        isic_id  oof_xgb_v5\n",
       "0  ISIC_0015657    0.376651\n",
       "1  ISIC_0015729    0.206420\n",
       "2  ISIC_0015740    0.502445"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ensemble_preds_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a24a5b0a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-29T00:43:23.269357Z",
     "iopub.status.busy": "2024-08-29T00:43:23.269015Z",
     "iopub.status.idle": "2024-08-29T00:43:23.284477Z",
     "shell.execute_reply": "2024-08-29T00:43:23.283532Z"
    },
    "papermill": {
     "duration": 0.025694,
     "end_time": "2024-08-29T00:43:23.286673",
     "exception": false,
     "start_time": "2024-08-29T00:43:23.260979",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>isic_id</th>\n",
       "      <th>oof_xgb_v5</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ISIC_0015657</td>\n",
       "      <td>0.376651</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ISIC_0015729</td>\n",
       "      <td>0.206420</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ISIC_0015740</td>\n",
       "      <td>0.502445</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        isic_id  oof_xgb_v5    target\n",
       "0  ISIC_0015657    0.376651  0.666667\n",
       "1  ISIC_0015729    0.206420  0.333333\n",
       "2  ISIC_0015740    0.502445  1.000000"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ensemble_preds = 0\n",
    "for idx, (blend_oof_column, weight) in enumerate(zip(blend_oof_columns, weights)):\n",
    "    ensemble_preds += ensemble_preds_df[blend_oof_column].rank(pct=True).values * weight\n",
    "ensemble_preds_df[target_column] = ensemble_preds\n",
    "ensemble_preds_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f47033e5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-29T00:43:23.303567Z",
     "iopub.status.busy": "2024-08-29T00:43:23.302818Z",
     "iopub.status.idle": "2024-08-29T00:43:23.312387Z",
     "shell.execute_reply": "2024-08-29T00:43:23.311475Z"
    },
    "papermill": {
     "duration": 0.020073,
     "end_time": "2024-08-29T00:43:23.314439",
     "exception": false,
     "start_time": "2024-08-29T00:43:23.294366",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    3.000000\n",
       "mean     0.666667\n",
       "std      0.333333\n",
       "min      0.333333\n",
       "25%      0.500000\n",
       "50%      0.666667\n",
       "75%      0.833333\n",
       "max      1.000000\n",
       "Name: target, dtype: float64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ensemble_preds_df[target_column].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "185aa3cf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-29T00:43:23.330726Z",
     "iopub.status.busy": "2024-08-29T00:43:23.330389Z",
     "iopub.status.idle": "2024-08-29T00:43:23.340699Z",
     "shell.execute_reply": "2024-08-29T00:43:23.339732Z"
    },
    "papermill": {
     "duration": 0.02088,
     "end_time": "2024-08-29T00:43:23.342805",
     "exception": false,
     "start_time": "2024-08-29T00:43:23.321925",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>isic_id</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ISIC_0015657</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ISIC_0015729</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ISIC_0015740</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        isic_id    target\n",
       "0  ISIC_0015657  0.666667\n",
       "1  ISIC_0015729  0.333333\n",
       "2  ISIC_0015740  1.000000"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ensemble_preds_df[[id_column, target_column]].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "29229322",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-29T00:43:23.359942Z",
     "iopub.status.busy": "2024-08-29T00:43:23.359365Z",
     "iopub.status.idle": "2024-08-29T00:43:23.367300Z",
     "shell.execute_reply": "2024-08-29T00:43:23.366403Z"
    },
    "papermill": {
     "duration": 0.018762,
     "end_time": "2024-08-29T00:43:23.369345",
     "exception": false,
     "start_time": "2024-08-29T00:43:23.350583",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "ensemble_preds_df[[id_column, target_column]].to_csv(\"submission.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf690c8b",
   "metadata": {
    "papermill": {
     "duration": 0.007358,
     "end_time": "2024-08-29T00:43:23.384292",
     "exception": false,
     "start_time": "2024-08-29T00:43:23.376934",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "databundleVersionId": 9094797,
     "sourceId": 63056,
     "sourceType": "competition"
    },
    {
     "datasetId": 5604316,
     "sourceId": 9262133,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 5521264,
     "sourceId": 9263094,
     "sourceType": "datasetVersion"
    },
    {
     "sourceId": 187477024,
     "sourceType": "kernelVersion"
    },
    {
     "sourceId": 194381002,
     "sourceType": "kernelVersion"
    },
    {
     "sourceId": 194481949,
     "sourceType": "kernelVersion"
    },
    {
     "sourceId": 194484347,
     "sourceType": "kernelVersion"
    },
    {
     "sourceId": 194484398,
     "sourceType": "kernelVersion"
    },
    {
     "sourceId": 194484667,
     "sourceType": "kernelVersion"
    },
    {
     "sourceId": 194485209,
     "sourceType": "kernelVersion"
    }
   ],
   "dockerImageVersionId": 30733,
   "isGpuEnabled": true,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 70.252583,
   "end_time": "2024-08-29T00:43:25.969807",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-08-29T00:42:15.717224",
   "version": "2.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
