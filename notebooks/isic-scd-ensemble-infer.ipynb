{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "18f93567",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2024-07-27T16:48:17.092603Z",
     "iopub.status.busy": "2024-07-27T16:48:17.092235Z",
     "iopub.status.idle": "2024-07-27T16:48:29.622250Z",
     "shell.execute_reply": "2024-07-27T16:48:29.621307Z"
    },
    "papermill": {
     "duration": 12.538805,
     "end_time": "2024-07-27T16:48:29.624610",
     "exception": false,
     "start_time": "2024-07-27T16:48:17.085805",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import joblib\n",
    "from tqdm import tqdm\n",
    "from pathlib import Path\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import lightgbm as lgb\n",
    "import catboost as cb\n",
    "\n",
    "import h5py\n",
    "from io import BytesIO\n",
    "from PIL import Image\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from timm import create_model\n",
    "\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "\n",
    "from accelerate import Accelerator\n",
    "\n",
    "from isic_helper import DotDict, get_folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a874c18c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-27T16:48:29.636980Z",
     "iopub.status.busy": "2024-07-27T16:48:29.635757Z",
     "iopub.status.idle": "2024-07-27T16:48:29.641122Z",
     "shell.execute_reply": "2024-07-27T16:48:29.640430Z"
    },
    "papermill": {
     "duration": 0.013039,
     "end_time": "2024-07-27T16:48:29.643039",
     "exception": false,
     "start_time": "2024-07-27T16:48:29.630000",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_names = [\"cb\", \"lgb\", \"resnet18\", \"efficientnet_b0\"]\n",
    "versions = [\"v1\", \"v3\", \"v2\",  \"v1\"]\n",
    "paths = [f\"/kaggle/input/isic-scd-{model_name.replace('_', '-')}-{version}-train\" for model_name, version in zip(model_names, versions)]\n",
    "\n",
    "weights = [1.0, 1.0, 0.8288018058494133, 0.4267574195330997]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "715c983a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-27T16:48:29.653491Z",
     "iopub.status.busy": "2024-07-27T16:48:29.653189Z",
     "iopub.status.idle": "2024-07-27T16:48:29.656928Z",
     "shell.execute_reply": "2024-07-27T16:48:29.656112Z"
    },
    "papermill": {
     "duration": 0.0111,
     "end_time": "2024-07-27T16:48:29.658818",
     "exception": false,
     "start_time": "2024-07-27T16:48:29.647718",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "id_column = \"isic_id\"\n",
    "target_column = \"target\"\n",
    "group_column = \"patient_id\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "062f8582",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-27T16:48:29.669498Z",
     "iopub.status.busy": "2024-07-27T16:48:29.669221Z",
     "iopub.status.idle": "2024-07-27T16:48:29.685939Z",
     "shell.execute_reply": "2024-07-27T16:48:29.685151Z"
    },
    "papermill": {
     "duration": 0.024267,
     "end_time": "2024-07-27T16:48:29.687803",
     "exception": false,
     "start_time": "2024-07-27T16:48:29.663536",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def count_features(df, col):\n",
    "    tmp = df[[id_column, group_column, col]].pivot_table(\n",
    "        values=id_column, \n",
    "        index=group_column, \n",
    "        columns=col, \n",
    "        aggfunc=\"count\", \n",
    "        fill_value=0)\n",
    "    feature_cols = tmp.columns.tolist()\n",
    "    tmp.reset_index(inplace=True)\n",
    "    tmp.index.name = None\n",
    "    df = df.merge(tmp, on=group_column, how=\"left\")\n",
    "    return df, feature_cols\n",
    "\n",
    "def mean_features(df, col, val):\n",
    "    tmp = df[[id_column, group_column, col, val]].pivot_table(\n",
    "        values=val, \n",
    "        index=group_column, \n",
    "        columns=col, \n",
    "        aggfunc=\"mean\", \n",
    "        fill_value=0)\n",
    "    tmp.columns = [f\"{c}_{val}_mean\" for c in tmp.columns.tolist()]\n",
    "    feature_cols = tmp.columns.tolist()\n",
    "    tmp.reset_index(inplace=True)\n",
    "    tmp.index.name = None\n",
    "    df = df.merge(tmp, on=group_column, how=\"left\")\n",
    "    return df, feature_cols\n",
    "\n",
    "\n",
    "def stat_features(df, group_cols, value_col, stats):\n",
    "    tmp = df.groupby(group_cols)[value_col].agg(stats)\n",
    "    tmp.columns = [f\"{value_col}_{stat}\" for stat in stats]\n",
    "    tmp.reset_index(inplace=True)\n",
    "    df = df.merge(tmp, on=group_cols, how=\"left\")\n",
    "    df[f\"{value_col}_mean_diff\"] = df[value_col] - df[f\"{value_col}_mean\"]\n",
    "    return df\n",
    "\n",
    "\n",
    "def feature_engineering(df):\n",
    "    new_num_cols = []\n",
    "    \n",
    "    df[\"lesion_size_ratio\"] = df[\"tbp_lv_minorAxisMM\"] / df[\"clin_size_long_diam_mm\"]\n",
    "    new_num_cols += [\"lesion_size_ratio\"]\n",
    "    \n",
    "    df[\"lesion_distance\"] = np.sqrt(df[\"tbp_lv_x\"]**2 + df[\"tbp_lv_y\"]**2 + df[\"tbp_lv_z\"]**2)\n",
    "    new_num_cols += [\"lesion_distance\"]\n",
    "    \n",
    "    df[\"hue_contrast\"] = df[\"tbp_lv_H\"] - df[\"tbp_lv_Hext\"]\n",
    "    df, feature_cols = mean_features(df, \"anatom_site_general\", \"hue_contrast\")\n",
    "    new_num_cols += feature_cols\n",
    "    \n",
    "    df, feature_cols = count_features(df, \"anatom_site_general\")\n",
    "    new_num_cols += feature_cols\n",
    "    \n",
    "    df[\"tbp_lv_A_diff\"] =  df[\"tbp_lv_Aext\"] - df[\"tbp_lv_A\"]\n",
    "    df = stat_features(df, [\"patient_id\", \"tbp_lv_location\"], \"tbp_lv_A_diff\", [\"mean\"])\n",
    "    new_num_cols += [\"tbp_lv_A_diff_mean_diff\"]\n",
    "    \n",
    "    df[\"tbp_lv_B_diff\"] =  df[\"tbp_lv_Bext\"] - df[\"tbp_lv_B\"]\n",
    "    df = stat_features(df, [\"patient_id\", \"tbp_lv_location\"], \"tbp_lv_B_diff\", [\"mean\"])\n",
    "    new_num_cols += [\"tbp_lv_B_diff_mean_diff\"]\n",
    "    \n",
    "    df[\"tbp_lv_L_diff\"] =  df[\"tbp_lv_Lext\"] - df[\"tbp_lv_L\"]\n",
    "    df = stat_features(df, [\"patient_id\", \"tbp_lv_location\"], \"tbp_lv_L_diff\", [\"mean\"])\n",
    "    new_num_cols += [\"tbp_lv_L_diff_mean_diff\"]\n",
    "    \n",
    "    df[\"tbp_lv_L_std_diff\"] =  df[\"tbp_lv_stdLExt\"] - df[\"tbp_lv_stdL\"]\n",
    "    df = stat_features(df, [\"patient_id\", \"tbp_lv_location\"], \"tbp_lv_L_std_diff\", [\"mean\"])\n",
    "    new_num_cols += [\"tbp_lv_L_std_diff_mean_diff\"]\n",
    "    \n",
    "    df[\"color_uniformity\"] = df[\"tbp_lv_color_std_mean\"] / df[\"tbp_lv_radial_color_std_max\"]\n",
    "    df, feature_cols = mean_features(df, \"anatom_site_general\", \"color_uniformity\")\n",
    "    new_num_cols += feature_cols\n",
    "    \n",
    "    df[\"radius\"] = np.cos(df[\"tbp_lv_symm_2axis_angle\"]) * np.sqrt(df[\"tbp_lv_x\"]**2 + df[\"tbp_lv_y\"]**2 + df[\"tbp_lv_z\"]**2)\n",
    "    new_num_cols += [\"radius\"]\n",
    "    \n",
    "    return df, new_num_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f1587177",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-27T16:48:29.698095Z",
     "iopub.status.busy": "2024-07-27T16:48:29.697841Z",
     "iopub.status.idle": "2024-07-27T16:48:29.710204Z",
     "shell.execute_reply": "2024-07-27T16:48:29.709427Z"
    },
    "papermill": {
     "duration": 0.019611,
     "end_time": "2024-07-27T16:48:29.712044",
     "exception": false,
     "start_time": "2024-07-27T16:48:29.692433",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def val_augment(image_size):\n",
    "    transform = A.Compose([A.Resize(image_size, image_size), ToTensorV2()], p=1.0)\n",
    "    return transform\n",
    "\n",
    "\n",
    "class ISICDataset(Dataset):\n",
    "    def __init__(self, metadata, images, augment, infer=False):\n",
    "        self.metadata = metadata\n",
    "        self.images = images\n",
    "        self.augment = augment\n",
    "        self.length = len(self.metadata)\n",
    "        self.infer = infer\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.length\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        data = self.metadata.iloc[index]\n",
    "\n",
    "        image = np.array(Image.open(BytesIO(self.images[data[\"isic_id\"]][()])))\n",
    "        image = self.augment(image=image)[\"image\"]\n",
    "\n",
    "        record = {\"image\": image}\n",
    "\n",
    "        if not self.infer:\n",
    "            target = data[\"target\"]\n",
    "            record[\"target\"] = torch.tensor(target).float()\n",
    "\n",
    "        return record\n",
    "\n",
    "\n",
    "class ISICNet(nn.Module):\n",
    "    def __init__(self, model_name, pretrained=True, infer=False):\n",
    "        super(ISICNet, self).__init__()\n",
    "        self.infer = infer\n",
    "        self.model = create_model(\n",
    "            model_name=model_name,\n",
    "            pretrained=pretrained,\n",
    "            in_chans=3,\n",
    "            num_classes=0,\n",
    "            global_pool=\"\",\n",
    "        )\n",
    "        self.classifier = nn.Linear(self.model.num_features, 1)\n",
    "\n",
    "        self.dropouts = nn.ModuleList([nn.Dropout(0.5) for i in range(5)])\n",
    "\n",
    "    def forward(self, batch):\n",
    "        image = batch[\"image\"]\n",
    "        image = image.float() / 255\n",
    "\n",
    "        x = self.model(image)\n",
    "        bs = len(image)\n",
    "        pool = F.adaptive_avg_pool2d(x, 1).reshape(bs, -1)\n",
    "\n",
    "        if self.training:\n",
    "            logit = 0\n",
    "            for i in range(len(self.dropouts)):\n",
    "                logit += self.classifier(self.dropouts[i](pool))\n",
    "            logit = logit / len(self.dropouts)\n",
    "        else:\n",
    "            logit = self.classifier(pool)\n",
    "        return logit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4a50a3f0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-27T16:48:29.722398Z",
     "iopub.status.busy": "2024-07-27T16:48:29.722112Z",
     "iopub.status.idle": "2024-07-27T16:48:44.272778Z",
     "shell.execute_reply": "2024-07-27T16:48:44.271974Z"
    },
    "papermill": {
     "duration": 14.558423,
     "end_time": "2024-07-27T16:48:44.275104",
     "exception": false,
     "start_time": "2024-07-27T16:48:29.716681",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data size: (401059, 57)\n",
      "Test data size: (3, 44)\n"
     ]
    }
   ],
   "source": [
    "INPUT_PATH = Path(\"../input/isic-2024-challenge/\")\n",
    "\n",
    "train_metadata = pd.read_csv(INPUT_PATH / \"train-metadata.csv\", low_memory=False)\n",
    "test_metadata = pd.read_csv(INPUT_PATH / \"test-metadata.csv\")\n",
    "\n",
    "folds_df = get_folds()\n",
    "train_metadata = train_metadata.merge(folds_df, on=[\"isic_id\", \"patient_id\"], how=\"inner\")\n",
    "print(f\"Train data size: {train_metadata.shape}\")\n",
    "print(f\"Test data size: {test_metadata.shape}\")\n",
    "\n",
    "train_metadata, new_num_cols = feature_engineering(train_metadata.copy())\n",
    "test_metadata, _ = feature_engineering(test_metadata.copy())\n",
    "\n",
    "test_images = h5py.File(INPUT_PATH / \"test-image.hdf5\", mode=\"r\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "80e1e1b2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-27T16:48:44.287099Z",
     "iopub.status.busy": "2024-07-27T16:48:44.286398Z",
     "iopub.status.idle": "2024-07-27T16:48:44.310520Z",
     "shell.execute_reply": "2024-07-27T16:48:44.309733Z"
    },
    "papermill": {
     "duration": 0.032046,
     "end_time": "2024-07-27T16:48:44.312495",
     "exception": false,
     "start_time": "2024-07-27T16:48:44.280449",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_boosting_predictions(train, test, test_images, model_name, version, path):\n",
    "    with open(path / f\"{model_name}_{version}_encoder.joblib\", \"rb\") as f:\n",
    "        mixed_encoded_preprocessor = joblib.load(f)\n",
    "\n",
    "    enc = mixed_encoded_preprocessor.fit(train)\n",
    "\n",
    "    for col in mixed_encoded_preprocessor.feature_names_in_:\n",
    "        if col not in test.columns:\n",
    "            test[col] = np.nan\n",
    "\n",
    "    X_test = enc.transform(test)\n",
    "\n",
    "    columns_for_model = len(X_test.columns)\n",
    "    print(f\"Total number of columns: {columns_for_model}\")\n",
    "\n",
    "    with open(path / f\"{model_name}_{version}_run_metadata.json\", \"r\") as f:\n",
    "        run_metadata = json.load(f)\n",
    "        \n",
    "    all_folds = np.unique(train[\"fold\"])\n",
    "    test_predictions_df = pd.DataFrame({id_column: test_metadata[id_column]})\n",
    "    for fold in all_folds:\n",
    "        model_filepath = path / f\"models/{model_name}_{version}_fold_{fold}.txt\"\n",
    "        if \"lgb\" in model_name:\n",
    "            model = lgb.Booster(model_file=model_filepath)\n",
    "            test_predictions_df[f\"fold_{fold}\"] = model.predict(X_test, num_iteration=run_metadata[\"best_num_rounds\"][f\"fold_{fold}\"])\n",
    "        elif \"cb\" in model_name:\n",
    "            model = cb.CatBoostClassifier(use_best_model=True)\n",
    "            model.load_model(model_filepath)\n",
    "            test_predictions_df[f\"fold_{fold}\"] = model.predict_proba(X_test)[:, -1]\n",
    "    test_predictions_df[target_column] = test_predictions_df[[f\"fold_{fold}\" for fold in all_folds]].mean(axis=1)\n",
    "    return test_predictions_df[[id_column, target_column]]\n",
    "\n",
    "\n",
    "def get_dnn_predictions(train, test, test_images, model_name, version, path):\n",
    "    with open(path / f\"{model_name}_{version}_run_metadata.json\", \"r\") as f:\n",
    "        run_metadata = json.load(f)\n",
    "        \n",
    "    test_dataset = ISICDataset(\n",
    "        test, test_images, augment=val_augment(run_metadata[\"params\"][\"image_size\"]), infer=True\n",
    "    )\n",
    "    test_dataloader = DataLoader(\n",
    "        test_dataset,\n",
    "        batch_size=run_metadata[\"params\"][\"val_batch_size\"],\n",
    "        shuffle=False,\n",
    "        num_workers=2,\n",
    "        drop_last=False,\n",
    "        pin_memory=True,\n",
    "    )\n",
    "    \n",
    "    all_folds = np.unique(train[\"fold\"])\n",
    "    test_predictions_df = pd.DataFrame({id_column: test_metadata[id_column]})\n",
    "    for fold in all_folds:\n",
    "        accelerator = Accelerator(\n",
    "            mixed_precision=run_metadata[\"params\"][\"mixed_precision\"],\n",
    "        )\n",
    "        \n",
    "        model = ISICNet(model_name=model_name, pretrained=False, infer=True)\n",
    "        model = model.to(accelerator.device)\n",
    "        \n",
    "        model, test_dataloader = accelerator.prepare(model, test_dataloader)\n",
    "        model_filepath = path / f\"models/fold_{fold}/epoch_{run_metadata['best_num_epochs'][f'fold_{fold}']}\"\n",
    "        accelerator.load_state(model_filepath)\n",
    "        \n",
    "        model.eval()\n",
    "        test_preds = []\n",
    "        with torch.no_grad():\n",
    "            for batch in tqdm(test_dataloader, total=len(test_dataloader)):\n",
    "                image0 = batch[\"image\"].clone().detach()\n",
    "                test_preds_batch = 0\n",
    "                counter = 0\n",
    "                with torch.no_grad():\n",
    "                    outputs = model(batch)\n",
    "                preds = torch.sigmoid(outputs)\n",
    "                preds = accelerator.gather(preds)\n",
    "                test_preds_batch += preds.data.cpu().numpy().reshape(-1)\n",
    "                counter += 1\n",
    "                if run_metadata[\"params\"][\"tta\"]:\n",
    "                    batch[\"image\"] = torch.flip(image0, dims=[2])\n",
    "                    with torch.no_grad():\n",
    "                        outputs = model(batch)\n",
    "                    preds = torch.sigmoid(outputs)\n",
    "                    preds = accelerator.gather(preds)\n",
    "                    test_preds_batch += preds.data.cpu().numpy().reshape(-1)\n",
    "                    counter += 1\n",
    "\n",
    "                    batch[\"image\"] = torch.flip(image0, dims=[3])\n",
    "                    with torch.no_grad():\n",
    "                        outputs = model(batch)\n",
    "                    preds = torch.sigmoid(outputs)\n",
    "                    preds = accelerator.gather(preds)\n",
    "                    test_preds_batch += preds.data.cpu().numpy().reshape(-1)\n",
    "                    counter += 1\n",
    "\n",
    "                    for k in [1, 2, 3]:\n",
    "                        batch[\"image\"] = torch.rot90(image0, k, dims=[2, 3])\n",
    "                        with torch.no_grad():\n",
    "                            outputs = model(batch)\n",
    "                        preds = torch.sigmoid(outputs)\n",
    "                        preds = accelerator.gather(preds)\n",
    "                        test_preds_batch += preds.data.cpu().numpy().reshape(-1)\n",
    "                        counter += 1\n",
    "                test_preds_batch = test_preds_batch / counter\n",
    "                test_preds.append(test_preds_batch)\n",
    "        \n",
    "        test_predictions_df[f\"fold_{fold}\"] = np.concatenate(test_preds)\n",
    "    test_predictions_df[target_column] = test_predictions_df[[f\"fold_{fold}\" for fold in all_folds]].mean(axis=1)\n",
    "    return test_predictions_df[[id_column, target_column]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "87258f90",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-27T16:48:44.323302Z",
     "iopub.status.busy": "2024-07-27T16:48:44.323024Z",
     "iopub.status.idle": "2024-07-27T16:48:44.327198Z",
     "shell.execute_reply": "2024-07-27T16:48:44.326393Z"
    },
    "papermill": {
     "duration": 0.011761,
     "end_time": "2024-07-27T16:48:44.329068",
     "exception": false,
     "start_time": "2024-07-27T16:48:44.317307",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_predict_function_topology = {\n",
    "    \"lgb\": get_boosting_predictions,\n",
    "    \"cb\": get_boosting_predictions,\n",
    "    \"resnet18\": get_dnn_predictions,\n",
    "    \"efficientnet_b0\": get_dnn_predictions\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "733de062",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-27T16:48:44.339611Z",
     "iopub.status.busy": "2024-07-27T16:48:44.339311Z",
     "iopub.status.idle": "2024-07-27T16:48:55.156956Z",
     "shell.execute_reply": "2024-07-27T16:48:55.155765Z"
    },
    "papermill": {
     "duration": 10.825466,
     "end_time": "2024-07-27T16:48:55.159292",
     "exception": false,
     "start_time": "2024-07-27T16:48:44.333826",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating predictions for cb_v1\n",
      "Total number of columns: 60\n",
      "\n",
      "\n",
      "Generating predictions for lgb_v3\n",
      "Total number of columns: 60\n",
      "\n",
      "\n",
      "Generating predictions for resnet18_v2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  1.16it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  9.27it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  9.22it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  9.47it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  8.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Generating predictions for efficientnet_b0_v1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  3.67it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  6.38it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  6.31it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  6.45it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  6.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "ensemble_preds = 0\n",
    "previous_model_name = None\n",
    "for idx, (model_name, version, path, weight) in enumerate(zip(model_names, versions, paths, weights)):\n",
    "    print(f\"Generating predictions for {model_name}_{version}\")\n",
    "    model_preds_df = model_predict_function_topology[model_name](train_metadata, test_metadata, test_images, model_name, version, Path(path))\n",
    "    if idx == 0:\n",
    "        ensemble_preds_df = model_preds_df.copy()\n",
    "    else:\n",
    "        ensemble_preds_df = ensemble_preds_df.merge(model_preds_df, on=id_column, how=\"inner\", suffixes=(f\"_{previous_model_name}\", \"\"))\n",
    "    ensemble_preds += ensemble_preds_df[target_column].rank(pct=True).values * weight\n",
    "    previous_model_name = model_name\n",
    "    print(\"\\n\")\n",
    "ensemble_preds_df.rename(columns={target_column: f\"{target_column}_{previous_model_name}\"}, inplace=True)\n",
    "ensemble_preds_df[target_column] = ensemble_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8b1eb73d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-27T16:48:55.177925Z",
     "iopub.status.busy": "2024-07-27T16:48:55.177348Z",
     "iopub.status.idle": "2024-07-27T16:48:55.194699Z",
     "shell.execute_reply": "2024-07-27T16:48:55.193847Z"
    },
    "papermill": {
     "duration": 0.028548,
     "end_time": "2024-07-27T16:48:55.196506",
     "exception": false,
     "start_time": "2024-07-27T16:48:55.167958",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>isic_id</th>\n",
       "      <th>target_cb</th>\n",
       "      <th>target_lgb</th>\n",
       "      <th>target_resnet18</th>\n",
       "      <th>target_efficientnet_b0</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ISIC_0015657</td>\n",
       "      <td>0.000182</td>\n",
       "      <td>0.000036</td>\n",
       "      <td>0.117095</td>\n",
       "      <td>0.032948</td>\n",
       "      <td>2.922226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ISIC_0015729</td>\n",
       "      <td>0.000023</td>\n",
       "      <td>0.000028</td>\n",
       "      <td>0.003008</td>\n",
       "      <td>0.002231</td>\n",
       "      <td>1.085186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ISIC_0015740</td>\n",
       "      <td>0.000113</td>\n",
       "      <td>0.000049</td>\n",
       "      <td>0.004665</td>\n",
       "      <td>0.005005</td>\n",
       "      <td>2.503706</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        isic_id  target_cb  target_lgb  target_resnet18  \\\n",
       "0  ISIC_0015657   0.000182    0.000036         0.117095   \n",
       "1  ISIC_0015729   0.000023    0.000028         0.003008   \n",
       "2  ISIC_0015740   0.000113    0.000049         0.004665   \n",
       "\n",
       "   target_efficientnet_b0    target  \n",
       "0                0.032948  2.922226  \n",
       "1                0.002231  1.085186  \n",
       "2                0.005005  2.503706  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ensemble_preds_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "905914fd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-27T16:48:55.215312Z",
     "iopub.status.busy": "2024-07-27T16:48:55.214840Z",
     "iopub.status.idle": "2024-07-27T16:48:55.223151Z",
     "shell.execute_reply": "2024-07-27T16:48:55.222350Z"
    },
    "papermill": {
     "duration": 0.019687,
     "end_time": "2024-07-27T16:48:55.225099",
     "exception": false,
     "start_time": "2024-07-27T16:48:55.205412",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    3.000000\n",
       "mean     2.170373\n",
       "std      0.962815\n",
       "min      1.085186\n",
       "25%      1.794446\n",
       "50%      2.503706\n",
       "75%      2.712966\n",
       "max      2.922226\n",
       "Name: target, dtype: float64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ensemble_preds_df[target_column].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "62aa11ea",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-27T16:48:55.244283Z",
     "iopub.status.busy": "2024-07-27T16:48:55.243831Z",
     "iopub.status.idle": "2024-07-27T16:48:55.252543Z",
     "shell.execute_reply": "2024-07-27T16:48:55.251773Z"
    },
    "papermill": {
     "duration": 0.019979,
     "end_time": "2024-07-27T16:48:55.254392",
     "exception": false,
     "start_time": "2024-07-27T16:48:55.234413",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>isic_id</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ISIC_0015657</td>\n",
       "      <td>2.922226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ISIC_0015729</td>\n",
       "      <td>1.085186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ISIC_0015740</td>\n",
       "      <td>2.503706</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        isic_id    target\n",
       "0  ISIC_0015657  2.922226\n",
       "1  ISIC_0015729  1.085186\n",
       "2  ISIC_0015740  2.503706"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ensemble_preds_df[[id_column, target_column]].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3441d205",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-27T16:48:55.274493Z",
     "iopub.status.busy": "2024-07-27T16:48:55.274175Z",
     "iopub.status.idle": "2024-07-27T16:48:55.281294Z",
     "shell.execute_reply": "2024-07-27T16:48:55.280609Z"
    },
    "papermill": {
     "duration": 0.019031,
     "end_time": "2024-07-27T16:48:55.283218",
     "exception": false,
     "start_time": "2024-07-27T16:48:55.264187",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "ensemble_preds_df[[id_column, target_column]].to_csv(\"submission.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7808ca3",
   "metadata": {
    "papermill": {
     "duration": 0.008572,
     "end_time": "2024-07-27T16:48:55.300886",
     "exception": false,
     "start_time": "2024-07-27T16:48:55.292314",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "databundleVersionId": 9094797,
     "sourceId": 63056,
     "sourceType": "competition"
    },
    {
     "datasetId": 5454133,
     "sourceId": 9046472,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 5454216,
     "sourceId": 9046476,
     "sourceType": "datasetVersion"
    },
    {
     "sourceId": 187477024,
     "sourceType": "kernelVersion"
    },
    {
     "sourceId": 189656082,
     "sourceType": "kernelVersion"
    },
    {
     "sourceId": 189785376,
     "sourceType": "kernelVersion"
    },
    {
     "sourceId": 189786208,
     "sourceType": "kernelVersion"
    }
   ],
   "dockerImageVersionId": 30733,
   "isGpuEnabled": true,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 43.10001,
   "end_time": "2024-07-27T16:48:57.433291",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-07-27T16:48:14.333281",
   "version": "2.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
