{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "182463fc",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2024-08-27T04:32:16.667432Z",
     "iopub.status.busy": "2024-08-27T04:32:16.667091Z",
     "iopub.status.idle": "2024-08-27T04:32:25.954566Z",
     "shell.execute_reply": "2024-08-27T04:32:25.953785Z"
    },
    "papermill": {
     "duration": 9.297672,
     "end_time": "2024-08-27T04:32:25.956916",
     "exception": false,
     "start_time": "2024-08-27T04:32:16.659244",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import gc\n",
    "import time\n",
    "import json\n",
    "import joblib\n",
    "from pprint import pprint\n",
    "from typing import List, Dict\n",
    "from collections import defaultdict\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import h5py\n",
    "from io import BytesIO\n",
    "from PIL import Image\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from timm import create_model\n",
    "\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "\n",
    "from accelerate import Accelerator\n",
    "\n",
    "from isic_helper import DotDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9fbab250",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-27T04:32:25.970405Z",
     "iopub.status.busy": "2024-08-27T04:32:25.969921Z",
     "iopub.status.idle": "2024-08-27T04:32:25.978825Z",
     "shell.execute_reply": "2024-08-27T04:32:25.977957Z"
    },
    "papermill": {
     "duration": 0.01772,
     "end_time": "2024-08-27T04:32:25.980866",
     "exception": false,
     "start_time": "2024-08-27T04:32:25.963146",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "id_column = \"isic_id\"\n",
    "target_column = \"target\"\n",
    "group_column = \"patient_id\"\n",
    "fold_column = \"fold\"\n",
    "\n",
    "INPUT_PATH = Path(\"/kaggle/input/isic-2024-challenge/\")\n",
    "\n",
    "boosting_model_names = [\"xgb\", \"xgb\", \"lgb\"]\n",
    "boosting_versions = [\"v1\", \"v2\", \"v6\"]\n",
    "boosting_modes = [\"train\", \"train\", \"train\"]\n",
    "boosting_oof_columns = [f\"oof_{model_name}_{version}\" for model_name, version in zip(boosting_model_names, boosting_versions)]\n",
    "boosting_paths = [f\"/kaggle/input/isic-scd-{model_name.replace('_', '-')}-{version}-{mode}\" for model_name, version, mode in zip(\n",
    "    boosting_model_names, boosting_versions, boosting_modes)]\n",
    "\n",
    "cnn_model_names = [\"efficientnet_b2\", \"efficientnet_b2\", \"resnet18\"]\n",
    "cnn_versions = [\"v1\", \"v2\", \"v1\"]\n",
    "cnn_modes = [\"pretrain\", \"pretrain\", \"pretrain\"]\n",
    "cnn_oof_columns = [f\"oof_{model_name}_{version}\" for model_name, version in zip(cnn_model_names, cnn_versions)]\n",
    "cnn_paths = [f\"/kaggle/input/isic-scd-{model_name.replace('_', '-')}-{version}-{mode}\" for model_name, version, mode in zip(\n",
    "    cnn_model_names, cnn_versions, cnn_modes)]\n",
    "\n",
    "oof_columns = boosting_oof_columns + cnn_oof_columns\n",
    "\n",
    "weights = [\n",
    "    9.184200253001404,\n",
    "    0.8552034877824392,\n",
    "    2.4021046742664947,\n",
    "    4.764737619598357,\n",
    "    3.2308662644235215,\n",
    "    1.282657759225282\n",
    "]\n",
    "\n",
    "SAMPLE_SIZE = 5000\n",
    "EXPECTED_TEST_SIZE = 500000\n",
    "TOTAL_RUNTIME = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d1fdf32b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-27T04:32:25.994109Z",
     "iopub.status.busy": "2024-08-27T04:32:25.993842Z",
     "iopub.status.idle": "2024-08-27T04:32:26.037732Z",
     "shell.execute_reply": "2024-08-27T04:32:26.036877Z"
    },
    "papermill": {
     "duration": 0.053131,
     "end_time": "2024-08-27T04:32:26.039787",
     "exception": false,
     "start_time": "2024-08-27T04:32:25.986656",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "numerical_features = [\n",
    "    \"age_approx\",\n",
    "    \"clin_size_long_diam_mm\",\n",
    "    \"tbp_lv_A\", \"tbp_lv_Aext\",\n",
    "    \"tbp_lv_B\", \"tbp_lv_Bext\",\n",
    "    \"tbp_lv_C\", \"tbp_lv_Cext\",\n",
    "    \"tbp_lv_H\", \"tbp_lv_Hext\",\n",
    "    \"tbp_lv_L\", \"tbp_lv_Lext\",\n",
    "    \"tbp_lv_areaMM2\",\n",
    "    \"tbp_lv_area_perim_ratio\",\n",
    "    \"tbp_lv_color_std_mean\",\n",
    "    \"tbp_lv_deltaA\", \"tbp_lv_deltaB\", \"tbp_lv_deltaL\", \"tbp_lv_deltaLB\", \"tbp_lv_deltaLBnorm\",\n",
    "    \"tbp_lv_eccentricity\",\n",
    "    \"tbp_lv_minorAxisMM\",\n",
    "    \"tbp_lv_nevi_confidence\",\n",
    "    \"tbp_lv_norm_border\", \"tbp_lv_norm_color\",\n",
    "    \"tbp_lv_perimeterMM\",\n",
    "    \"tbp_lv_radial_color_std_max\",\n",
    "    \"tbp_lv_stdL\", \"tbp_lv_stdLExt\",\n",
    "    \"tbp_lv_symm_2axis\", \"tbp_lv_symm_2axis_angle\",\n",
    "    \"tbp_lv_x\", \"tbp_lv_y\", \"tbp_lv_z\",\n",
    "]\n",
    "\n",
    "ord_categorical_features = [\n",
    "    \"sex\",\n",
    "    \"tbp_lv_location\",\n",
    "    \"tbp_tile_type\",\n",
    "    \"tbp_lv_location_simple\",\n",
    "]\n",
    "\n",
    "ohe_categorical_features = [\n",
    "    \"anatom_site_general\", \n",
    "    \"attribution\",\n",
    "]\n",
    "\n",
    "attribution_mapper = {\n",
    "    \"Memorial Sloan Kettering Cancer Center\": \"MSKCC\",\n",
    "    \"ACEMID MIA\": \"ACEMIDMIA\",\n",
    "    \"Department of Dermatology, Hospital Cl√≠nic de Barcelona\": \"DoD_HCB\",\n",
    "    \"University Hospital of Basel\": \"UHB\",\n",
    "    \"Frazer Institute, The University of Queensland, Dermatology Research Centre\": \"FI_TUQ-DRC\",\n",
    "    \"Department of Dermatology, University of Athens, Andreas Syggros Hospital of Skin and Venereal Diseases, Alexander Stratigos, Konstantinos Liopyris\": \"DoD_UA\",\n",
    "    \"ViDIR Group, Department of Dermatology, Medical University of Vienna\": \"ViDIR\"\n",
    "}\n",
    "\n",
    "def boosting_preprocess(df):\n",
    "    df[\"anatom_site_general\"] = df[\"anatom_site_general\"].fillna(\"missing_site\")\n",
    "    df[\"sex\"] = df[\"sex\"].fillna(\"missing_sex\")\n",
    "    df[\"tbp_tile_type\"] = df[\"tbp_tile_type\"].map({\"3D: white\": \"white\", \"3D: XP\": \"XP\"})\n",
    "    df[\"attribution\"] = df[\"attribution\"].map(attribution_mapper)\n",
    "    return df\n",
    "\n",
    "def norm_feature(df, value_col, group_cols=[group_column], err=1e-5):\n",
    "    stats = [\"mean\", \"std\"]\n",
    "    tmp = df.groupby(group_cols)[value_col].agg(stats)\n",
    "    tmp.columns = [f\"{value_col}_{stat}\" for stat in stats]\n",
    "    tmp.reset_index(inplace=True)\n",
    "    df = df.merge(tmp, on=group_cols, how=\"left\")\n",
    "    feature_name = f\"{value_col}_patient_norm\"\n",
    "    df[feature_name] = ((df[value_col] - df[f\"{value_col}_mean\"]) / \n",
    "                                       (df[f\"{value_col}_std\"] + err))\n",
    "    return df, feature_name\n",
    "\n",
    "def count_features(df, col):\n",
    "    tmp = df[[id_column, group_column, col]].pivot_table(\n",
    "        values=id_column, \n",
    "        index=group_column, \n",
    "        columns=col, \n",
    "        aggfunc=\"count\", \n",
    "        fill_value=0)\n",
    "    feature_cols = tmp.columns.tolist()\n",
    "    tmp.reset_index(inplace=True)\n",
    "    tmp.index.name = None\n",
    "    df = df.merge(tmp, on=group_column, how=\"left\")\n",
    "    return df, feature_cols\n",
    "\n",
    "def boosting_feature_engineering(df, err=1e-5):\n",
    "    new_num_cols = []\n",
    "    \n",
    "    df[\"lesion_size_ratio\"] = df[\"tbp_lv_minorAxisMM\"] / df[\"clin_size_long_diam_mm\"]\n",
    "    new_num_cols += [\"lesion_size_ratio\"]\n",
    "    \n",
    "    df[\"lesion_shape_index\"] = df[\"tbp_lv_areaMM2\"] / df[\"tbp_lv_perimeterMM\"]**2\n",
    "    new_num_cols += [\"lesion_shape_index\"]\n",
    "    \n",
    "    df[\"hue_contrast\"] = np.abs(df[\"tbp_lv_H\"] - df[\"tbp_lv_Hext\"])\n",
    "    new_num_cols += [\"hue_contrast\"]\n",
    "    \n",
    "    df[\"luminance_contrast\"] = np.abs(df[\"tbp_lv_L\"] - df[\"tbp_lv_Lext\"])\n",
    "    new_num_cols += [\"luminance_contrast\"]\n",
    "    \n",
    "    df[\"lesion_color_difference\"] = np.sqrt(df[\"tbp_lv_deltaA\"]**2 +\n",
    "                                            df[\"tbp_lv_deltaB\"]**2 +\n",
    "                                            df[\"tbp_lv_deltaL\"]**2)\n",
    "    new_num_cols += [\"lesion_color_difference\"]\n",
    "    \n",
    "    df[\"border_complexity\"] = df[\"tbp_lv_norm_border\"] + df[\"tbp_lv_symm_2axis\"]\n",
    "    new_num_cols += [\"border_complexity\"]\n",
    "    \n",
    "    df[\"color_uniformity\"] = df[\"tbp_lv_color_std_mean\"] / (df[\"tbp_lv_radial_color_std_max\"] + err)\n",
    "    new_num_cols += [\"color_uniformity\"]\n",
    "    \n",
    "    df[\"position_distance_3d\"] = np.sqrt(df[\"tbp_lv_x\"]**2 +\n",
    "                                         df[\"tbp_lv_y\"]**2 +\n",
    "                                         df[\"tbp_lv_z\"]**2)\n",
    "    new_num_cols += [\"position_distance_3d\"]\n",
    "    \n",
    "    df[\"perimeter_to_area_ratio\"] = df[\"tbp_lv_perimeterMM\"] / df[\"tbp_lv_areaMM2\"]\n",
    "    new_num_cols += [\"perimeter_to_area_ratio\"]\n",
    "    \n",
    "    df[\"area_to_perimeter_ratio\"] = df[\"tbp_lv_areaMM2\"] / df[\"tbp_lv_perimeterMM\"]\n",
    "    new_num_cols += [\"area_to_perimeter_ratio\"]\n",
    "    \n",
    "    df[\"lesion_visibility_score\"] = df[\"tbp_lv_deltaLBnorm\"] + df[\"tbp_lv_norm_color\"]\n",
    "    new_num_cols += [\"lesion_visibility_score\"]\n",
    "    \n",
    "    df[\"symmetry_border_consistency\"] = df[\"tbp_lv_symm_2axis\"] * df[\"tbp_lv_norm_border\"]\n",
    "    new_num_cols += [\"symmetry_border_consistency\"]\n",
    "    \n",
    "    df[\"consistency_symmetry_border\"] = (df[\"tbp_lv_symm_2axis\"] * df[\"tbp_lv_norm_border\"] /\n",
    "                                         (df[\"tbp_lv_symm_2axis\"] + df[\"tbp_lv_norm_border\"]))\n",
    "    new_num_cols += [\"consistency_symmetry_border\"]\n",
    "    \n",
    "    df[\"color_consistency\"] = df[\"tbp_lv_stdL\"] / df[\"tbp_lv_Lext\"]\n",
    "    new_num_cols += [\"color_consistency\"]\n",
    "    \n",
    "    df[\"consistency_color\"] = (df[\"tbp_lv_stdL\"] * df[\"tbp_lv_Lext\"] /\n",
    "                               (df[\"tbp_lv_stdL\"] * df[\"tbp_lv_Lext\"]))\n",
    "    new_num_cols += [\"consistency_color\"]\n",
    "    \n",
    "    df[\"size_age_interaction\"] = df[\"clin_size_long_diam_mm\"] * df[\"age_approx\"]\n",
    "    new_num_cols += [\"size_age_interaction\"]\n",
    "    \n",
    "    df[\"hue_color_std_interaction\"] = df[\"tbp_lv_H\"] * df[\"tbp_lv_color_std_mean\"]\n",
    "    new_num_cols += [\"hue_color_std_interaction\"]\n",
    "    \n",
    "    df[\"lesion_severity_index\"] = (df[\"tbp_lv_norm_border\"] +\n",
    "                                   df[\"tbp_lv_norm_color\"] +\n",
    "                                   df[\"tbp_lv_eccentricity\"]) / 3\n",
    "    new_num_cols += [\"lesion_severity_index\"]\n",
    "    \n",
    "    df[\"shape_complexity_index\"] = df[\"border_complexity\"] + df[\"lesion_shape_index\"]\n",
    "    new_num_cols += [\"shape_complexity_index\"]\n",
    "    \n",
    "    df[\"color_contrast_index\"] = (df[\"tbp_lv_deltaA\"] +\n",
    "                                  df[\"tbp_lv_deltaB\"] + \n",
    "                                  df[\"tbp_lv_deltaL\"] +\n",
    "                                  df[\"tbp_lv_deltaLBnorm\"])\n",
    "    new_num_cols += [\"color_contrast_index\"]\n",
    "    \n",
    "    df[\"log_lesion_area\"] = np.log1p(df[\"tbp_lv_areaMM2\"])\n",
    "    new_num_cols += [\"log_lesion_area\"]\n",
    "    \n",
    "    df[\"normalized_lesion_size\"] = df[\"clin_size_long_diam_mm\"] / df[\"age_approx\"]\n",
    "    new_num_cols += [\"normalized_lesion_size\"]\n",
    "    \n",
    "    df[\"mean_hue_difference\"] = (df[\"tbp_lv_H\"] + df[\"tbp_lv_Hext\"]) / 2\n",
    "    new_num_cols += [\"mean_hue_difference\"]\n",
    "    \n",
    "    df[\"std_dev_contrast\"] = np.sqrt((df[\"tbp_lv_deltaA\"]**2 +\n",
    "                                      df[\"tbp_lv_deltaB\"]**2 + \n",
    "                                      df[\"tbp_lv_deltaL\"]**2) / 3)\n",
    "    new_num_cols += [\"std_dev_contrast\"]\n",
    "    \n",
    "    df[\"color_shape_composite_index\"] = (df[\"tbp_lv_color_std_mean\"] + \n",
    "                                         df[\"tbp_lv_area_perim_ratio\"] +\n",
    "                                         df[\"tbp_lv_symm_2axis\"]) / 3\n",
    "    new_num_cols += [\"color_shape_composite_index\"]\n",
    "    \n",
    "    df[\"lesion_orientation_3d\"] = np.arctan2(df[\"tbp_lv_y\"], df[\"tbp_lv_x\"])\n",
    "    new_num_cols += [\"lesion_orientation_3d\"]\n",
    "    \n",
    "    df[\"overall_color_difference\"] = (df[\"tbp_lv_deltaA\"] + \n",
    "                                      df[\"tbp_lv_deltaB\"] + \n",
    "                                      df[\"tbp_lv_deltaL\"]) / 3\n",
    "    new_num_cols += [\"overall_color_difference\"]\n",
    "    \n",
    "    df[\"symmetry_perimeter_interaction\"] = df[\"tbp_lv_symm_2axis\"] * df[\"tbp_lv_perimeterMM\"]\n",
    "    new_num_cols += [\"symmetry_perimeter_interaction\"]\n",
    "    \n",
    "    df[\"comprehensive_lesion_index\"] = (df[\"tbp_lv_area_perim_ratio\"] +\n",
    "                                        df[\"tbp_lv_eccentricity\"] +\n",
    "                                        df[\"tbp_lv_norm_color\"] +\n",
    "                                        df[\"tbp_lv_symm_2axis\"]) / 4\n",
    "    new_num_cols += [\"comprehensive_lesion_index\"]\n",
    "    \n",
    "    df[\"color_variance_ratio\"] = df[\"tbp_lv_color_std_mean\"] / df[\"tbp_lv_stdLExt\"]\n",
    "    new_num_cols += [\"color_variance_ratio\"]\n",
    "    \n",
    "    df[\"border_color_interaction\"] = df[\"tbp_lv_norm_border\"] * df[\"tbp_lv_norm_color\"]\n",
    "    new_num_cols += [\"border_color_interaction\"]\n",
    "    \n",
    "    df[\"border_color_interaction_2\"] = ((df[\"tbp_lv_norm_border\"] * df[\"tbp_lv_norm_color\"]) /\n",
    "                                        (df[\"tbp_lv_norm_border\"] + df[\"tbp_lv_norm_color\"]))\n",
    "    new_num_cols += [\"border_color_interaction_2\"]\n",
    "    \n",
    "    df[\"size_color_contrast_ratio\"] = df[\"clin_size_long_diam_mm\"] / df[\"tbp_lv_deltaLBnorm\"]\n",
    "    new_num_cols += [\"size_color_contrast_ratio\"]\n",
    "    \n",
    "    df[\"age_normalized_nevi_confidence\"] = df[\"tbp_lv_nevi_confidence\"] / df[\"age_approx\"]\n",
    "    new_num_cols += [\"age_normalized_nevi_confidence\"]\n",
    "    \n",
    "    df[\"age_normalized_nevi_confidence_2\"] = np.sqrt(df[\"tbp_lv_nevi_confidence\"]**2 + df[\"age_approx\"]**2)\n",
    "    new_num_cols += [\"age_normalized_nevi_confidence_2\"]\n",
    "    \n",
    "    df[\"color_asymmetry_index\"] = df[\"tbp_lv_radial_color_std_max\"] * df[\"tbp_lv_symm_2axis\"]\n",
    "    new_num_cols += [\"color_asymmetry_index\"]\n",
    "    \n",
    "    df[\"volume_approximation_3d\"] = df[\"tbp_lv_areaMM2\"] * np.sqrt(df[\"tbp_lv_x\"]**2 +\n",
    "                                                                   df[\"tbp_lv_y\"]**2 +\n",
    "                                                                   df[\"tbp_lv_z\"]**2)\n",
    "    new_num_cols += [\"volume_approximation_3d\"]\n",
    "    \n",
    "    df[\"color_range\"] = (np.abs(df[\"tbp_lv_L\"] - df[\"tbp_lv_Lext\"]) +\n",
    "                         np.abs(df[\"tbp_lv_A\"] - df[\"tbp_lv_Aext\"]) +\n",
    "                         np.abs(df[\"tbp_lv_B\"] - df[\"tbp_lv_Bext\"]))\n",
    "    new_num_cols += [\"color_range\"]\n",
    "    \n",
    "    df[\"shape_color_consistency\"] = df[\"tbp_lv_eccentricity\"] * df[\"tbp_lv_color_std_mean\"]\n",
    "    new_num_cols += [\"shape_color_consistency\"]\n",
    "    \n",
    "    df[\"border_length_ratio\"] = df[\"tbp_lv_perimeterMM\"] / np.sqrt(2 * df[\"tbp_lv_areaMM2\"])\n",
    "    new_num_cols += [\"border_length_ratio\"]\n",
    "    \n",
    "    df[\"age_size_symmetry_index\"] = (df[\"age_approx\"] *\n",
    "                                     df[\"clin_size_long_diam_mm\"] *\n",
    "                                     df[\"tbp_lv_symm_2axis\"])\n",
    "    new_num_cols += [\"age_size_symmetry_index\"]\n",
    "    \n",
    "    df[\"age_area_symmetry\"] = (df[\"age_approx\"] *\n",
    "                               df[\"tbp_lv_areaMM2\"] *\n",
    "                               df[\"tbp_lv_symm_2axis\"])\n",
    "    new_num_cols += [\"age_area_symmetry\"]\n",
    "    \n",
    "    for col in numerical_features:\n",
    "        df, feature_name = norm_feature(df, col)\n",
    "        new_num_cols += [feature_name]\n",
    "    \n",
    "    df[\"num_images\"] = df[group_column].map(df.groupby(group_column)[id_column].count())\n",
    "    new_num_cols += [\"num_images\"]\n",
    "\n",
    "    return df, new_num_cols\n",
    "\n",
    "\n",
    "# class PAUC:\n",
    "#     def get_final_error(self, error, weight):\n",
    "#         return error\n",
    "\n",
    "#     def is_max_optimal(self):\n",
    "#         return True\n",
    "\n",
    "#     def evaluate(self, approxes, target, weight):\n",
    "#         y_true = target.astype(int)\n",
    "#         y_pred = approxes[0].astype(float)\n",
    "        \n",
    "#         score = compute_pauc(y_true, y_pred, min_tpr=0.8)\n",
    "        \n",
    "#         return score, 1.0\n",
    "\n",
    "\n",
    "def pauc_80(y_train, y_pred):\n",
    "    score_value = compute_pauc(y_train, y_pred, min_tpr=0.8)   \n",
    "    return score_value\n",
    "\n",
    "\n",
    "def get_boosting_predictions(train, test, model_name, version, path, oof_column):\n",
    "    start_time = time.time()\n",
    "    with open(path / f\"{model_name}_{version}_run_metadata.json\", \"r\") as f:\n",
    "        run_metadata = json.load(f)\n",
    "    pprint(run_metadata)\n",
    "    \n",
    "    with open(path / f\"{model_name}_{version}_encoder.joblib\", \"rb\") as f:\n",
    "        mixed_encoded_preprocessor = joblib.load(f)\n",
    "\n",
    "    enc = mixed_encoded_preprocessor.fit(train)\n",
    "    X_test = enc.transform(test)\n",
    "\n",
    "    columns_for_model = len(X_test.columns)\n",
    "    print(f\"Total number of columns: {columns_for_model}\")\n",
    "        \n",
    "    all_folds = np.unique(train[fold_column])\n",
    "#     all_folds = [1]\n",
    "    test_predictions_df = pd.DataFrame({id_column: test[id_column]})\n",
    "    for fold in all_folds:\n",
    "        model_filepath = path / f\"models/{model_name}_{version}_fold_{fold}.txt\"\n",
    "        with open(model_filepath, \"rb\") as f:\n",
    "            estimator = joblib.load(f)\n",
    "        test_predictions_df[f\"fold_{fold}\"] = estimator.predict_proba(X_test)[:, -1]\n",
    "    test_predictions_df[oof_column] = test_predictions_df[[f\"fold_{fold}\" for fold in all_folds]].mean(axis=1)\n",
    "    end_time = time.time()\n",
    "    return test_predictions_df[[id_column, oof_column]], (end_time - start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "55d44a7a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-27T04:32:26.053042Z",
     "iopub.status.busy": "2024-08-27T04:32:26.052759Z",
     "iopub.status.idle": "2024-08-27T04:32:58.004527Z",
     "shell.execute_reply": "2024-08-27T04:32:58.003582Z"
    },
    "papermill": {
     "duration": 31.960798,
     "end_time": "2024-08-27T04:32:58.006859",
     "exception": false,
     "start_time": "2024-08-27T04:32:26.046061",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data size: (401059, 56)\n",
      "Test data size: (3, 44)\n"
     ]
    }
   ],
   "source": [
    "train_metadata = pd.read_csv(INPUT_PATH / \"train-metadata.csv\", low_memory=False, na_values=[\"NA\"])\n",
    "test_metadata = pd.read_csv(INPUT_PATH / \"test-metadata.csv\", low_memory=False, na_values=[\"NA\"])\n",
    "\n",
    "folds_df = pd.read_csv(\"/kaggle/input/isic-scd-folds/folds.csv\")\n",
    "train_metadata = train_metadata.merge(folds_df, on=[id_column, group_column], how=\"inner\")\n",
    "print(f\"Train data size: {train_metadata.shape}\")\n",
    "print(f\"Test data size: {test_metadata.shape}\")\n",
    "\n",
    "train_metadata = boosting_preprocess(train_metadata)\n",
    "test_metadata = boosting_preprocess(test_metadata)\n",
    "\n",
    "train_metadata, new_num_cols = boosting_feature_engineering(train_metadata)\n",
    "test_metadata, _ = boosting_feature_engineering(test_metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1957b83c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-27T04:32:58.021043Z",
     "iopub.status.busy": "2024-08-27T04:32:58.020270Z",
     "iopub.status.idle": "2024-08-27T04:33:05.695823Z",
     "shell.execute_reply": "2024-08-27T04:33:05.694778Z"
    },
    "papermill": {
     "duration": 7.685037,
     "end_time": "2024-08-27T04:33:05.698276",
     "exception": false,
     "start_time": "2024-08-27T04:32:58.013239",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating predictions for xgb_v1\n",
      "{'best_num_rounds': {'fold_1': 82,\n",
      "                     'fold_2': 173,\n",
      "                     'fold_3': 20,\n",
      "                     'fold_4': 142,\n",
      "                     'fold_5': 77},\n",
      " 'config': {'_key': None,\n",
      "            '_parent': None,\n",
      "            '_temp': False,\n",
      "            'model_name': 'xgb_v1',\n",
      "            'models_output_dir': 'models',\n",
      "            'sampling_ratio': 0.01,\n",
      "            'seed': 2022},\n",
      " 'cv_auc_avg': 0.9673757713901316,\n",
      " 'cv_auc_oof': 0.9464921630675764,\n",
      " 'cv_auc_std': 0.006521637731286478,\n",
      " 'cv_pauc_avg': 0.17368981947890508,\n",
      " 'cv_pauc_oof': 0.15296119492851015,\n",
      " 'cv_pauc_std': 0.00587196296972231,\n",
      " 'es_rounds': 150,\n",
      " 'num_rounds': 2000,\n",
      " 'params': {'alpha': 0.6779926606782505,\n",
      "            'colsample_bylevel': 0.5476090898823716,\n",
      "            'colsample_bynode': 0.9928601203635129,\n",
      "            'colsample_bytree': 0.8437772277074493,\n",
      "            'disable_default_eval_metric': True,\n",
      "            'enable_categorical': True,\n",
      "            'lambda': 8.879624125465703,\n",
      "            'learning_rate': 0.08501257473292347,\n",
      "            'max_depth': 6,\n",
      "            'random_state': 2022,\n",
      "            'scale_pos_weight': 3.29440313334688,\n",
      "            'subsample': 0.6012681388711075,\n",
      "            'tree_method': 'hist',\n",
      "            'verbosity': 0},\n",
      " 'val_auc_scores': {'fold_1': 0.9763855695822203,\n",
      "                    'fold_2': 0.9572885288935904,\n",
      "                    'fold_3': 0.9635023430382749,\n",
      "                    'fold_4': 0.9709627048208559,\n",
      "                    'fold_5': 0.9687397106157167},\n",
      " 'val_pauc_scores': {'fold_1': 0.18367412688887158,\n",
      "                     'fold_2': 0.16537818384974395,\n",
      "                     'fold_3': 0.17194383259911888,\n",
      "                     'fold_4': 0.17426448565474031,\n",
      "                     'fold_5': 0.17318846840205077}}\n",
      "Total number of columns: 86\n",
      "\n",
      "\n",
      "Generating predictions for xgb_v2\n",
      "{'best_num_rounds': {'fold_1': 106,\n",
      "                     'fold_2': 196,\n",
      "                     'fold_3': 118,\n",
      "                     'fold_4': 112,\n",
      "                     'fold_5': 44},\n",
      " 'config': {'_key': None,\n",
      "            '_parent': None,\n",
      "            '_temp': False,\n",
      "            'model_name': 'xgb_v2',\n",
      "            'models_output_dir': 'models',\n",
      "            'sampling_ratio': 0.01,\n",
      "            'seed': 2022},\n",
      " 'cv_auc_avg': 0.9667334024019318,\n",
      " 'cv_auc_oof': 0.9584420660973526,\n",
      " 'cv_auc_std': 0.004672574423174126,\n",
      " 'cv_pauc_avg': 0.17260122602267397,\n",
      " 'cv_pauc_oof': 0.1645339574493963,\n",
      " 'cv_pauc_std': 0.004837525595179168,\n",
      " 'es_rounds': 150,\n",
      " 'num_rounds': 2000,\n",
      " 'params': {'alpha': 0.6779926606782505,\n",
      "            'colsample_bylevel': 0.5476090898823716,\n",
      "            'colsample_bynode': 0.9928601203635129,\n",
      "            'colsample_bytree': 0.8437772277074493,\n",
      "            'disable_default_eval_metric': True,\n",
      "            'enable_categorical': True,\n",
      "            'lambda': 8.879624125465703,\n",
      "            'learning_rate': 0.08501257473292347,\n",
      "            'max_depth': 6,\n",
      "            'random_state': 2022,\n",
      "            'scale_pos_weight': 3.29440313334688,\n",
      "            'subsample': 0.6012681388711075,\n",
      "            'tree_method': 'hist',\n",
      "            'verbosity': 0},\n",
      " 'val_auc_scores': {'fold_1': 0.9751129113471103,\n",
      "                    'fold_2': 0.963817176741778,\n",
      "                    'fold_3': 0.9639184585241667,\n",
      "                    'fold_4': 0.9684925309805195,\n",
      "                    'fold_5': 0.9623259344160846},\n",
      " 'val_pauc_scores': {'fold_1': 0.18166898925849218,\n",
      "                     'fold_2': 0.17040633221405424,\n",
      "                     'fold_3': 0.17186716127341475,\n",
      "                     'fold_4': 0.17183237448677788,\n",
      "                     'fold_5': 0.16723127288063078}}\n",
      "Total number of columns: 128\n",
      "\n",
      "\n",
      "Generating predictions for lgb_v6\n",
      "{'best_num_rounds': {'fold_1': 267,\n",
      "                     'fold_2': 493,\n",
      "                     'fold_3': 409,\n",
      "                     'fold_4': 605,\n",
      "                     'fold_5': 185},\n",
      " 'config': {'_key': None,\n",
      "            '_parent': None,\n",
      "            '_temp': False,\n",
      "            'model_name': 'lgb_v6',\n",
      "            'models_output_dir': 'models',\n",
      "            'sampling_ratio': 0.01,\n",
      "            'seed': 2022},\n",
      " 'cv_auc_avg': 0.9669392381585942,\n",
      " 'cv_auc_oof': 0.9646024610753375,\n",
      " 'cv_auc_std': 0.0073841692717788975,\n",
      " 'cv_pauc_avg': 0.17245002747303687,\n",
      " 'cv_pauc_oof': 0.17008720048549186,\n",
      " 'cv_pauc_std': 0.007484726322328974,\n",
      " 'es_rounds': 150,\n",
      " 'num_rounds': 2000,\n",
      " 'params': {'bagging_fraction': 0.7738954452473223,\n",
      "            'bagging_freq': 4,\n",
      "            'boosting_type': 'gbdt',\n",
      "            'colsample_bynode': 0.4025961355653304,\n",
      "            'colsample_bytree': 0.8329551585827726,\n",
      "            'lambda_l1': 0.08758718919397321,\n",
      "            'lambda_l2': 0.0039689175176025465,\n",
      "            'learning_rate': 0.02,\n",
      "            'max_depth': 4,\n",
      "            'metric': 'custom',\n",
      "            'min_data_in_leaf': 85,\n",
      "            'num_leaves': 103,\n",
      "            'objective': 'binary',\n",
      "            'random_state': 2022,\n",
      "            'scale_pos_weight': 2.7984184778875543,\n",
      "            'verbosity': -1},\n",
      " 'val_auc_scores': {'fold_1': 0.9772534016017052,\n",
      "                    'fold_2': 0.9545421675104455,\n",
      "                    'fold_3': 0.9649406908687025,\n",
      "                    'fold_4': 0.9693242939686264,\n",
      "                    'fold_5': 0.9686356368434913},\n",
      " 'val_pauc_scores': {'fold_1': 0.18387722064924852,\n",
      "                     'fold_2': 0.16025631426335243,\n",
      "                     'fold_3': 0.17205357477131192,\n",
      "                     'fold_4': 0.17308064294717396,\n",
      "                     'fold_5': 0.17298238473409747}}\n",
      "Total number of columns: 128\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "if test_metadata.shape[0] == 3:\n",
    "    test_metadata = train_metadata.sample(n=SAMPLE_SIZE, random_state=42)\n",
    "for idx, (model_name, version, path, oof_column) in enumerate(zip(boosting_model_names, boosting_versions, boosting_paths, boosting_oof_columns)):\n",
    "    print(f\"Generating predictions for {model_name}_{version}\")\n",
    "    model_preds_df, runtime = get_boosting_predictions(\n",
    "        train_metadata, \n",
    "        test_metadata,\n",
    "        model_name, \n",
    "        version, \n",
    "        Path(path),\n",
    "        oof_column\n",
    "    )\n",
    "    print(\"\\n\")\n",
    "    if idx == 0:\n",
    "        ensemble_preds_df = model_preds_df.copy()\n",
    "    else:\n",
    "        ensemble_preds_df = ensemble_preds_df.merge(model_preds_df, on=id_column, how=\"left\")\n",
    "    TOTAL_RUNTIME += runtime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "baeaa3be",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-27T04:33:05.713729Z",
     "iopub.status.busy": "2024-08-27T04:33:05.712656Z",
     "iopub.status.idle": "2024-08-27T04:33:05.941883Z",
     "shell.execute_reply": "2024-08-27T04:33:05.941015Z"
    },
    "papermill": {
     "duration": 0.238985,
     "end_time": "2024-08-27T04:33:05.944098",
     "exception": false,
     "start_time": "2024-08-27T04:33:05.705113",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "88"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del train_metadata, test_metadata\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a9f2cb8c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-27T04:33:05.959487Z",
     "iopub.status.busy": "2024-08-27T04:33:05.959171Z",
     "iopub.status.idle": "2024-08-27T04:33:06.011100Z",
     "shell.execute_reply": "2024-08-27T04:33:06.010315Z"
    },
    "papermill": {
     "duration": 0.062074,
     "end_time": "2024-08-27T04:33:06.013059",
     "exception": false,
     "start_time": "2024-08-27T04:33:05.950985",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "feature_mapping_dict = {\n",
    "    \"sex\": defaultdict(lambda: 0, {\n",
    "        \"missing_sex\": 0,\n",
    "        \"female\": 1,\n",
    "        \"male\": 2,\n",
    "    }),\n",
    "    \"anatom_site_general\": defaultdict(lambda: 0, {\n",
    "        \"missing_anatom_site_general\": 0,\n",
    "        \"lower extremity\": 1,\n",
    "        \"head/neck\": 2,\n",
    "        \"posterior torso\": 3,\n",
    "        \"anterior torso\": 4,\n",
    "        \"upper extremity\": 5,\n",
    "    }),\n",
    "    \"tbp_tile_type\": defaultdict(lambda: 0, {\n",
    "        \"3D: white\": 0,\n",
    "        \"3D: XP\": 1,\n",
    "    }),\n",
    "    \"tbp_lv_location\": defaultdict(lambda: 0, {\n",
    "        \"Unknown\": 0,\n",
    "        \"Right Leg - Upper\": 1,\n",
    "        \"Head & Neck\": 2,\n",
    "        \"Torso Back Top Third\": 3,\n",
    "        \"Torso Front Top Half\": 4,\n",
    "        \"Right Arm - Upper\": 5,\n",
    "        \"Left Leg - Upper\": 6,\n",
    "        \"Torso Front Bottom Half\": 7,\n",
    "        \"Left Arm - Upper\": 8,\n",
    "        \"Right Leg\": 9,\n",
    "        \"Torso Back Middle Third\": 10,\n",
    "        \"Right Arm - Lower\": 11,\n",
    "        \"Right Leg - Lower\": 12,\n",
    "        \"Left Leg - Lower\": 13,\n",
    "        \"Left Arm - Lower\": 14,\n",
    "        \"Left Leg\": 15,\n",
    "        \"Torso Back Bottom Third\": 16,\n",
    "        \"Left Arm\": 17,\n",
    "        \"Right Arm\": 18,\n",
    "        \"Torso Front\": 19,\n",
    "        \"Torso Back\": 20\n",
    "    }),\n",
    "    \"tbp_lv_location_simple\": defaultdict(lambda: 0, {\n",
    "        \"Unknown\": 0,\n",
    "        \"Right Leg\": 1,\n",
    "        \"Head & Neck\": 2,\n",
    "        \"Torso Back\": 3,\n",
    "        \"Torso Front\": 4,\n",
    "        \"Right Arm\": 5,\n",
    "        \"Left Leg\": 6,\n",
    "        \"Left Arm\": 7,\n",
    "    }),\n",
    "}\n",
    "\n",
    "\n",
    "def cnn_preprocess(df):\n",
    "    df[\"age_approx\"] = df[\"age_approx\"].fillna(0)\n",
    "    df[\"age_approx\"] = df[\"age_approx\"] / 90\n",
    "    df[\"sex\"] = df[\"sex\"].fillna(\"missing_sex\")\n",
    "    df[\"sex\"] = df[\"sex\"].map(feature_mapping_dict[\"sex\"])\n",
    "    df[\"anatom_site_general\"] = df[\"anatom_site_general\"].fillna(\"missing_anatom_site_general\")\n",
    "    df[\"anatom_site_general\"] = df[\"anatom_site_general\"].map(feature_mapping_dict[\"anatom_site_general\"])\n",
    "    df[\"tbp_tile_type\"] = df[\"tbp_tile_type\"].map(feature_mapping_dict[\"tbp_tile_type\"])\n",
    "    df[\"tbp_lv_location\"] = df[\"tbp_lv_location\"].map(feature_mapping_dict[\"tbp_lv_location\"])\n",
    "    df[\"tbp_lv_location_simple\"] = df[\"tbp_lv_location_simple\"].map(feature_mapping_dict[\"tbp_lv_location_simple\"])\n",
    "    return df\n",
    "\n",
    "\n",
    "def get_emb_szs(cat_cols):\n",
    "    emb_szs = {}\n",
    "    for col in cat_cols:\n",
    "        emb_szs[col] = (len(feature_mapping_dict[col]), min(600, round(1.6 * len(feature_mapping_dict[col]) ** 0.56)))\n",
    "    return emb_szs\n",
    "\n",
    "\n",
    "def cnn_feature_engineering(df, stats_dict=None):\n",
    "    cat_cols = [\"sex\", \"anatom_site_general\",\n",
    "                \"tbp_tile_type\", \"tbp_lv_location\", \"tbp_lv_location_simple\"]\n",
    "    cont_cols = [\"age_approx\",\n",
    "                 \"clin_size_long_diam_mm\",\n",
    "                 \"tbp_lv_A\", \"tbp_lv_Aext\",\n",
    "                 \"tbp_lv_B\", \"tbp_lv_Bext\",\n",
    "                 \"tbp_lv_C\", \"tbp_lv_Cext\",\n",
    "                 \"tbp_lv_H\", \"tbp_lv_Hext\",\n",
    "                 \"tbp_lv_L\", \"tbp_lv_Lext\",\n",
    "                 \"tbp_lv_areaMM2\", \"tbp_lv_area_perim_ratio\",\n",
    "                 \"tbp_lv_color_std_mean\",\n",
    "                 \"tbp_lv_deltaA\", \"tbp_lv_deltaB\", \"tbp_lv_deltaL\", \"tbp_lv_deltaLB\", \"tbp_lv_deltaLBnorm\",\n",
    "                 \"tbp_lv_eccentricity\",\n",
    "                 \"tbp_lv_minorAxisMM\", \"tbp_lv_nevi_confidence\", \"tbp_lv_norm_border\",\n",
    "                 \"tbp_lv_norm_color\", \"tbp_lv_perimeterMM\",\n",
    "                 \"tbp_lv_radial_color_std_max\", \"tbp_lv_stdL\", \"tbp_lv_stdLExt\",\n",
    "                 \"tbp_lv_symm_2axis\", \"tbp_lv_symm_2axis_angle\",\n",
    "                 \"tbp_lv_x\", \"tbp_lv_y\", \"tbp_lv_z\"\n",
    "                 ]\n",
    "\n",
    "    df[\"num_images\"] = df[\"patient_id\"].map(df.groupby(\"patient_id\")[\"isic_id\"].count())\n",
    "    cont_cols.append(\"num_images\")\n",
    "\n",
    "    df[\"num_images\"] = np.log1p(df[\"num_images\"])\n",
    "\n",
    "    if stats_dict is None:\n",
    "        stats_dict = {}\n",
    "        for col in cont_cols:\n",
    "            if col not in [\"num_images\", \"age_approx\"]:\n",
    "                stats_dict[col] = {\"mean\": df[col].mean(), \"std\": df[col].std()}\n",
    "                df[col] = (df[col] - stats_dict[col][\"mean\"]) / stats_dict[col][\"std\"]\n",
    "    else:\n",
    "        for col in cont_cols:\n",
    "            if col not in [\"num_images\", \"age_approx\"]:\n",
    "                df[col] = (df[col] - stats_dict[col][\"mean\"]) / stats_dict[col][\"std\"]\n",
    "    return df, cat_cols, cont_cols, stats_dict\n",
    "\n",
    "def test_augment(image_size, mean=None, std=None):\n",
    "    if mean is not None and std is not None:\n",
    "        normalize = A.Normalize(mean=mean, std=std, max_pixel_value=255.0, p=1.0)\n",
    "    else:\n",
    "        normalize = A.Normalize(max_pixel_value=255.0, p=1.0)\n",
    "    transform = A.Compose(\n",
    "        [A.Resize(image_size, image_size), normalize, ToTensorV2()], p=1.0\n",
    "    )\n",
    "    return transform\n",
    "\n",
    "\n",
    "class ISICDataset(Dataset):\n",
    "    def __init__(self, metadata, images, augment,\n",
    "                 use_meta=False, cat_cols: List = None, cont_cols: List = None,\n",
    "                 infer=False):\n",
    "        self.metadata = metadata\n",
    "        self.images = images\n",
    "        self.augment = augment\n",
    "        self.use_meta = use_meta\n",
    "        self.cat_cols = cat_cols\n",
    "        self.cont_cols = cont_cols\n",
    "        self.length = len(self.metadata)\n",
    "        self.infer = infer\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.length\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        row = self.metadata.iloc[index]\n",
    "        image = np.array(Image.open(BytesIO(self.images[row[\"isic_id\"]][()])))\n",
    "        if self.augment is not None:\n",
    "            image = self.augment(image=image)[\"image\"].float()\n",
    "\n",
    "        if self.use_meta:\n",
    "            x_cat = torch.tensor([row[col] for col in self.cat_cols], dtype=torch.long)\n",
    "            x_cont = torch.tensor([row[col] for col in self.cont_cols], dtype=torch.float)\n",
    "        else:\n",
    "            x_cat = torch.tensor(0)\n",
    "            x_cont = torch.tensor(0)\n",
    "\n",
    "        if self.infer:\n",
    "            return image, x_cat, x_cont\n",
    "        else:\n",
    "            target = torch.tensor(row[\"target\"])\n",
    "            return image, x_cat, x_cont, target\n",
    "\n",
    "    \n",
    "class ISICNet(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        model_name,\n",
    "        pretrained=True,\n",
    "        use_meta=False,\n",
    "        cat_cols: List = None, cont_cols: List = None, emb_szs: Dict = None,\n",
    "    ):\n",
    "        super(ISICNet, self).__init__()\n",
    "        self.model = create_model(\n",
    "            model_name=model_name,\n",
    "            pretrained=pretrained,\n",
    "            in_chans=3,\n",
    "            num_classes=0,\n",
    "            global_pool=\"\",\n",
    "        )\n",
    "        in_dim = self.model.num_features\n",
    "        self.dropouts = nn.ModuleList([nn.Dropout(0.5) for _ in range(5)])\n",
    "        self.use_meta = use_meta\n",
    "        if use_meta:\n",
    "            self.linear = nn.Linear(in_dim, 256)\n",
    "\n",
    "            self.embeddings = nn.ModuleList([nn.Embedding(emb_szs[col][0], emb_szs[col][1]) for col in cat_cols])\n",
    "            self.embedding_dropout = nn.Dropout(0.1)\n",
    "            n_emb = sum([emb_szs[col][1] for col in cat_cols])\n",
    "            n_cont = len(cont_cols)\n",
    "            self.bn_cont = nn.BatchNorm1d(n_cont)\n",
    "            self.meta = nn.Sequential(\n",
    "                nn.Linear(n_emb + n_cont, 256),\n",
    "                nn.BatchNorm1d(256),\n",
    "                nn.SiLU(),\n",
    "                nn.Dropout(0.3),\n",
    "                nn.Linear(256, 64),\n",
    "                nn.BatchNorm1d(64),\n",
    "                nn.SiLU(),\n",
    "                nn.Dropout(0.1),\n",
    "            )\n",
    "            self.classifier = nn.Linear(256 + 64, 1)\n",
    "        else:\n",
    "            self.linear = nn.Linear(in_dim, 1)\n",
    "\n",
    "    def forward(self, images, x_cat=None, x_cont=None):\n",
    "        x = self.model(images)\n",
    "        bs = len(images)\n",
    "        pool = F.adaptive_avg_pool2d(x, 1).reshape(bs, -1)\n",
    "        if self.training:\n",
    "            x_image = 0\n",
    "            for i in range(len(self.dropouts)):\n",
    "                x_image += self.linear(self.dropouts[i](pool))\n",
    "            x_image = x_image / len(self.dropouts)\n",
    "        else:\n",
    "            x_image = self.linear(pool)\n",
    "\n",
    "        if self.use_meta:\n",
    "            x_cat = [emb(x_cat[:, i]) for i, emb in enumerate(self.embeddings)]\n",
    "            x_cat = torch.cat(x_cat, 1)\n",
    "            x_cat = self.embedding_dropout(x_cat)\n",
    "            x_cont = self.bn_cont(x_cont)\n",
    "            x_meta = self.meta(torch.cat([x_cat, x_cont], 1))\n",
    "            x = torch.cat([x_image, x_meta], 1)\n",
    "            logits = self.classifier(x)\n",
    "        else:\n",
    "            logits = x_image\n",
    "        return logits\n",
    "\n",
    "\n",
    "def get_trans(img, iteration):\n",
    "    if iteration >= 6:\n",
    "        img = img.transpose(2, 3)\n",
    "    if iteration % 6 == 0:\n",
    "        return img\n",
    "    elif iteration % 6 == 1:\n",
    "        return torch.flip(img, dims=[2])\n",
    "    elif iteration % 6 == 2:\n",
    "        return torch.flip(img, dims=[3])\n",
    "    elif iteration % 6 == 3:\n",
    "        return torch.rot90(img, 1, dims=[2, 3])\n",
    "    elif iteration % 6 == 4:\n",
    "        return torch.rot90(img, 2, dims=[2, 3])\n",
    "    elif iteration % 6 == 5:\n",
    "        return torch.rot90(img, 3, dims=[2, 3])\n",
    "\n",
    "    \n",
    "def predict(model, test_dataloader, accelerator, n_tta, use_meta, log_interval=10):\n",
    "    model.eval()\n",
    "    test_probs = []\n",
    "    total_steps = len(test_dataloader)\n",
    "    with torch.no_grad():\n",
    "        for step, (images, x_cat, x_cont) in enumerate(test_dataloader):\n",
    "            logits = 0\n",
    "            probs = 0\n",
    "            for i in range(n_tta):\n",
    "                if use_meta:\n",
    "                    logits_iter = model(get_trans(images, i), x_cat, x_cont)\n",
    "                else:\n",
    "                    logits_iter = model(get_trans(images, i))\n",
    "                logits += logits_iter\n",
    "                probs += torch.sigmoid(logits_iter)\n",
    "            logits /= n_tta\n",
    "            probs /= n_tta\n",
    "\n",
    "            probs = accelerator.gather(probs)\n",
    "            test_probs.append(probs)\n",
    "\n",
    "            if (step == 0) or ((step + 1) % log_interval == 0):\n",
    "                print(f\"Step: {step + 1}/{total_steps}\")\n",
    "\n",
    "    test_probs = torch.cat(test_probs).cpu().numpy()\n",
    "    return test_probs\n",
    "\n",
    "\n",
    "def get_dnn_predictions(train, test, images, model_name, version, path, oof_column):\n",
    "    start_time = time.time()\n",
    "    with open(path / f\"{model_name}_{version}_run_metadata.json\", \"r\") as f:\n",
    "        run_metadata = json.load(f)\n",
    "    pprint(run_metadata[\"params\"])\n",
    "    \n",
    "    image_size = run_metadata[\"params\"][\"image_size\"]\n",
    "    batch_size = run_metadata[\"params\"][\"val_batch_size\"]\n",
    "    use_meta = run_metadata[\"params\"][\"use_meta\"]\n",
    "    \n",
    "    test_dataset = ISICDataset(\n",
    "        test, images, augment=test_augment(image_size), \n",
    "        use_meta=use_meta,\n",
    "        cat_cols=cat_cols,\n",
    "        cont_cols=cont_cols,\n",
    "        infer=True\n",
    "    )\n",
    "    test_dataloader = DataLoader(\n",
    "        test_dataset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=False,\n",
    "        num_workers=4,\n",
    "        drop_last=False,\n",
    "        pin_memory=True,\n",
    "    )\n",
    "\n",
    "    all_folds = np.unique(train[fold_column])\n",
    "#     all_folds = [1]\n",
    "    test_predictions_df = pd.DataFrame({id_column: test[id_column]})\n",
    "    for fold in all_folds:\n",
    "        print(f\"\\nFold {fold}\")\n",
    "        accelerator = Accelerator(\n",
    "            mixed_precision=run_metadata[\"params\"][\"mixed_precision\"],\n",
    "        )\n",
    "        \n",
    "        model = ISICNet(model_name=model_name, pretrained=False,\n",
    "                        use_meta=use_meta,\n",
    "                        cat_cols=cat_cols,\n",
    "                        cont_cols=cont_cols,\n",
    "                        emb_szs=emb_szs,)\n",
    "        model = model.to(accelerator.device)\n",
    "        \n",
    "        model, test_dataloader = accelerator.prepare(model, test_dataloader)\n",
    "        model_filepath = path / f\"models/fold_{fold}\"\n",
    "        accelerator.load_state(model_filepath)\n",
    "\n",
    "        test_predictions_df[f\"fold_{fold}\"] = predict(model, test_dataloader, accelerator, n_tta=run_metadata[\"params\"][\"n_tta\"], use_meta=use_meta)\n",
    "    test_predictions_df[oof_column] = test_predictions_df[[f\"fold_{fold}\" for fold in all_folds]].mean(axis=1)\n",
    "    end_time = time.time()\n",
    "    return test_predictions_df[[id_column, oof_column]], (end_time - start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8c16a5fd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-27T04:33:06.028041Z",
     "iopub.status.busy": "2024-08-27T04:33:06.027705Z",
     "iopub.status.idle": "2024-08-27T04:33:15.649765Z",
     "shell.execute_reply": "2024-08-27T04:33:15.648958Z"
    },
    "papermill": {
     "duration": 9.632067,
     "end_time": "2024-08-27T04:33:15.652033",
     "exception": false,
     "start_time": "2024-08-27T04:33:06.019966",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data size: (401059, 56)\n",
      "Test data size: (3, 44)\n"
     ]
    }
   ],
   "source": [
    "train_metadata = pd.read_csv(INPUT_PATH / \"train-metadata.csv\", low_memory=False, na_values=[\"NA\"])\n",
    "test_metadata = pd.read_csv(INPUT_PATH / \"test-metadata.csv\", low_memory=False, na_values=[\"NA\"])\n",
    "\n",
    "folds_df = pd.read_csv(\"/kaggle/input/isic-scd-folds/folds.csv\")\n",
    "train_metadata = train_metadata.merge(folds_df, on=[id_column, group_column], how=\"inner\")\n",
    "print(f\"Train data size: {train_metadata.shape}\")\n",
    "print(f\"Test data size: {test_metadata.shape}\")\n",
    "\n",
    "train_metadata = cnn_preprocess(train_metadata)\n",
    "test_metadata = cnn_preprocess(test_metadata)\n",
    "\n",
    "train_metadata, cat_cols, cont_cols, stats_dict = cnn_feature_engineering(train_metadata)\n",
    "test_metadata, _, _, _ = cnn_feature_engineering(test_metadata, stats_dict=stats_dict)\n",
    "emb_szs = get_emb_szs(cat_cols)\n",
    "\n",
    "train_images = h5py.File(INPUT_PATH / \"train-image.hdf5\", mode=\"r\")\n",
    "test_images = h5py.File(INPUT_PATH / \"test-image.hdf5\", mode=\"r\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "73ff0f59",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-27T04:33:15.667245Z",
     "iopub.status.busy": "2024-08-27T04:33:15.666926Z",
     "iopub.status.idle": "2024-08-27T04:36:28.705920Z",
     "shell.execute_reply": "2024-08-27T04:36:28.704544Z"
    },
    "papermill": {
     "duration": 193.048989,
     "end_time": "2024-08-27T04:36:28.708043",
     "exception": false,
     "start_time": "2024-08-27T04:33:15.659054",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating predictions for efficientnet_b2_v1\n",
      "{'debug': False,\n",
      " 'down_sampling': True,\n",
      " 'image_size': 128,\n",
      " 'init_lr': 3e-05,\n",
      " 'mixed_precision': 'fp16',\n",
      " 'mode': 'pretrain',\n",
      " 'n_tta': 8,\n",
      " 'num_epochs': 20,\n",
      " 'num_workers': 8,\n",
      " 'seed': 2022,\n",
      " 'train_batch_size': 64,\n",
      " 'use_meta': True,\n",
      " 'val_batch_size': 512}\n",
      "\n",
      "Fold 1\n",
      "Step: 1/10\n",
      "Step: 10/10\n",
      "\n",
      "Fold 2\n",
      "Step: 1/10\n",
      "Step: 10/10\n",
      "\n",
      "Fold 3\n",
      "Step: 1/10\n",
      "Step: 10/10\n",
      "\n",
      "Fold 4\n",
      "Step: 1/10\n",
      "Step: 10/10\n",
      "\n",
      "Fold 5\n",
      "Step: 1/10\n",
      "Step: 10/10\n",
      "\n",
      "\n",
      "Generating predictions for efficientnet_b2_v2\n",
      "{'debug': False,\n",
      " 'down_sampling': True,\n",
      " 'image_size': 92,\n",
      " 'init_lr': 3e-05,\n",
      " 'mixed_precision': 'fp16',\n",
      " 'mode': 'pretrain',\n",
      " 'n_tta': 8,\n",
      " 'num_epochs': 20,\n",
      " 'num_workers': 8,\n",
      " 'seed': 2022,\n",
      " 'train_batch_size': 64,\n",
      " 'use_meta': True,\n",
      " 'val_batch_size': 512}\n",
      "\n",
      "Fold 1\n",
      "Step: 1/10\n",
      "Step: 10/10\n",
      "\n",
      "Fold 2\n",
      "Step: 1/10\n",
      "Step: 10/10\n",
      "\n",
      "Fold 3\n",
      "Step: 1/10\n",
      "Step: 10/10\n",
      "\n",
      "Fold 4\n",
      "Step: 1/10\n",
      "Step: 10/10\n",
      "\n",
      "Fold 5\n",
      "Step: 1/10\n",
      "Step: 10/10\n",
      "\n",
      "\n",
      "Generating predictions for resnet18_v1\n",
      "{'debug': False,\n",
      " 'down_sampling': True,\n",
      " 'image_size': 128,\n",
      " 'init_lr': 3e-05,\n",
      " 'mixed_precision': 'fp16',\n",
      " 'mode': 'pretrain',\n",
      " 'n_tta': 8,\n",
      " 'num_epochs': 20,\n",
      " 'num_workers': 8,\n",
      " 'seed': 2022,\n",
      " 'train_batch_size': 64,\n",
      " 'use_meta': True,\n",
      " 'val_batch_size': 512}\n",
      "\n",
      "Fold 1\n",
      "Step: 1/10\n",
      "Step: 10/10\n",
      "\n",
      "Fold 2\n",
      "Step: 1/10\n",
      "Step: 10/10\n",
      "\n",
      "Fold 3\n",
      "Step: 1/10\n",
      "Step: 10/10\n",
      "\n",
      "Fold 4\n",
      "Step: 1/10\n",
      "Step: 10/10\n",
      "\n",
      "Fold 5\n",
      "Step: 1/10\n",
      "Step: 10/10\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "if test_metadata.shape[0] == 3:\n",
    "    test_metadata = train_metadata.sample(n=SAMPLE_SIZE, random_state=42)\n",
    "    test_images = train_images\n",
    "for idx, (model_name, version, path, oof_column) in enumerate(zip(cnn_model_names, cnn_versions, cnn_paths, cnn_oof_columns)):\n",
    "    print(f\"Generating predictions for {model_name}_{version}\")\n",
    "    model_preds_df, runtime = get_dnn_predictions(\n",
    "        train_metadata, \n",
    "        test_metadata,\n",
    "        test_images,\n",
    "        model_name, \n",
    "        version, \n",
    "        Path(path),\n",
    "        oof_column\n",
    "    )\n",
    "    print(\"\\n\")\n",
    "    ensemble_preds_df = ensemble_preds_df.merge(model_preds_df, on=id_column, how=\"left\")\n",
    "    TOTAL_RUNTIME += runtime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "75ceacec",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-27T04:36:28.730538Z",
     "iopub.status.busy": "2024-08-27T04:36:28.730180Z",
     "iopub.status.idle": "2024-08-27T04:36:28.736077Z",
     "shell.execute_reply": "2024-08-27T04:36:28.735201Z"
    },
    "papermill": {
     "duration": 0.019721,
     "end_time": "2024-08-27T04:36:28.738373",
     "exception": false,
     "start_time": "2024-08-27T04:36:28.718652",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expected total runtime during submission: 334 mins and 16.996917724609375 secs\n"
     ]
    }
   ],
   "source": [
    "factor = EXPECTED_TEST_SIZE / SAMPLE_SIZE\n",
    "expected_total_runtime = TOTAL_RUNTIME * factor\n",
    "total_runtime_minutes = int(expected_total_runtime // 60)\n",
    "total_runtime_seconds = expected_total_runtime % 60\n",
    "print(f\"Expected total runtime during submission: {total_runtime_minutes} mins and {total_runtime_seconds} secs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f62c37ef",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-27T04:36:28.759781Z",
     "iopub.status.busy": "2024-08-27T04:36:28.759443Z",
     "iopub.status.idle": "2024-08-27T04:36:28.780418Z",
     "shell.execute_reply": "2024-08-27T04:36:28.779566Z"
    },
    "papermill": {
     "duration": 0.033662,
     "end_time": "2024-08-27T04:36:28.782345",
     "exception": false,
     "start_time": "2024-08-27T04:36:28.748683",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>isic_id</th>\n",
       "      <th>oof_xgb_v1</th>\n",
       "      <th>oof_xgb_v2</th>\n",
       "      <th>oof_lgb_v6</th>\n",
       "      <th>oof_efficientnet_b2_v1</th>\n",
       "      <th>oof_efficientnet_b2_v2</th>\n",
       "      <th>oof_resnet18_v1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ISIC_6973879</td>\n",
       "      <td>0.007072</td>\n",
       "      <td>0.002608</td>\n",
       "      <td>0.001650</td>\n",
       "      <td>0.000019</td>\n",
       "      <td>0.000090</td>\n",
       "      <td>6.663231e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ISIC_5407194</td>\n",
       "      <td>0.005565</td>\n",
       "      <td>0.001158</td>\n",
       "      <td>0.000617</td>\n",
       "      <td>0.000014</td>\n",
       "      <td>0.000107</td>\n",
       "      <td>7.876630e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ISIC_5273739</td>\n",
       "      <td>0.008066</td>\n",
       "      <td>0.005405</td>\n",
       "      <td>0.006381</td>\n",
       "      <td>0.000225</td>\n",
       "      <td>0.002308</td>\n",
       "      <td>6.009169e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ISIC_0802250</td>\n",
       "      <td>0.006882</td>\n",
       "      <td>0.002557</td>\n",
       "      <td>0.003496</td>\n",
       "      <td>0.000042</td>\n",
       "      <td>0.000395</td>\n",
       "      <td>1.347116e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ISIC_8084953</td>\n",
       "      <td>0.117304</td>\n",
       "      <td>0.086990</td>\n",
       "      <td>0.129695</td>\n",
       "      <td>0.000091</td>\n",
       "      <td>0.000566</td>\n",
       "      <td>2.165027e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4995</th>\n",
       "      <td>ISIC_7957551</td>\n",
       "      <td>0.005735</td>\n",
       "      <td>0.001501</td>\n",
       "      <td>0.000910</td>\n",
       "      <td>0.000083</td>\n",
       "      <td>0.000278</td>\n",
       "      <td>4.376952e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4996</th>\n",
       "      <td>ISIC_7499278</td>\n",
       "      <td>0.006262</td>\n",
       "      <td>0.002116</td>\n",
       "      <td>0.001097</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>0.000145</td>\n",
       "      <td>1.715483e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4997</th>\n",
       "      <td>ISIC_5754512</td>\n",
       "      <td>0.007842</td>\n",
       "      <td>0.003500</td>\n",
       "      <td>0.004969</td>\n",
       "      <td>0.000041</td>\n",
       "      <td>0.000576</td>\n",
       "      <td>3.080450e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4998</th>\n",
       "      <td>ISIC_2067724</td>\n",
       "      <td>0.010438</td>\n",
       "      <td>0.005192</td>\n",
       "      <td>0.005186</td>\n",
       "      <td>0.000068</td>\n",
       "      <td>0.000262</td>\n",
       "      <td>1.566706e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4999</th>\n",
       "      <td>ISIC_5231518</td>\n",
       "      <td>0.005909</td>\n",
       "      <td>0.001789</td>\n",
       "      <td>0.001284</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.000020</td>\n",
       "      <td>2.171525e-07</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5000 rows √ó 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           isic_id  oof_xgb_v1  oof_xgb_v2  oof_lgb_v6  \\\n",
       "0     ISIC_6973879    0.007072    0.002608    0.001650   \n",
       "1     ISIC_5407194    0.005565    0.001158    0.000617   \n",
       "2     ISIC_5273739    0.008066    0.005405    0.006381   \n",
       "3     ISIC_0802250    0.006882    0.002557    0.003496   \n",
       "4     ISIC_8084953    0.117304    0.086990    0.129695   \n",
       "...            ...         ...         ...         ...   \n",
       "4995  ISIC_7957551    0.005735    0.001501    0.000910   \n",
       "4996  ISIC_7499278    0.006262    0.002116    0.001097   \n",
       "4997  ISIC_5754512    0.007842    0.003500    0.004969   \n",
       "4998  ISIC_2067724    0.010438    0.005192    0.005186   \n",
       "4999  ISIC_5231518    0.005909    0.001789    0.001284   \n",
       "\n",
       "      oof_efficientnet_b2_v1  oof_efficientnet_b2_v2  oof_resnet18_v1  \n",
       "0                   0.000019                0.000090     6.663231e-06  \n",
       "1                   0.000014                0.000107     7.876630e-07  \n",
       "2                   0.000225                0.002308     6.009169e-05  \n",
       "3                   0.000042                0.000395     1.347116e-05  \n",
       "4                   0.000091                0.000566     2.165027e-05  \n",
       "...                      ...                     ...              ...  \n",
       "4995                0.000083                0.000278     4.376952e-06  \n",
       "4996                0.000013                0.000145     1.715483e-06  \n",
       "4997                0.000041                0.000576     3.080450e-05  \n",
       "4998                0.000068                0.000262     1.566706e-05  \n",
       "4999                0.000002                0.000020     2.171525e-07  \n",
       "\n",
       "[5000 rows x 7 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ensemble_preds_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "40b9856a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-27T04:36:28.804228Z",
     "iopub.status.busy": "2024-08-27T04:36:28.803952Z",
     "iopub.status.idle": "2024-08-27T04:36:28.824629Z",
     "shell.execute_reply": "2024-08-27T04:36:28.823802Z"
    },
    "papermill": {
     "duration": 0.03373,
     "end_time": "2024-08-27T04:36:28.826641",
     "exception": false,
     "start_time": "2024-08-27T04:36:28.792911",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>isic_id</th>\n",
       "      <th>oof_xgb_v1</th>\n",
       "      <th>oof_xgb_v2</th>\n",
       "      <th>oof_lgb_v6</th>\n",
       "      <th>oof_efficientnet_b2_v1</th>\n",
       "      <th>oof_efficientnet_b2_v2</th>\n",
       "      <th>oof_resnet18_v1</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ISIC_6973879</td>\n",
       "      <td>0.007072</td>\n",
       "      <td>0.002608</td>\n",
       "      <td>0.001650</td>\n",
       "      <td>0.000019</td>\n",
       "      <td>0.000090</td>\n",
       "      <td>6.663231e-06</td>\n",
       "      <td>9.286090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ISIC_5407194</td>\n",
       "      <td>0.005565</td>\n",
       "      <td>0.001158</td>\n",
       "      <td>0.000617</td>\n",
       "      <td>0.000014</td>\n",
       "      <td>0.000107</td>\n",
       "      <td>7.876630e-07</td>\n",
       "      <td>2.695662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ISIC_5273739</td>\n",
       "      <td>0.008066</td>\n",
       "      <td>0.005405</td>\n",
       "      <td>0.006381</td>\n",
       "      <td>0.000225</td>\n",
       "      <td>0.002308</td>\n",
       "      <td>6.009169e-05</td>\n",
       "      <td>16.697294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ISIC_0802250</td>\n",
       "      <td>0.006882</td>\n",
       "      <td>0.002557</td>\n",
       "      <td>0.003496</td>\n",
       "      <td>0.000042</td>\n",
       "      <td>0.000395</td>\n",
       "      <td>1.347116e-05</td>\n",
       "      <td>12.144622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ISIC_8084953</td>\n",
       "      <td>0.117304</td>\n",
       "      <td>0.086990</td>\n",
       "      <td>0.129695</td>\n",
       "      <td>0.000091</td>\n",
       "      <td>0.000566</td>\n",
       "      <td>2.165027e-05</td>\n",
       "      <td>18.554648</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        isic_id  oof_xgb_v1  oof_xgb_v2  oof_lgb_v6  oof_efficientnet_b2_v1  \\\n",
       "0  ISIC_6973879    0.007072    0.002608    0.001650                0.000019   \n",
       "1  ISIC_5407194    0.005565    0.001158    0.000617                0.000014   \n",
       "2  ISIC_5273739    0.008066    0.005405    0.006381                0.000225   \n",
       "3  ISIC_0802250    0.006882    0.002557    0.003496                0.000042   \n",
       "4  ISIC_8084953    0.117304    0.086990    0.129695                0.000091   \n",
       "\n",
       "   oof_efficientnet_b2_v2  oof_resnet18_v1     target  \n",
       "0                0.000090     6.663231e-06   9.286090  \n",
       "1                0.000107     7.876630e-07   2.695662  \n",
       "2                0.002308     6.009169e-05  16.697294  \n",
       "3                0.000395     1.347116e-05  12.144622  \n",
       "4                0.000566     2.165027e-05  18.554648  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ensemble_preds = 0\n",
    "for idx, (oof_column, weight) in enumerate(zip(oof_columns, weights)):\n",
    "    ensemble_preds += ensemble_preds_df[oof_column].rank(pct=True).values * weight\n",
    "ensemble_preds_df[target_column] = ensemble_preds\n",
    "ensemble_preds_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "def8b306",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-27T04:36:28.850361Z",
     "iopub.status.busy": "2024-08-27T04:36:28.849662Z",
     "iopub.status.idle": "2024-08-27T04:36:28.860803Z",
     "shell.execute_reply": "2024-08-27T04:36:28.859812Z"
    },
    "papermill": {
     "duration": 0.025419,
     "end_time": "2024-08-27T04:36:28.862907",
     "exception": false,
     "start_time": "2024-08-27T04:36:28.837488",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    5000.000000\n",
       "mean       10.862057\n",
       "std         5.553865\n",
       "min         0.035798\n",
       "25%         6.314943\n",
       "50%        10.404242\n",
       "75%        15.374151\n",
       "max        21.717738\n",
       "Name: target, dtype: float64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ensemble_preds_df[target_column].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fe4c40c6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-27T04:36:28.886864Z",
     "iopub.status.busy": "2024-08-27T04:36:28.886486Z",
     "iopub.status.idle": "2024-08-27T04:36:28.898018Z",
     "shell.execute_reply": "2024-08-27T04:36:28.897090Z"
    },
    "papermill": {
     "duration": 0.025957,
     "end_time": "2024-08-27T04:36:28.900049",
     "exception": false,
     "start_time": "2024-08-27T04:36:28.874092",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>isic_id</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ISIC_6973879</td>\n",
       "      <td>9.286090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ISIC_5407194</td>\n",
       "      <td>2.695662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ISIC_5273739</td>\n",
       "      <td>16.697294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ISIC_0802250</td>\n",
       "      <td>12.144622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ISIC_8084953</td>\n",
       "      <td>18.554648</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        isic_id     target\n",
       "0  ISIC_6973879   9.286090\n",
       "1  ISIC_5407194   2.695662\n",
       "2  ISIC_5273739  16.697294\n",
       "3  ISIC_0802250  12.144622\n",
       "4  ISIC_8084953  18.554648"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ensemble_preds_df[[id_column, target_column]].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e78db881",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-27T04:36:28.924591Z",
     "iopub.status.busy": "2024-08-27T04:36:28.923629Z",
     "iopub.status.idle": "2024-08-27T04:36:28.949004Z",
     "shell.execute_reply": "2024-08-27T04:36:28.948141Z"
    },
    "papermill": {
     "duration": 0.040066,
     "end_time": "2024-08-27T04:36:28.951384",
     "exception": false,
     "start_time": "2024-08-27T04:36:28.911318",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "ensemble_preds_df[[id_column, target_column]].to_csv(\"submission.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a992761c",
   "metadata": {
    "papermill": {
     "duration": 0.010944,
     "end_time": "2024-08-27T04:36:28.973810",
     "exception": false,
     "start_time": "2024-08-27T04:36:28.962866",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "databundleVersionId": 9094797,
     "sourceId": 63056,
     "sourceType": "competition"
    },
    {
     "datasetId": 5554293,
     "sourceId": 9220637,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 5599623,
     "sourceId": 9255356,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 5554381,
     "sourceId": 9254696,
     "sourceType": "datasetVersion"
    },
    {
     "sourceId": 187477024,
     "sourceType": "kernelVersion"
    },
    {
     "sourceId": 193130710,
     "sourceType": "kernelVersion"
    },
    {
     "sourceId": 193248043,
     "sourceType": "kernelVersion"
    },
    {
     "sourceId": 193248172,
     "sourceType": "kernelVersion"
    },
    {
     "sourceId": 193248211,
     "sourceType": "kernelVersion"
    }
   ],
   "dockerImageVersionId": 30733,
   "isGpuEnabled": true,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 258.322669,
   "end_time": "2024-08-27T04:36:32.175354",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-08-27T04:32:13.852685",
   "version": "2.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
