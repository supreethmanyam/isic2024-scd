{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c9771e90",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2024-08-22T23:36:04.800901Z",
     "iopub.status.busy": "2024-08-22T23:36:04.800642Z",
     "iopub.status.idle": "2024-08-22T23:36:13.907982Z",
     "shell.execute_reply": "2024-08-22T23:36:13.907221Z"
    },
    "papermill": {
     "duration": 9.116691,
     "end_time": "2024-08-22T23:36:13.910235",
     "exception": false,
     "start_time": "2024-08-22T23:36:04.793544",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import gc\n",
    "import time\n",
    "import json\n",
    "import joblib\n",
    "from pprint import pprint\n",
    "from typing import List, Dict\n",
    "from collections import defaultdict\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import h5py\n",
    "from io import BytesIO\n",
    "from PIL import Image\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from timm import create_model\n",
    "\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "\n",
    "from accelerate import Accelerator\n",
    "\n",
    "from isic_helper import DotDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6125060f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-22T23:36:13.924053Z",
     "iopub.status.busy": "2024-08-22T23:36:13.923102Z",
     "iopub.status.idle": "2024-08-22T23:36:13.932685Z",
     "shell.execute_reply": "2024-08-22T23:36:13.931863Z"
    },
    "papermill": {
     "duration": 0.01815,
     "end_time": "2024-08-22T23:36:13.934620",
     "exception": false,
     "start_time": "2024-08-22T23:36:13.916470",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "id_column = \"isic_id\"\n",
    "target_column = \"target\"\n",
    "group_column = \"patient_id\"\n",
    "fold_column = \"fold\"\n",
    "\n",
    "INPUT_PATH = Path(\"/kaggle/input/isic-2024-challenge/\")\n",
    "\n",
    "boosting_model_names = [\"xgb\", \"xgb\", \"lgb\"]\n",
    "boosting_versions = [\"v1\", \"v2\", \"v6\"]\n",
    "boosting_modes = [\"train\", \"train\", \"train\"]\n",
    "boosting_oof_columns = [f\"oof_{model_name}_{version}\" for model_name, version in zip(boosting_model_names, boosting_versions)]\n",
    "boosting_paths = [f\"/kaggle/input/isic-scd-{model_name.replace('_', '-')}-{version}-{mode}\" for model_name, version, mode in zip(\n",
    "    boosting_model_names, boosting_versions, boosting_modes)]\n",
    "\n",
    "cnn_model_names = [\"efficientnet_b2\", \"seresnet50\"]\n",
    "cnn_versions = [\"v1\", \"v1\"]\n",
    "cnn_modes = [\"pretrain\", \"pretrain\"]\n",
    "cnn_oof_columns = [f\"oof_{model_name}_{version}\" for model_name, version in zip(cnn_model_names, cnn_versions)]\n",
    "cnn_paths = [f\"/kaggle/input/isic-scd-{model_name.replace('_', '-')}-{version}-{mode}\" for model_name, version, mode in zip(\n",
    "    cnn_model_names, cnn_versions, cnn_modes)]\n",
    "\n",
    "oof_columns = boosting_oof_columns + cnn_oof_columns\n",
    "\n",
    "weights = [\n",
    "    7.6301738560674535,\n",
    "    1.5282528312134354,\n",
    "    2.005918723856249,\n",
    "    4.900651372327644,\n",
    "    2.789006301548013\n",
    "]\n",
    "\n",
    "SAMPLE_SIZE = 5000\n",
    "EXPECTED_TEST_SIZE = 500000\n",
    "TOTAL_RUNTIME = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eb8bd642",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-22T23:36:13.947448Z",
     "iopub.status.busy": "2024-08-22T23:36:13.947192Z",
     "iopub.status.idle": "2024-08-22T23:36:13.989384Z",
     "shell.execute_reply": "2024-08-22T23:36:13.988741Z"
    },
    "papermill": {
     "duration": 0.050892,
     "end_time": "2024-08-22T23:36:13.991200",
     "exception": false,
     "start_time": "2024-08-22T23:36:13.940308",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "numerical_features = [\n",
    "    \"age_approx\",\n",
    "    \"clin_size_long_diam_mm\",\n",
    "    \"tbp_lv_A\", \"tbp_lv_Aext\",\n",
    "    \"tbp_lv_B\", \"tbp_lv_Bext\",\n",
    "    \"tbp_lv_C\", \"tbp_lv_Cext\",\n",
    "    \"tbp_lv_H\", \"tbp_lv_Hext\",\n",
    "    \"tbp_lv_L\", \"tbp_lv_Lext\",\n",
    "    \"tbp_lv_areaMM2\",\n",
    "    \"tbp_lv_area_perim_ratio\",\n",
    "    \"tbp_lv_color_std_mean\",\n",
    "    \"tbp_lv_deltaA\", \"tbp_lv_deltaB\", \"tbp_lv_deltaL\", \"tbp_lv_deltaLB\", \"tbp_lv_deltaLBnorm\",\n",
    "    \"tbp_lv_eccentricity\",\n",
    "    \"tbp_lv_minorAxisMM\",\n",
    "    \"tbp_lv_nevi_confidence\",\n",
    "    \"tbp_lv_norm_border\", \"tbp_lv_norm_color\",\n",
    "    \"tbp_lv_perimeterMM\",\n",
    "    \"tbp_lv_radial_color_std_max\",\n",
    "    \"tbp_lv_stdL\", \"tbp_lv_stdLExt\",\n",
    "    \"tbp_lv_symm_2axis\", \"tbp_lv_symm_2axis_angle\",\n",
    "    \"tbp_lv_x\", \"tbp_lv_y\", \"tbp_lv_z\",\n",
    "]\n",
    "\n",
    "ord_categorical_features = [\n",
    "    \"sex\",\n",
    "    \"tbp_lv_location\",\n",
    "    \"tbp_tile_type\",\n",
    "    \"tbp_lv_location_simple\",\n",
    "]\n",
    "\n",
    "ohe_categorical_features = [\n",
    "    \"anatom_site_general\", \n",
    "    \"attribution\",\n",
    "]\n",
    "\n",
    "attribution_mapper = {\n",
    "    \"Memorial Sloan Kettering Cancer Center\": \"MSKCC\",\n",
    "    \"ACEMID MIA\": \"ACEMIDMIA\",\n",
    "    \"Department of Dermatology, Hospital Cl√≠nic de Barcelona\": \"DoD_HCB\",\n",
    "    \"University Hospital of Basel\": \"UHB\",\n",
    "    \"Frazer Institute, The University of Queensland, Dermatology Research Centre\": \"FI_TUQ-DRC\",\n",
    "    \"Department of Dermatology, University of Athens, Andreas Syggros Hospital of Skin and Venereal Diseases, Alexander Stratigos, Konstantinos Liopyris\": \"DoD_UA\",\n",
    "    \"ViDIR Group, Department of Dermatology, Medical University of Vienna\": \"ViDIR\"\n",
    "}\n",
    "\n",
    "def boosting_preprocess(df):\n",
    "    df[\"anatom_site_general\"] = df[\"anatom_site_general\"].fillna(\"missing_site\")\n",
    "    df[\"sex\"] = df[\"sex\"].fillna(\"missing_sex\")\n",
    "    df[\"tbp_tile_type\"] = df[\"tbp_tile_type\"].map({\"3D: white\": \"white\", \"3D: XP\": \"XP\"})\n",
    "    df[\"attribution\"] = df[\"attribution\"].map(attribution_mapper)\n",
    "    return df\n",
    "\n",
    "def norm_feature(df, value_col, group_cols=[group_column], err=1e-5):\n",
    "    stats = [\"mean\", \"std\"]\n",
    "    tmp = df.groupby(group_cols)[value_col].agg(stats)\n",
    "    tmp.columns = [f\"{value_col}_{stat}\" for stat in stats]\n",
    "    tmp.reset_index(inplace=True)\n",
    "    df = df.merge(tmp, on=group_cols, how=\"left\")\n",
    "    feature_name = f\"{value_col}_patient_norm\"\n",
    "    df[feature_name] = ((df[value_col] - df[f\"{value_col}_mean\"]) / \n",
    "                                       (df[f\"{value_col}_std\"] + err))\n",
    "    return df, feature_name\n",
    "\n",
    "def count_features(df, col):\n",
    "    tmp = df[[id_column, group_column, col]].pivot_table(\n",
    "        values=id_column, \n",
    "        index=group_column, \n",
    "        columns=col, \n",
    "        aggfunc=\"count\", \n",
    "        fill_value=0)\n",
    "    feature_cols = tmp.columns.tolist()\n",
    "    tmp.reset_index(inplace=True)\n",
    "    tmp.index.name = None\n",
    "    df = df.merge(tmp, on=group_column, how=\"left\")\n",
    "    return df, feature_cols\n",
    "\n",
    "def boosting_feature_engineering(df, err=1e-5):\n",
    "    new_num_cols = []\n",
    "    \n",
    "    df[\"lesion_size_ratio\"] = df[\"tbp_lv_minorAxisMM\"] / df[\"clin_size_long_diam_mm\"]\n",
    "    new_num_cols += [\"lesion_size_ratio\"]\n",
    "    \n",
    "    df[\"lesion_shape_index\"] = df[\"tbp_lv_areaMM2\"] / df[\"tbp_lv_perimeterMM\"]**2\n",
    "    new_num_cols += [\"lesion_shape_index\"]\n",
    "    \n",
    "    df[\"hue_contrast\"] = np.abs(df[\"tbp_lv_H\"] - df[\"tbp_lv_Hext\"])\n",
    "    new_num_cols += [\"hue_contrast\"]\n",
    "    \n",
    "    df[\"luminance_contrast\"] = np.abs(df[\"tbp_lv_L\"] - df[\"tbp_lv_Lext\"])\n",
    "    new_num_cols += [\"luminance_contrast\"]\n",
    "    \n",
    "    df[\"lesion_color_difference\"] = np.sqrt(df[\"tbp_lv_deltaA\"]**2 +\n",
    "                                            df[\"tbp_lv_deltaB\"]**2 +\n",
    "                                            df[\"tbp_lv_deltaL\"]**2)\n",
    "    new_num_cols += [\"lesion_color_difference\"]\n",
    "    \n",
    "    df[\"border_complexity\"] = df[\"tbp_lv_norm_border\"] + df[\"tbp_lv_symm_2axis\"]\n",
    "    new_num_cols += [\"border_complexity\"]\n",
    "    \n",
    "    df[\"color_uniformity\"] = df[\"tbp_lv_color_std_mean\"] / (df[\"tbp_lv_radial_color_std_max\"] + err)\n",
    "    new_num_cols += [\"color_uniformity\"]\n",
    "    \n",
    "    df[\"position_distance_3d\"] = np.sqrt(df[\"tbp_lv_x\"]**2 +\n",
    "                                         df[\"tbp_lv_y\"]**2 +\n",
    "                                         df[\"tbp_lv_z\"]**2)\n",
    "    new_num_cols += [\"position_distance_3d\"]\n",
    "    \n",
    "    df[\"perimeter_to_area_ratio\"] = df[\"tbp_lv_perimeterMM\"] / df[\"tbp_lv_areaMM2\"]\n",
    "    new_num_cols += [\"perimeter_to_area_ratio\"]\n",
    "    \n",
    "    df[\"area_to_perimeter_ratio\"] = df[\"tbp_lv_areaMM2\"] / df[\"tbp_lv_perimeterMM\"]\n",
    "    new_num_cols += [\"area_to_perimeter_ratio\"]\n",
    "    \n",
    "    df[\"lesion_visibility_score\"] = df[\"tbp_lv_deltaLBnorm\"] + df[\"tbp_lv_norm_color\"]\n",
    "    new_num_cols += [\"lesion_visibility_score\"]\n",
    "    \n",
    "    df[\"symmetry_border_consistency\"] = df[\"tbp_lv_symm_2axis\"] * df[\"tbp_lv_norm_border\"]\n",
    "    new_num_cols += [\"symmetry_border_consistency\"]\n",
    "    \n",
    "    df[\"consistency_symmetry_border\"] = (df[\"tbp_lv_symm_2axis\"] * df[\"tbp_lv_norm_border\"] /\n",
    "                                         (df[\"tbp_lv_symm_2axis\"] + df[\"tbp_lv_norm_border\"]))\n",
    "    new_num_cols += [\"consistency_symmetry_border\"]\n",
    "    \n",
    "    df[\"color_consistency\"] = df[\"tbp_lv_stdL\"] / df[\"tbp_lv_Lext\"]\n",
    "    new_num_cols += [\"color_consistency\"]\n",
    "    \n",
    "    df[\"consistency_color\"] = (df[\"tbp_lv_stdL\"] * df[\"tbp_lv_Lext\"] /\n",
    "                               (df[\"tbp_lv_stdL\"] * df[\"tbp_lv_Lext\"]))\n",
    "    new_num_cols += [\"consistency_color\"]\n",
    "    \n",
    "    df[\"size_age_interaction\"] = df[\"clin_size_long_diam_mm\"] * df[\"age_approx\"]\n",
    "    new_num_cols += [\"size_age_interaction\"]\n",
    "    \n",
    "    df[\"hue_color_std_interaction\"] = df[\"tbp_lv_H\"] * df[\"tbp_lv_color_std_mean\"]\n",
    "    new_num_cols += [\"hue_color_std_interaction\"]\n",
    "    \n",
    "    df[\"lesion_severity_index\"] = (df[\"tbp_lv_norm_border\"] +\n",
    "                                   df[\"tbp_lv_norm_color\"] +\n",
    "                                   df[\"tbp_lv_eccentricity\"]) / 3\n",
    "    new_num_cols += [\"lesion_severity_index\"]\n",
    "    \n",
    "    df[\"shape_complexity_index\"] = df[\"border_complexity\"] + df[\"lesion_shape_index\"]\n",
    "    new_num_cols += [\"shape_complexity_index\"]\n",
    "    \n",
    "    df[\"color_contrast_index\"] = (df[\"tbp_lv_deltaA\"] +\n",
    "                                  df[\"tbp_lv_deltaB\"] + \n",
    "                                  df[\"tbp_lv_deltaL\"] +\n",
    "                                  df[\"tbp_lv_deltaLBnorm\"])\n",
    "    new_num_cols += [\"color_contrast_index\"]\n",
    "    \n",
    "    df[\"log_lesion_area\"] = np.log1p(df[\"tbp_lv_areaMM2\"])\n",
    "    new_num_cols += [\"log_lesion_area\"]\n",
    "    \n",
    "    df[\"normalized_lesion_size\"] = df[\"clin_size_long_diam_mm\"] / df[\"age_approx\"]\n",
    "    new_num_cols += [\"normalized_lesion_size\"]\n",
    "    \n",
    "    df[\"mean_hue_difference\"] = (df[\"tbp_lv_H\"] + df[\"tbp_lv_Hext\"]) / 2\n",
    "    new_num_cols += [\"mean_hue_difference\"]\n",
    "    \n",
    "    df[\"std_dev_contrast\"] = np.sqrt((df[\"tbp_lv_deltaA\"]**2 +\n",
    "                                      df[\"tbp_lv_deltaB\"]**2 + \n",
    "                                      df[\"tbp_lv_deltaL\"]**2) / 3)\n",
    "    new_num_cols += [\"std_dev_contrast\"]\n",
    "    \n",
    "    df[\"color_shape_composite_index\"] = (df[\"tbp_lv_color_std_mean\"] + \n",
    "                                         df[\"tbp_lv_area_perim_ratio\"] +\n",
    "                                         df[\"tbp_lv_symm_2axis\"]) / 3\n",
    "    new_num_cols += [\"color_shape_composite_index\"]\n",
    "    \n",
    "    df[\"lesion_orientation_3d\"] = np.arctan2(df[\"tbp_lv_y\"], df[\"tbp_lv_x\"])\n",
    "    new_num_cols += [\"lesion_orientation_3d\"]\n",
    "    \n",
    "    df[\"overall_color_difference\"] = (df[\"tbp_lv_deltaA\"] + \n",
    "                                      df[\"tbp_lv_deltaB\"] + \n",
    "                                      df[\"tbp_lv_deltaL\"]) / 3\n",
    "    new_num_cols += [\"overall_color_difference\"]\n",
    "    \n",
    "    df[\"symmetry_perimeter_interaction\"] = df[\"tbp_lv_symm_2axis\"] * df[\"tbp_lv_perimeterMM\"]\n",
    "    new_num_cols += [\"symmetry_perimeter_interaction\"]\n",
    "    \n",
    "    df[\"comprehensive_lesion_index\"] = (df[\"tbp_lv_area_perim_ratio\"] +\n",
    "                                        df[\"tbp_lv_eccentricity\"] +\n",
    "                                        df[\"tbp_lv_norm_color\"] +\n",
    "                                        df[\"tbp_lv_symm_2axis\"]) / 4\n",
    "    new_num_cols += [\"comprehensive_lesion_index\"]\n",
    "    \n",
    "    df[\"color_variance_ratio\"] = df[\"tbp_lv_color_std_mean\"] / df[\"tbp_lv_stdLExt\"]\n",
    "    new_num_cols += [\"color_variance_ratio\"]\n",
    "    \n",
    "    df[\"border_color_interaction\"] = df[\"tbp_lv_norm_border\"] * df[\"tbp_lv_norm_color\"]\n",
    "    new_num_cols += [\"border_color_interaction\"]\n",
    "    \n",
    "    df[\"border_color_interaction_2\"] = ((df[\"tbp_lv_norm_border\"] * df[\"tbp_lv_norm_color\"]) /\n",
    "                                        (df[\"tbp_lv_norm_border\"] + df[\"tbp_lv_norm_color\"]))\n",
    "    new_num_cols += [\"border_color_interaction_2\"]\n",
    "    \n",
    "    df[\"size_color_contrast_ratio\"] = df[\"clin_size_long_diam_mm\"] / df[\"tbp_lv_deltaLBnorm\"]\n",
    "    new_num_cols += [\"size_color_contrast_ratio\"]\n",
    "    \n",
    "    df[\"age_normalized_nevi_confidence\"] = df[\"tbp_lv_nevi_confidence\"] / df[\"age_approx\"]\n",
    "    new_num_cols += [\"age_normalized_nevi_confidence\"]\n",
    "    \n",
    "    df[\"age_normalized_nevi_confidence_2\"] = np.sqrt(df[\"tbp_lv_nevi_confidence\"]**2 + df[\"age_approx\"]**2)\n",
    "    new_num_cols += [\"age_normalized_nevi_confidence_2\"]\n",
    "    \n",
    "    df[\"color_asymmetry_index\"] = df[\"tbp_lv_radial_color_std_max\"] * df[\"tbp_lv_symm_2axis\"]\n",
    "    new_num_cols += [\"color_asymmetry_index\"]\n",
    "    \n",
    "    df[\"volume_approximation_3d\"] = df[\"tbp_lv_areaMM2\"] * np.sqrt(df[\"tbp_lv_x\"]**2 +\n",
    "                                                                   df[\"tbp_lv_y\"]**2 +\n",
    "                                                                   df[\"tbp_lv_z\"]**2)\n",
    "    new_num_cols += [\"volume_approximation_3d\"]\n",
    "    \n",
    "    df[\"color_range\"] = (np.abs(df[\"tbp_lv_L\"] - df[\"tbp_lv_Lext\"]) +\n",
    "                         np.abs(df[\"tbp_lv_A\"] - df[\"tbp_lv_Aext\"]) +\n",
    "                         np.abs(df[\"tbp_lv_B\"] - df[\"tbp_lv_Bext\"]))\n",
    "    new_num_cols += [\"color_range\"]\n",
    "    \n",
    "    df[\"shape_color_consistency\"] = df[\"tbp_lv_eccentricity\"] * df[\"tbp_lv_color_std_mean\"]\n",
    "    new_num_cols += [\"shape_color_consistency\"]\n",
    "    \n",
    "    df[\"border_length_ratio\"] = df[\"tbp_lv_perimeterMM\"] / np.sqrt(2 * df[\"tbp_lv_areaMM2\"])\n",
    "    new_num_cols += [\"border_length_ratio\"]\n",
    "    \n",
    "    df[\"age_size_symmetry_index\"] = (df[\"age_approx\"] *\n",
    "                                     df[\"clin_size_long_diam_mm\"] *\n",
    "                                     df[\"tbp_lv_symm_2axis\"])\n",
    "    new_num_cols += [\"age_size_symmetry_index\"]\n",
    "    \n",
    "    df[\"age_area_symmetry\"] = (df[\"age_approx\"] *\n",
    "                               df[\"tbp_lv_areaMM2\"] *\n",
    "                               df[\"tbp_lv_symm_2axis\"])\n",
    "    new_num_cols += [\"age_area_symmetry\"]\n",
    "    \n",
    "    for col in numerical_features:\n",
    "        df, feature_name = norm_feature(df, col)\n",
    "        new_num_cols += [feature_name]\n",
    "    \n",
    "    df[\"num_images\"] = df[group_column].map(df.groupby(group_column)[id_column].count())\n",
    "    new_num_cols += [\"num_images\"]\n",
    "\n",
    "    return df, new_num_cols\n",
    "\n",
    "\n",
    "# class PAUC:\n",
    "#     def get_final_error(self, error, weight):\n",
    "#         return error\n",
    "\n",
    "#     def is_max_optimal(self):\n",
    "#         return True\n",
    "\n",
    "#     def evaluate(self, approxes, target, weight):\n",
    "#         y_true = target.astype(int)\n",
    "#         y_pred = approxes[0].astype(float)\n",
    "        \n",
    "#         score = compute_pauc(y_true, y_pred, min_tpr=0.8)\n",
    "        \n",
    "#         return score, 1.0\n",
    "\n",
    "\n",
    "def pauc_80(y_train, y_pred):\n",
    "    score_value = compute_pauc(y_train, y_pred, min_tpr=0.8)   \n",
    "    return score_value\n",
    "\n",
    "\n",
    "def get_boosting_predictions(train, test, model_name, version, path, oof_column):\n",
    "    start_time = time.time()\n",
    "    with open(path / f\"{model_name}_{version}_run_metadata.json\", \"r\") as f:\n",
    "        run_metadata = json.load(f)\n",
    "    pprint(run_metadata)\n",
    "    \n",
    "    with open(path / f\"{model_name}_{version}_encoder.joblib\", \"rb\") as f:\n",
    "        mixed_encoded_preprocessor = joblib.load(f)\n",
    "\n",
    "    enc = mixed_encoded_preprocessor.fit(train)\n",
    "    X_test = enc.transform(test)\n",
    "\n",
    "    columns_for_model = len(X_test.columns)\n",
    "    print(f\"Total number of columns: {columns_for_model}\")\n",
    "        \n",
    "    all_folds = np.unique(train[fold_column])\n",
    "#     all_folds = [1]\n",
    "    test_predictions_df = pd.DataFrame({id_column: test[id_column]})\n",
    "    for fold in all_folds:\n",
    "        model_filepath = path / f\"models/{model_name}_{version}_fold_{fold}.txt\"\n",
    "        with open(model_filepath, \"rb\") as f:\n",
    "            estimator = joblib.load(f)\n",
    "        test_predictions_df[f\"fold_{fold}\"] = estimator.predict_proba(X_test)[:, -1]\n",
    "    test_predictions_df[oof_column] = test_predictions_df[[f\"fold_{fold}\" for fold in all_folds]].mean(axis=1)\n",
    "    end_time = time.time()\n",
    "    return test_predictions_df[[id_column, oof_column]], (end_time - start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5a92576c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-22T23:36:14.003381Z",
     "iopub.status.busy": "2024-08-22T23:36:14.003125Z",
     "iopub.status.idle": "2024-08-22T23:36:44.730332Z",
     "shell.execute_reply": "2024-08-22T23:36:44.729498Z"
    },
    "papermill": {
     "duration": 30.735836,
     "end_time": "2024-08-22T23:36:44.732609",
     "exception": false,
     "start_time": "2024-08-22T23:36:13.996773",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data size: (401059, 56)\n",
      "Test data size: (3, 44)\n"
     ]
    }
   ],
   "source": [
    "train_metadata = pd.read_csv(INPUT_PATH / \"train-metadata.csv\", low_memory=False, na_values=[\"NA\"])\n",
    "test_metadata = pd.read_csv(INPUT_PATH / \"test-metadata.csv\", low_memory=False, na_values=[\"NA\"])\n",
    "\n",
    "folds_df = pd.read_csv(\"/kaggle/input/isic-scd-folds/folds.csv\")\n",
    "train_metadata = train_metadata.merge(folds_df, on=[id_column, group_column], how=\"inner\")\n",
    "print(f\"Train data size: {train_metadata.shape}\")\n",
    "print(f\"Test data size: {test_metadata.shape}\")\n",
    "\n",
    "train_metadata = boosting_preprocess(train_metadata)\n",
    "test_metadata = boosting_preprocess(test_metadata)\n",
    "\n",
    "train_metadata, new_num_cols = boosting_feature_engineering(train_metadata)\n",
    "test_metadata, _ = boosting_feature_engineering(test_metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c106e8dc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-22T23:36:44.745937Z",
     "iopub.status.busy": "2024-08-22T23:36:44.745639Z",
     "iopub.status.idle": "2024-08-22T23:36:52.382135Z",
     "shell.execute_reply": "2024-08-22T23:36:52.381176Z"
    },
    "papermill": {
     "duration": 7.645449,
     "end_time": "2024-08-22T23:36:52.384286",
     "exception": false,
     "start_time": "2024-08-22T23:36:44.738837",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating predictions for xgb_v1\n",
      "{'best_num_rounds': {'fold_1': 82,\n",
      "                     'fold_2': 173,\n",
      "                     'fold_3': 20,\n",
      "                     'fold_4': 142,\n",
      "                     'fold_5': 77},\n",
      " 'config': {'_key': None,\n",
      "            '_parent': None,\n",
      "            '_temp': False,\n",
      "            'model_name': 'xgb_v1',\n",
      "            'models_output_dir': 'models',\n",
      "            'sampling_ratio': 0.01,\n",
      "            'seed': 2022},\n",
      " 'cv_auc_avg': 0.9673757713901316,\n",
      " 'cv_auc_oof': 0.9464921630675764,\n",
      " 'cv_auc_std': 0.006521637731286478,\n",
      " 'cv_pauc_avg': 0.17368981947890508,\n",
      " 'cv_pauc_oof': 0.15296119492851015,\n",
      " 'cv_pauc_std': 0.00587196296972231,\n",
      " 'es_rounds': 150,\n",
      " 'num_rounds': 2000,\n",
      " 'params': {'alpha': 0.6779926606782505,\n",
      "            'colsample_bylevel': 0.5476090898823716,\n",
      "            'colsample_bynode': 0.9928601203635129,\n",
      "            'colsample_bytree': 0.8437772277074493,\n",
      "            'disable_default_eval_metric': True,\n",
      "            'enable_categorical': True,\n",
      "            'lambda': 8.879624125465703,\n",
      "            'learning_rate': 0.08501257473292347,\n",
      "            'max_depth': 6,\n",
      "            'random_state': 2022,\n",
      "            'scale_pos_weight': 3.29440313334688,\n",
      "            'subsample': 0.6012681388711075,\n",
      "            'tree_method': 'hist',\n",
      "            'verbosity': 0},\n",
      " 'val_auc_scores': {'fold_1': 0.9763855695822203,\n",
      "                    'fold_2': 0.9572885288935904,\n",
      "                    'fold_3': 0.9635023430382749,\n",
      "                    'fold_4': 0.9709627048208559,\n",
      "                    'fold_5': 0.9687397106157167},\n",
      " 'val_pauc_scores': {'fold_1': 0.18367412688887158,\n",
      "                     'fold_2': 0.16537818384974395,\n",
      "                     'fold_3': 0.17194383259911888,\n",
      "                     'fold_4': 0.17426448565474031,\n",
      "                     'fold_5': 0.17318846840205077}}\n",
      "Total number of columns: 86\n",
      "\n",
      "\n",
      "Generating predictions for xgb_v2\n",
      "{'best_num_rounds': {'fold_1': 106,\n",
      "                     'fold_2': 196,\n",
      "                     'fold_3': 118,\n",
      "                     'fold_4': 112,\n",
      "                     'fold_5': 44},\n",
      " 'config': {'_key': None,\n",
      "            '_parent': None,\n",
      "            '_temp': False,\n",
      "            'model_name': 'xgb_v2',\n",
      "            'models_output_dir': 'models',\n",
      "            'sampling_ratio': 0.01,\n",
      "            'seed': 2022},\n",
      " 'cv_auc_avg': 0.9667334024019318,\n",
      " 'cv_auc_oof': 0.9584420660973526,\n",
      " 'cv_auc_std': 0.004672574423174126,\n",
      " 'cv_pauc_avg': 0.17260122602267397,\n",
      " 'cv_pauc_oof': 0.1645339574493963,\n",
      " 'cv_pauc_std': 0.004837525595179168,\n",
      " 'es_rounds': 150,\n",
      " 'num_rounds': 2000,\n",
      " 'params': {'alpha': 0.6779926606782505,\n",
      "            'colsample_bylevel': 0.5476090898823716,\n",
      "            'colsample_bynode': 0.9928601203635129,\n",
      "            'colsample_bytree': 0.8437772277074493,\n",
      "            'disable_default_eval_metric': True,\n",
      "            'enable_categorical': True,\n",
      "            'lambda': 8.879624125465703,\n",
      "            'learning_rate': 0.08501257473292347,\n",
      "            'max_depth': 6,\n",
      "            'random_state': 2022,\n",
      "            'scale_pos_weight': 3.29440313334688,\n",
      "            'subsample': 0.6012681388711075,\n",
      "            'tree_method': 'hist',\n",
      "            'verbosity': 0},\n",
      " 'val_auc_scores': {'fold_1': 0.9751129113471103,\n",
      "                    'fold_2': 0.963817176741778,\n",
      "                    'fold_3': 0.9639184585241667,\n",
      "                    'fold_4': 0.9684925309805195,\n",
      "                    'fold_5': 0.9623259344160846},\n",
      " 'val_pauc_scores': {'fold_1': 0.18166898925849218,\n",
      "                     'fold_2': 0.17040633221405424,\n",
      "                     'fold_3': 0.17186716127341475,\n",
      "                     'fold_4': 0.17183237448677788,\n",
      "                     'fold_5': 0.16723127288063078}}\n",
      "Total number of columns: 128\n",
      "\n",
      "\n",
      "Generating predictions for lgb_v6\n",
      "{'best_num_rounds': {'fold_1': 267,\n",
      "                     'fold_2': 493,\n",
      "                     'fold_3': 409,\n",
      "                     'fold_4': 605,\n",
      "                     'fold_5': 185},\n",
      " 'config': {'_key': None,\n",
      "            '_parent': None,\n",
      "            '_temp': False,\n",
      "            'model_name': 'lgb_v6',\n",
      "            'models_output_dir': 'models',\n",
      "            'sampling_ratio': 0.01,\n",
      "            'seed': 2022},\n",
      " 'cv_auc_avg': 0.9669392381585942,\n",
      " 'cv_auc_oof': 0.9646024610753375,\n",
      " 'cv_auc_std': 0.0073841692717788975,\n",
      " 'cv_pauc_avg': 0.17245002747303687,\n",
      " 'cv_pauc_oof': 0.17008720048549186,\n",
      " 'cv_pauc_std': 0.007484726322328974,\n",
      " 'es_rounds': 150,\n",
      " 'num_rounds': 2000,\n",
      " 'params': {'bagging_fraction': 0.7738954452473223,\n",
      "            'bagging_freq': 4,\n",
      "            'boosting_type': 'gbdt',\n",
      "            'colsample_bynode': 0.4025961355653304,\n",
      "            'colsample_bytree': 0.8329551585827726,\n",
      "            'lambda_l1': 0.08758718919397321,\n",
      "            'lambda_l2': 0.0039689175176025465,\n",
      "            'learning_rate': 0.02,\n",
      "            'max_depth': 4,\n",
      "            'metric': 'custom',\n",
      "            'min_data_in_leaf': 85,\n",
      "            'num_leaves': 103,\n",
      "            'objective': 'binary',\n",
      "            'random_state': 2022,\n",
      "            'scale_pos_weight': 2.7984184778875543,\n",
      "            'verbosity': -1},\n",
      " 'val_auc_scores': {'fold_1': 0.9772534016017052,\n",
      "                    'fold_2': 0.9545421675104455,\n",
      "                    'fold_3': 0.9649406908687025,\n",
      "                    'fold_4': 0.9693242939686264,\n",
      "                    'fold_5': 0.9686356368434913},\n",
      " 'val_pauc_scores': {'fold_1': 0.18387722064924852,\n",
      "                     'fold_2': 0.16025631426335243,\n",
      "                     'fold_3': 0.17205357477131192,\n",
      "                     'fold_4': 0.17308064294717396,\n",
      "                     'fold_5': 0.17298238473409747}}\n",
      "Total number of columns: 128\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "if test_metadata.shape[0] == 3:\n",
    "    test_metadata = train_metadata.sample(n=SAMPLE_SIZE, random_state=42)\n",
    "for idx, (model_name, version, path, oof_column) in enumerate(zip(boosting_model_names, boosting_versions, boosting_paths, boosting_oof_columns)):\n",
    "    print(f\"Generating predictions for {model_name}_{version}\")\n",
    "    model_preds_df, runtime = get_boosting_predictions(\n",
    "        train_metadata, \n",
    "        test_metadata,\n",
    "        model_name, \n",
    "        version, \n",
    "        Path(path),\n",
    "        oof_column\n",
    "    )\n",
    "    print(\"\\n\")\n",
    "    if idx == 0:\n",
    "        ensemble_preds_df = model_preds_df.copy()\n",
    "    else:\n",
    "        ensemble_preds_df = ensemble_preds_df.merge(model_preds_df, on=id_column, how=\"left\")\n",
    "    TOTAL_RUNTIME += runtime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6531d1a6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-22T23:36:52.399018Z",
     "iopub.status.busy": "2024-08-22T23:36:52.398459Z",
     "iopub.status.idle": "2024-08-22T23:36:52.602396Z",
     "shell.execute_reply": "2024-08-22T23:36:52.601558Z"
    },
    "papermill": {
     "duration": 0.213239,
     "end_time": "2024-08-22T23:36:52.604331",
     "exception": false,
     "start_time": "2024-08-22T23:36:52.391092",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "88"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del train_metadata, test_metadata\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "93e0dd6e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-22T23:36:52.619656Z",
     "iopub.status.busy": "2024-08-22T23:36:52.619401Z",
     "iopub.status.idle": "2024-08-22T23:36:52.667470Z",
     "shell.execute_reply": "2024-08-22T23:36:52.666602Z"
    },
    "papermill": {
     "duration": 0.058146,
     "end_time": "2024-08-22T23:36:52.669448",
     "exception": false,
     "start_time": "2024-08-22T23:36:52.611302",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "feature_mapping_dict = {\n",
    "    \"sex\": defaultdict(lambda: 0, {\n",
    "        \"missing_sex\": 0,\n",
    "        \"female\": 1,\n",
    "        \"male\": 2,\n",
    "    }),\n",
    "    \"anatom_site_general\": defaultdict(lambda: 0, {\n",
    "        \"missing_anatom_site_general\": 0,\n",
    "        \"lower extremity\": 1,\n",
    "        \"head/neck\": 2,\n",
    "        \"posterior torso\": 3,\n",
    "        \"anterior torso\": 4,\n",
    "        \"upper extremity\": 5,\n",
    "    }),\n",
    "    \"tbp_tile_type\": defaultdict(lambda: 0, {\n",
    "        \"3D: white\": 0,\n",
    "        \"3D: XP\": 1,\n",
    "    }),\n",
    "    \"tbp_lv_location\": defaultdict(lambda: 0, {\n",
    "        \"Unknown\": 0,\n",
    "        \"Right Leg - Upper\": 1,\n",
    "        \"Head & Neck\": 2,\n",
    "        \"Torso Back Top Third\": 3,\n",
    "        \"Torso Front Top Half\": 4,\n",
    "        \"Right Arm - Upper\": 5,\n",
    "        \"Left Leg - Upper\": 6,\n",
    "        \"Torso Front Bottom Half\": 7,\n",
    "        \"Left Arm - Upper\": 8,\n",
    "        \"Right Leg\": 9,\n",
    "        \"Torso Back Middle Third\": 10,\n",
    "        \"Right Arm - Lower\": 11,\n",
    "        \"Right Leg - Lower\": 12,\n",
    "        \"Left Leg - Lower\": 13,\n",
    "        \"Left Arm - Lower\": 14,\n",
    "        \"Left Leg\": 15,\n",
    "        \"Torso Back Bottom Third\": 16,\n",
    "        \"Left Arm\": 17,\n",
    "        \"Right Arm\": 18,\n",
    "        \"Torso Front\": 19,\n",
    "        \"Torso Back\": 20\n",
    "    }),\n",
    "    \"tbp_lv_location_simple\": defaultdict(lambda: 0, {\n",
    "        \"Unknown\": 0,\n",
    "        \"Right Leg\": 1,\n",
    "        \"Head & Neck\": 2,\n",
    "        \"Torso Back\": 3,\n",
    "        \"Torso Front\": 4,\n",
    "        \"Right Arm\": 5,\n",
    "        \"Left Leg\": 6,\n",
    "        \"Left Arm\": 7,\n",
    "    }),\n",
    "}\n",
    "\n",
    "\n",
    "def cnn_preprocess(df):\n",
    "    df[\"age_approx\"] = df[\"age_approx\"].fillna(0)\n",
    "    df[\"age_approx\"] = df[\"age_approx\"] / 90\n",
    "    df[\"sex\"] = df[\"sex\"].fillna(\"missing_sex\")\n",
    "    df[\"sex\"] = df[\"sex\"].map(feature_mapping_dict[\"sex\"])\n",
    "    df[\"anatom_site_general\"] = df[\"anatom_site_general\"].fillna(\"missing_anatom_site_general\")\n",
    "    df[\"anatom_site_general\"] = df[\"anatom_site_general\"].map(feature_mapping_dict[\"anatom_site_general\"])\n",
    "    df[\"tbp_tile_type\"] = df[\"tbp_tile_type\"].map(feature_mapping_dict[\"tbp_tile_type\"])\n",
    "    df[\"tbp_lv_location\"] = df[\"tbp_lv_location\"].map(feature_mapping_dict[\"tbp_lv_location\"])\n",
    "    df[\"tbp_lv_location_simple\"] = df[\"tbp_lv_location_simple\"].map(feature_mapping_dict[\"tbp_lv_location_simple\"])\n",
    "    return df\n",
    "\n",
    "\n",
    "def get_emb_szs(cat_cols):\n",
    "    emb_szs = {}\n",
    "    for col in cat_cols:\n",
    "        emb_szs[col] = (len(feature_mapping_dict[col]), min(600, round(1.6 * len(feature_mapping_dict[col]) ** 0.56)))\n",
    "    return emb_szs\n",
    "\n",
    "\n",
    "def cnn_feature_engineering(df):\n",
    "    cat_cols = [\"sex\", \"anatom_site_general\",\n",
    "                \"tbp_tile_type\", \"tbp_lv_location\", \"tbp_lv_location_simple\"]\n",
    "    cont_cols = [\"age_approx\",\n",
    "                 \"clin_size_long_diam_mm\",\n",
    "                 \"tbp_lv_A\", \"tbp_lv_Aext\",\n",
    "                 \"tbp_lv_B\", \"tbp_lv_Bext\",\n",
    "                 \"tbp_lv_C\", \"tbp_lv_Cext\",\n",
    "                 \"tbp_lv_H\", \"tbp_lv_Hext\",\n",
    "                 \"tbp_lv_L\", \"tbp_lv_Lext\",\n",
    "                 \"tbp_lv_areaMM2\", \"tbp_lv_area_perim_ratio\",\n",
    "                 \"tbp_lv_color_std_mean\",\n",
    "                 # \"tbp_lv_deltaA\", \"tbp_lv_deltaB\", \"tbp_lv_deltaL\", \"tbp_lv_deltaLB\", \"tbp_lv_deltaLBnorm\",\n",
    "                 \"tbp_lv_eccentricity\",\n",
    "                 \"tbp_lv_minorAxisMM\", \"tbp_lv_nevi_confidence\", \"tbp_lv_norm_border\",\n",
    "                 \"tbp_lv_norm_color\", \"tbp_lv_perimeterMM\",\n",
    "                 \"tbp_lv_radial_color_std_max\", \"tbp_lv_stdL\", \"tbp_lv_stdLExt\",\n",
    "                 \"tbp_lv_symm_2axis\", \"tbp_lv_symm_2axis_angle\",\n",
    "                 # \"tbp_lv_x\", \"tbp_lv_y\", \"tbp_lv_z\"\n",
    "                 ]\n",
    "\n",
    "    df[\"num_images\"] = df[\"patient_id\"].map(df.groupby(\"patient_id\")[\"isic_id\"].count())\n",
    "    cont_cols.append(\"num_images\")\n",
    "\n",
    "    for col in cont_cols:\n",
    "        df[col] = np.log(df[col] + 30)\n",
    "        df[col] = df[col].fillna(0)\n",
    "    return df, cat_cols, cont_cols\n",
    "\n",
    "def test_augment(image_size, mean=None, std=None):\n",
    "    if mean is not None and std is not None:\n",
    "        normalize = A.Normalize(mean=mean, std=std, max_pixel_value=255.0, p=1.0)\n",
    "    else:\n",
    "        normalize = A.Normalize(max_pixel_value=255.0, p=1.0)\n",
    "    transform = A.Compose(\n",
    "        [A.Resize(image_size, image_size), normalize, ToTensorV2()], p=1.0\n",
    "    )\n",
    "    return transform\n",
    "\n",
    "\n",
    "class ISICDataset(Dataset):\n",
    "    def __init__(self, metadata, images, augment,\n",
    "                 use_meta=False, cat_cols: List = None, cont_cols: List = None,\n",
    "                 infer=False):\n",
    "        self.metadata = metadata\n",
    "        self.images = images\n",
    "        self.augment = augment\n",
    "        self.use_meta = use_meta\n",
    "        self.cat_cols = cat_cols\n",
    "        self.cont_cols = cont_cols\n",
    "        self.length = len(self.metadata)\n",
    "        self.infer = infer\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.length\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        row = self.metadata.iloc[index]\n",
    "        image = np.array(Image.open(BytesIO(self.images[row[\"isic_id\"]][()])))\n",
    "        if self.augment is not None:\n",
    "            image = self.augment(image=image)[\"image\"].float()\n",
    "\n",
    "        if self.use_meta:\n",
    "            x_cat = torch.tensor([row[col] for col in self.cat_cols], dtype=torch.long)\n",
    "            x_cont = torch.tensor([row[col] for col in self.cont_cols], dtype=torch.float)\n",
    "        else:\n",
    "            x_cat = torch.tensor(0)\n",
    "            x_cont = torch.tensor(0)\n",
    "\n",
    "        if self.infer:\n",
    "            return image, x_cat, x_cont\n",
    "        else:\n",
    "            target = torch.tensor(row[\"target\"])\n",
    "            return image, x_cat, x_cont, target\n",
    "\n",
    "    \n",
    "class ISICNet(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        model_name,\n",
    "        pretrained=True,\n",
    "        use_meta=False,\n",
    "        cat_cols: List = None, cont_cols: List = None, emb_szs: Dict = None,\n",
    "    ):\n",
    "        super(ISICNet, self).__init__()\n",
    "        self.model = create_model(\n",
    "            model_name=model_name,\n",
    "            pretrained=pretrained,\n",
    "            in_chans=3,\n",
    "            num_classes=0,\n",
    "            global_pool=\"\",\n",
    "        )\n",
    "        in_dim = self.model.num_features\n",
    "        self.dropouts = nn.ModuleList([nn.Dropout(0.5) for _ in range(5)])\n",
    "        self.use_meta = use_meta\n",
    "        if use_meta:\n",
    "            self.linear = nn.Linear(in_dim, 256)\n",
    "\n",
    "            self.embeddings = nn.ModuleList([nn.Embedding(emb_szs[col][0], emb_szs[col][1]) for col in cat_cols])\n",
    "            self.embedding_dropout = nn.Dropout(0.1)\n",
    "            n_emb = sum([emb_szs[col][1] for col in cat_cols])\n",
    "            n_cont = len(cont_cols)\n",
    "            self.bn_cont = nn.BatchNorm1d(n_cont)\n",
    "            self.meta = nn.Sequential(\n",
    "                nn.Linear(n_emb + n_cont, 256),\n",
    "                nn.BatchNorm1d(256),\n",
    "                nn.SiLU(),\n",
    "                nn.Dropout(0.3),\n",
    "                nn.Linear(256, 64),\n",
    "                nn.BatchNorm1d(64),\n",
    "                nn.SiLU(),\n",
    "                nn.Dropout(0.1),\n",
    "            )\n",
    "            self.classifier = nn.Linear(256 + 64, 1)\n",
    "        else:\n",
    "            self.linear = nn.Linear(in_dim, 1)\n",
    "\n",
    "    def forward(self, images, x_cat=None, x_cont=None):\n",
    "        x = self.model(images)\n",
    "        bs = len(images)\n",
    "        pool = F.adaptive_avg_pool2d(x, 1).reshape(bs, -1)\n",
    "        if self.training:\n",
    "            x_image = 0\n",
    "            for i in range(len(self.dropouts)):\n",
    "                x_image += self.linear(self.dropouts[i](pool))\n",
    "            x_image = x_image / len(self.dropouts)\n",
    "        else:\n",
    "            x_image = self.linear(pool)\n",
    "\n",
    "        if self.use_meta:\n",
    "            x_cat = [emb(x_cat[:, i]) for i, emb in enumerate(self.embeddings)]\n",
    "            x_cat = torch.cat(x_cat, 1)\n",
    "            x_cat = self.embedding_dropout(x_cat)\n",
    "            x_cont = self.bn_cont(x_cont)\n",
    "            x_meta = self.meta(torch.cat([x_cat, x_cont], 1))\n",
    "            x = torch.cat([x_image, x_meta], 1)\n",
    "            logits = self.classifier(x)\n",
    "        else:\n",
    "            logits = x_image\n",
    "        return logits\n",
    "\n",
    "\n",
    "def get_trans(img, iteration):\n",
    "    if iteration >= 6:\n",
    "        img = img.transpose(2, 3)\n",
    "    if iteration % 6 == 0:\n",
    "        return img\n",
    "    elif iteration % 6 == 1:\n",
    "        return torch.flip(img, dims=[2])\n",
    "    elif iteration % 6 == 2:\n",
    "        return torch.flip(img, dims=[3])\n",
    "    elif iteration % 6 == 3:\n",
    "        return torch.rot90(img, 1, dims=[2, 3])\n",
    "    elif iteration % 6 == 4:\n",
    "        return torch.rot90(img, 2, dims=[2, 3])\n",
    "    elif iteration % 6 == 5:\n",
    "        return torch.rot90(img, 3, dims=[2, 3])\n",
    "\n",
    "    \n",
    "def predict(model, test_dataloader, accelerator, n_tta, use_meta, log_interval=10):\n",
    "    model.eval()\n",
    "    test_probs = []\n",
    "    total_steps = len(test_dataloader)\n",
    "    with torch.no_grad():\n",
    "        for step, (images, x_cat, x_cont) in enumerate(test_dataloader):\n",
    "            logits = 0\n",
    "            probs = 0\n",
    "            for i in range(n_tta):\n",
    "                if use_meta:\n",
    "                    logits_iter = model(get_trans(images, i), x_cat, x_cont)\n",
    "                else:\n",
    "                    logits_iter = model(get_trans(images, i))\n",
    "                logits += logits_iter\n",
    "                probs += torch.sigmoid(logits_iter)\n",
    "            logits /= n_tta\n",
    "            probs /= n_tta\n",
    "\n",
    "            probs = accelerator.gather(probs)\n",
    "            test_probs.append(probs)\n",
    "\n",
    "            if (step == 0) or ((step + 1) % log_interval == 0):\n",
    "                print(f\"Step: {step + 1}/{total_steps}\")\n",
    "\n",
    "    test_probs = torch.cat(test_probs).cpu().numpy()\n",
    "    return test_probs\n",
    "\n",
    "\n",
    "def get_dnn_predictions(train, test, images, model_name, version, path, oof_column):\n",
    "    start_time = time.time()\n",
    "    with open(path / f\"{model_name}_{version}_run_metadata.json\", \"r\") as f:\n",
    "        run_metadata = json.load(f)\n",
    "    pprint(run_metadata[\"params\"])\n",
    "    \n",
    "    image_size = run_metadata[\"params\"][\"image_size\"]\n",
    "    batch_size = run_metadata[\"params\"][\"val_batch_size\"]\n",
    "    use_meta = run_metadata[\"params\"][\"use_meta\"]\n",
    "    \n",
    "    test_dataset = ISICDataset(\n",
    "        test, images, augment=test_augment(image_size), \n",
    "        use_meta=use_meta,\n",
    "        cat_cols=cat_cols,\n",
    "        cont_cols=cont_cols,\n",
    "        infer=True\n",
    "    )\n",
    "    test_dataloader = DataLoader(\n",
    "        test_dataset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=False,\n",
    "        num_workers=4,\n",
    "        drop_last=False,\n",
    "        pin_memory=True,\n",
    "    )\n",
    "\n",
    "    all_folds = np.unique(train[fold_column])\n",
    "#     all_folds = [1]\n",
    "    test_predictions_df = pd.DataFrame({id_column: test[id_column]})\n",
    "    for fold in all_folds:\n",
    "        print(f\"\\nFold {fold}\")\n",
    "        accelerator = Accelerator(\n",
    "            mixed_precision=run_metadata[\"params\"][\"mixed_precision\"],\n",
    "        )\n",
    "        \n",
    "        model = ISICNet(model_name=model_name, pretrained=False,\n",
    "                        use_meta=use_meta,\n",
    "                        cat_cols=cat_cols,\n",
    "                        cont_cols=cont_cols,\n",
    "                        emb_szs=emb_szs,)\n",
    "        model = model.to(accelerator.device)\n",
    "        \n",
    "        model, test_dataloader = accelerator.prepare(model, test_dataloader)\n",
    "        model_filepath = path / f\"models/fold_{fold}\"\n",
    "        accelerator.load_state(model_filepath)\n",
    "\n",
    "        test_predictions_df[f\"fold_{fold}\"] = predict(model, test_dataloader, accelerator, n_tta=run_metadata[\"params\"][\"n_tta\"], use_meta=use_meta)\n",
    "    test_predictions_df[oof_column] = test_predictions_df[[f\"fold_{fold}\" for fold in all_folds]].mean(axis=1)\n",
    "    end_time = time.time()\n",
    "    return test_predictions_df[[id_column, oof_column]], (end_time - start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d33ac010",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-22T23:36:52.683649Z",
     "iopub.status.busy": "2024-08-22T23:36:52.683382Z",
     "iopub.status.idle": "2024-08-22T23:37:01.833514Z",
     "shell.execute_reply": "2024-08-22T23:37:01.832725Z"
    },
    "papermill": {
     "duration": 9.159744,
     "end_time": "2024-08-22T23:37:01.835795",
     "exception": false,
     "start_time": "2024-08-22T23:36:52.676051",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data size: (401059, 56)\n",
      "Test data size: (3, 44)\n"
     ]
    }
   ],
   "source": [
    "train_metadata = pd.read_csv(INPUT_PATH / \"train-metadata.csv\", low_memory=False, na_values=[\"NA\"])\n",
    "test_metadata = pd.read_csv(INPUT_PATH / \"test-metadata.csv\", low_memory=False, na_values=[\"NA\"])\n",
    "\n",
    "folds_df = pd.read_csv(\"/kaggle/input/isic-scd-folds/folds.csv\")\n",
    "train_metadata = train_metadata.merge(folds_df, on=[id_column, group_column], how=\"inner\")\n",
    "print(f\"Train data size: {train_metadata.shape}\")\n",
    "print(f\"Test data size: {test_metadata.shape}\")\n",
    "\n",
    "train_metadata = cnn_preprocess(train_metadata)\n",
    "test_metadata = cnn_preprocess(test_metadata)\n",
    "\n",
    "train_metadata, cat_cols, cont_cols = cnn_feature_engineering(train_metadata)\n",
    "test_metadata, _, _ = cnn_feature_engineering(test_metadata)\n",
    "emb_szs = get_emb_szs(cat_cols)\n",
    "\n",
    "train_images = h5py.File(INPUT_PATH / \"train-image.hdf5\", mode=\"r\")\n",
    "test_images = h5py.File(INPUT_PATH / \"test-image.hdf5\", mode=\"r\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "942c6ca9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-22T23:37:01.850871Z",
     "iopub.status.busy": "2024-08-22T23:37:01.850592Z",
     "iopub.status.idle": "2024-08-22T23:40:31.969393Z",
     "shell.execute_reply": "2024-08-22T23:40:31.968224Z"
    },
    "papermill": {
     "duration": 210.128654,
     "end_time": "2024-08-22T23:40:31.971568",
     "exception": false,
     "start_time": "2024-08-22T23:37:01.842914",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating predictions for efficientnet_b2_v1\n",
      "{'debug': False,\n",
      " 'down_sampling': True,\n",
      " 'image_size': 128,\n",
      " 'init_lr': 3e-05,\n",
      " 'mixed_precision': 'fp16',\n",
      " 'mode': 'pretrain',\n",
      " 'n_tta': 8,\n",
      " 'num_epochs': 20,\n",
      " 'num_workers': 8,\n",
      " 'seed': 2022,\n",
      " 'train_batch_size': 64,\n",
      " 'use_meta': True,\n",
      " 'val_batch_size': 512}\n",
      "\n",
      "Fold 1\n",
      "Step: 1/10\n",
      "Step: 10/10\n",
      "\n",
      "Fold 2\n",
      "Step: 1/10\n",
      "Step: 10/10\n",
      "\n",
      "Fold 3\n",
      "Step: 1/10\n",
      "Step: 10/10\n",
      "\n",
      "Fold 4\n",
      "Step: 1/10\n",
      "Step: 10/10\n",
      "\n",
      "Fold 5\n",
      "Step: 1/10\n",
      "Step: 10/10\n",
      "\n",
      "\n",
      "Generating predictions for seresnet50_v1\n",
      "{'debug': False,\n",
      " 'down_sampling': True,\n",
      " 'image_size': 128,\n",
      " 'init_lr': 3e-05,\n",
      " 'mixed_precision': 'fp16',\n",
      " 'mode': 'pretrain',\n",
      " 'n_tta': 8,\n",
      " 'num_epochs': 20,\n",
      " 'num_workers': 8,\n",
      " 'seed': 2022,\n",
      " 'train_batch_size': 64,\n",
      " 'use_meta': True,\n",
      " 'val_batch_size': 512}\n",
      "\n",
      "Fold 1\n",
      "Step: 1/10\n",
      "Step: 10/10\n",
      "\n",
      "Fold 2\n",
      "Step: 1/10\n",
      "Step: 10/10\n",
      "\n",
      "Fold 3\n",
      "Step: 1/10\n",
      "Step: 10/10\n",
      "\n",
      "Fold 4\n",
      "Step: 1/10\n",
      "Step: 10/10\n",
      "\n",
      "Fold 5\n",
      "Step: 1/10\n",
      "Step: 10/10\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "if test_metadata.shape[0] == 3:\n",
    "    test_metadata = train_metadata.sample(n=SAMPLE_SIZE, random_state=42)\n",
    "    test_images = train_images\n",
    "for idx, (model_name, version, path, oof_column) in enumerate(zip(cnn_model_names, cnn_versions, cnn_paths, cnn_oof_columns)):\n",
    "    print(f\"Generating predictions for {model_name}_{version}\")\n",
    "    model_preds_df, runtime = get_dnn_predictions(\n",
    "        train_metadata, \n",
    "        test_metadata,\n",
    "        test_images,\n",
    "        model_name, \n",
    "        version, \n",
    "        Path(path),\n",
    "        oof_column\n",
    "    )\n",
    "    print(\"\\n\")\n",
    "    ensemble_preds_df = ensemble_preds_df.merge(model_preds_df, on=id_column, how=\"left\")\n",
    "    TOTAL_RUNTIME += runtime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bee00cd4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-22T23:40:31.991369Z",
     "iopub.status.busy": "2024-08-22T23:40:31.991062Z",
     "iopub.status.idle": "2024-08-22T23:40:31.996694Z",
     "shell.execute_reply": "2024-08-22T23:40:31.995831Z"
    },
    "papermill": {
     "duration": 0.018117,
     "end_time": "2024-08-22T23:40:31.998939",
     "exception": false,
     "start_time": "2024-08-22T23:40:31.980822",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expected total runtime during submission: 362 mins and 43.52241039276123 secs\n"
     ]
    }
   ],
   "source": [
    "factor = EXPECTED_TEST_SIZE / SAMPLE_SIZE\n",
    "expected_total_runtime = TOTAL_RUNTIME * factor\n",
    "total_runtime_minutes = int(expected_total_runtime // 60)\n",
    "total_runtime_seconds = expected_total_runtime % 60\n",
    "print(f\"Expected total runtime during submission: {total_runtime_minutes} mins and {total_runtime_seconds} secs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8a0eb39a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-22T23:40:32.018321Z",
     "iopub.status.busy": "2024-08-22T23:40:32.018024Z",
     "iopub.status.idle": "2024-08-22T23:40:32.037679Z",
     "shell.execute_reply": "2024-08-22T23:40:32.036769Z"
    },
    "papermill": {
     "duration": 0.031467,
     "end_time": "2024-08-22T23:40:32.039672",
     "exception": false,
     "start_time": "2024-08-22T23:40:32.008205",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>isic_id</th>\n",
       "      <th>oof_xgb_v1</th>\n",
       "      <th>oof_xgb_v2</th>\n",
       "      <th>oof_lgb_v6</th>\n",
       "      <th>oof_efficientnet_b2_v1</th>\n",
       "      <th>oof_seresnet50_v1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ISIC_6973879</td>\n",
       "      <td>0.007072</td>\n",
       "      <td>0.002608</td>\n",
       "      <td>0.001650</td>\n",
       "      <td>0.000025</td>\n",
       "      <td>0.000010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ISIC_5407194</td>\n",
       "      <td>0.005565</td>\n",
       "      <td>0.001158</td>\n",
       "      <td>0.000617</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.000002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ISIC_5273739</td>\n",
       "      <td>0.008066</td>\n",
       "      <td>0.005405</td>\n",
       "      <td>0.006381</td>\n",
       "      <td>0.003474</td>\n",
       "      <td>0.000524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ISIC_0802250</td>\n",
       "      <td>0.006882</td>\n",
       "      <td>0.002557</td>\n",
       "      <td>0.003496</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>0.000014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ISIC_8084953</td>\n",
       "      <td>0.117304</td>\n",
       "      <td>0.086990</td>\n",
       "      <td>0.129695</td>\n",
       "      <td>0.000346</td>\n",
       "      <td>0.000411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4995</th>\n",
       "      <td>ISIC_7957551</td>\n",
       "      <td>0.005735</td>\n",
       "      <td>0.001501</td>\n",
       "      <td>0.000910</td>\n",
       "      <td>0.000058</td>\n",
       "      <td>0.000008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4996</th>\n",
       "      <td>ISIC_7499278</td>\n",
       "      <td>0.006262</td>\n",
       "      <td>0.002116</td>\n",
       "      <td>0.001097</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>0.000002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4997</th>\n",
       "      <td>ISIC_5754512</td>\n",
       "      <td>0.007842</td>\n",
       "      <td>0.003500</td>\n",
       "      <td>0.004969</td>\n",
       "      <td>0.000123</td>\n",
       "      <td>0.000095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4998</th>\n",
       "      <td>ISIC_2067724</td>\n",
       "      <td>0.010438</td>\n",
       "      <td>0.005192</td>\n",
       "      <td>0.005186</td>\n",
       "      <td>0.000107</td>\n",
       "      <td>0.000018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4999</th>\n",
       "      <td>ISIC_5231518</td>\n",
       "      <td>0.005909</td>\n",
       "      <td>0.001789</td>\n",
       "      <td>0.001284</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.000004</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5000 rows √ó 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           isic_id  oof_xgb_v1  oof_xgb_v2  oof_lgb_v6  \\\n",
       "0     ISIC_6973879    0.007072    0.002608    0.001650   \n",
       "1     ISIC_5407194    0.005565    0.001158    0.000617   \n",
       "2     ISIC_5273739    0.008066    0.005405    0.006381   \n",
       "3     ISIC_0802250    0.006882    0.002557    0.003496   \n",
       "4     ISIC_8084953    0.117304    0.086990    0.129695   \n",
       "...            ...         ...         ...         ...   \n",
       "4995  ISIC_7957551    0.005735    0.001501    0.000910   \n",
       "4996  ISIC_7499278    0.006262    0.002116    0.001097   \n",
       "4997  ISIC_5754512    0.007842    0.003500    0.004969   \n",
       "4998  ISIC_2067724    0.010438    0.005192    0.005186   \n",
       "4999  ISIC_5231518    0.005909    0.001789    0.001284   \n",
       "\n",
       "      oof_efficientnet_b2_v1  oof_seresnet50_v1  \n",
       "0                   0.000025           0.000010  \n",
       "1                   0.000010           0.000002  \n",
       "2                   0.003474           0.000524  \n",
       "3                   0.000006           0.000014  \n",
       "4                   0.000346           0.000411  \n",
       "...                      ...                ...  \n",
       "4995                0.000058           0.000008  \n",
       "4996                0.000009           0.000002  \n",
       "4997                0.000123           0.000095  \n",
       "4998                0.000107           0.000018  \n",
       "4999                0.000003           0.000004  \n",
       "\n",
       "[5000 rows x 6 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ensemble_preds_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f93f1fbe",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-22T23:40:32.059843Z",
     "iopub.status.busy": "2024-08-22T23:40:32.059575Z",
     "iopub.status.idle": "2024-08-22T23:40:32.078651Z",
     "shell.execute_reply": "2024-08-22T23:40:32.077726Z"
    },
    "papermill": {
     "duration": 0.031543,
     "end_time": "2024-08-22T23:40:32.080617",
     "exception": false,
     "start_time": "2024-08-22T23:40:32.049074",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>isic_id</th>\n",
       "      <th>oof_xgb_v1</th>\n",
       "      <th>oof_xgb_v2</th>\n",
       "      <th>oof_lgb_v6</th>\n",
       "      <th>oof_efficientnet_b2_v1</th>\n",
       "      <th>oof_seresnet50_v1</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ISIC_6973879</td>\n",
       "      <td>0.007072</td>\n",
       "      <td>0.002608</td>\n",
       "      <td>0.001650</td>\n",
       "      <td>0.000025</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>8.585434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ISIC_5407194</td>\n",
       "      <td>0.005565</td>\n",
       "      <td>0.001158</td>\n",
       "      <td>0.000617</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>1.697877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ISIC_5273739</td>\n",
       "      <td>0.008066</td>\n",
       "      <td>0.005405</td>\n",
       "      <td>0.006381</td>\n",
       "      <td>0.003474</td>\n",
       "      <td>0.000524</td>\n",
       "      <td>15.157740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ISIC_0802250</td>\n",
       "      <td>0.006882</td>\n",
       "      <td>0.002557</td>\n",
       "      <td>0.003496</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>0.000014</td>\n",
       "      <td>7.886787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ISIC_8084953</td>\n",
       "      <td>0.117304</td>\n",
       "      <td>0.086990</td>\n",
       "      <td>0.129695</td>\n",
       "      <td>0.000346</td>\n",
       "      <td>0.000411</td>\n",
       "      <td>17.387309</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        isic_id  oof_xgb_v1  oof_xgb_v2  oof_lgb_v6  oof_efficientnet_b2_v1  \\\n",
       "0  ISIC_6973879    0.007072    0.002608    0.001650                0.000025   \n",
       "1  ISIC_5407194    0.005565    0.001158    0.000617                0.000010   \n",
       "2  ISIC_5273739    0.008066    0.005405    0.006381                0.003474   \n",
       "3  ISIC_0802250    0.006882    0.002557    0.003496                0.000006   \n",
       "4  ISIC_8084953    0.117304    0.086990    0.129695                0.000346   \n",
       "\n",
       "   oof_seresnet50_v1     target  \n",
       "0           0.000010   8.585434  \n",
       "1           0.000002   1.697877  \n",
       "2           0.000524  15.157740  \n",
       "3           0.000014   7.886787  \n",
       "4           0.000411  17.387309  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ensemble_preds = 0\n",
    "for idx, (oof_column, weight) in enumerate(zip(oof_columns, weights)):\n",
    "    ensemble_preds += ensemble_preds_df[oof_column].rank(pct=True).values * weight\n",
    "ensemble_preds_df[target_column] = ensemble_preds\n",
    "ensemble_preds_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f23c2b47",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-22T23:40:32.101188Z",
     "iopub.status.busy": "2024-08-22T23:40:32.100892Z",
     "iopub.status.idle": "2024-08-22T23:40:32.111500Z",
     "shell.execute_reply": "2024-08-22T23:40:32.110659Z"
    },
    "papermill": {
     "duration": 0.022993,
     "end_time": "2024-08-22T23:40:32.113309",
     "exception": false,
     "start_time": "2024-08-22T23:40:32.090316",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    5000.000000\n",
       "mean        9.428887\n",
       "std         4.873161\n",
       "min         0.073086\n",
       "25%         5.403659\n",
       "50%         9.056840\n",
       "75%        13.325227\n",
       "max        18.852171\n",
       "Name: target, dtype: float64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ensemble_preds_df[target_column].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0debe0ad",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-22T23:40:32.134446Z",
     "iopub.status.busy": "2024-08-22T23:40:32.133936Z",
     "iopub.status.idle": "2024-08-22T23:40:32.143571Z",
     "shell.execute_reply": "2024-08-22T23:40:32.142767Z"
    },
    "papermill": {
     "duration": 0.022368,
     "end_time": "2024-08-22T23:40:32.145688",
     "exception": false,
     "start_time": "2024-08-22T23:40:32.123320",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>isic_id</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ISIC_6973879</td>\n",
       "      <td>8.585434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ISIC_5407194</td>\n",
       "      <td>1.697877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ISIC_5273739</td>\n",
       "      <td>15.157740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ISIC_0802250</td>\n",
       "      <td>7.886787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ISIC_8084953</td>\n",
       "      <td>17.387309</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        isic_id     target\n",
       "0  ISIC_6973879   8.585434\n",
       "1  ISIC_5407194   1.697877\n",
       "2  ISIC_5273739  15.157740\n",
       "3  ISIC_0802250   7.886787\n",
       "4  ISIC_8084953  17.387309"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ensemble_preds_df[[id_column, target_column]].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "be84e885",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-22T23:40:32.167433Z",
     "iopub.status.busy": "2024-08-22T23:40:32.166922Z",
     "iopub.status.idle": "2024-08-22T23:40:32.191024Z",
     "shell.execute_reply": "2024-08-22T23:40:32.190264Z"
    },
    "papermill": {
     "duration": 0.03726,
     "end_time": "2024-08-22T23:40:32.193247",
     "exception": false,
     "start_time": "2024-08-22T23:40:32.155987",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "ensemble_preds_df[[id_column, target_column]].to_csv(\"submission.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5bb810e",
   "metadata": {
    "papermill": {
     "duration": 0.009988,
     "end_time": "2024-08-22T23:40:32.218807",
     "exception": false,
     "start_time": "2024-08-22T23:40:32.208819",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "databundleVersionId": 9094797,
     "sourceId": 63056,
     "sourceType": "competition"
    },
    {
     "datasetId": 5554293,
     "sourceId": 9220637,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 5580934,
     "sourceId": 9227465,
     "sourceType": "datasetVersion"
    },
    {
     "sourceId": 187477024,
     "sourceType": "kernelVersion"
    },
    {
     "sourceId": 193130710,
     "sourceType": "kernelVersion"
    },
    {
     "sourceId": 193248043,
     "sourceType": "kernelVersion"
    },
    {
     "sourceId": 193248172,
     "sourceType": "kernelVersion"
    },
    {
     "sourceId": 193248211,
     "sourceType": "kernelVersion"
    }
   ],
   "dockerImageVersionId": 30733,
   "isGpuEnabled": true,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 273.276108,
   "end_time": "2024-08-22T23:40:35.336211",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-08-22T23:36:02.060103",
   "version": "2.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
